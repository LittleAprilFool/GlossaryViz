[
  {"definition": "A transform that preserves parallel lines.\nThat is, when the transform is applied to a pair of lines that are parallel, then the\nresulting transformed lines are also parallel.  An affine transform, T, has the property\nthat the transform of the line segment between a point (x1,y1) and a point (x2,y2) is\nthe line between the points T(x1,y1) and T(x2,y2).  Effectively, the transform of a line\nsegment can be computed just by transforming its two endpoints.  This makes affine\ntransforms very efficient for computer graphics.  Any affine transform can be represented\nas a composition of rotations, translations, and scalings.", "term": "affine transform."},
{"definition": "In object-oriented programming, a class that is meant to be used\nonly as a basis for subclasses. Objects can be created from the subclasses, but not from\nthe abstract class itself.  The purpose of an abstract class is to define the properties\nand behaviors that all of its subclasses have in common.", "term": "abstract class."},
{"definition": "Using the alpha component of a color to blend the color with\na background color, when the color is drawn over the background color.  That is, the new color \nof a pixel is obtained by blending the drawing color with the current color, with the degree of \nblending depending on the alpha component of the drawing color.  Alpha blending is most\ncommonly used to simulate transparency.", "term": "alpha blending."},
{"definition": "An extra component (that is, one of the numbers that are used\nto specify a color) in a color model that is not part of the actual color specification.  The\nalpha component is extra information.  It is most often used to specify the degree of\ntransparency of a color.", "term": "alpha color component."},
{"definition": "A material property that represents the proportion of\nambient light in the environment that is reflected by a surface.", "term": "ambient color."},
{"definition": "Directionless light that exists in an environment but does not\nseem to come from a particular source in the environment.  An approximation for light\nthat has been reflected so many times that its original source can't be identified.\nAmbient light illuminates all objects in a scene equally.", "term": "ambient light."},
{"definition": "A rendering technique that takes into account the fact that ambient light\nwill illuminate different surfaces to varying extents, depending on the degree to which ambient light is blocked,\nor \"occluded,\" from reaching each surface by other geometry in the scene.  \nAmbient occlusion is an improvement on basic ambient lighting, but it is not an actual physical phenomenon.", "term": "ambient occlusion."},
{"definition": "A technique for combining stereographic images of a scene, one for the\nleft eye and one for the right eye, into a single image.  Typically, the image for the left eye is\ndrawn using only shades of red, and the image for the right eye contains only blue and green\ncolor components.  The 3D effect can be seen by viewing the combined image through\nred/cyan glasses, which allow each eye to see only the image that is intended for that eye.", "term": "anaglyph stereo."},
{"definition": "A sequence of images that, when displayed quickly one after the other,\nwill produce the impression of continuous motion or change.  The term animation also refers\nto the process of creating such image sequences.", "term": "animation."},
{"definition": "A technique for more accurate sampling of texture images, in the\ncase where a pixel on the surface that is being textured corresponds to a non-rectangular region in the\ntexture.  Anisotropic filtering is available as an optional extension in WebGL.", "term": "anisotropic filtering."},
{"definition": "A technique used to reduce the jagged or \"staircase\" appearance\nof diagonal lines, text, and other shapes that are drawn using pixels.  When a pixel is only partly\ncovered by a geometric shape, then the color of the pixel is a blend of the color of the shape and\nthe color of the background, with the degree of blending depending on the fraction of the\npixel that is covered by the geometric shape.", "term": "antialiasing."},
{"definition": "Application Programming Interface.  A collection of related classes, functions,\nconstants, etc., for performing some task.  An API is an \"interface\" in the sense that it\ncan be used without understanding how its functionality is actually implemented.", "term": "API."},
{"definition": "The ratio of the width, w, of a rectangle to the height, h, of the rectangle, \nexpressed either as a ratio w:h or as a fraction w/h.", "term": "aspect ratio."},
{"definition": "Refers to the way that illumination from a point light or\nspot light decreases with distance from the light.  Physically, illumination should\ndecrease with the square of the distance, but computer graphics often uses a linear\nattenuation with distance, or no attenuation at at all.", "term": "attenuation."},
{"definition": "A property, such as color, of a graphical object.  An image can be specified\nby the geometric shapes that it contains, together with their attributes.", "term": "attribute."},
{"definition": "Variables that represent input to the vertex shader in a \nprogrammable graphics pipeline.  An attribute variable can take on a different value for \neach vertex in a primitive.", "term": "attribute variable."},
{"definition": "Rotation in 3D space is rotation about a line, which is called\nthe axis of rotation.  The axis of rotation remains fixed, while everything else moves\nin circles around the axis.", "term": "axis of rotation."},
{"definition": "One of the two sides of a polygon in 3D.\nA polygon has two sides. One is taken to be the front face, and the other is the back face.  In OpenGL, the\ndifference is determined by the order in which the vertices of the polygon are\nenumerated.  The default is that, seen from the back, the vertices are enumerated\nin clockwise order around the polygon.", "term": "back face."},
{"definition": "A coordinate system on a triangle in which a point is written\nas a linear combination of the vertices of the triangle, that is, a*A+b*B+c*C, where A, B, and C\nare the vertices and a, b, and c are numbers.  Any point in the triangle can be written in this form\nwhere the coefficients a, b, and c have values in the range 0 to 1 and a+b+c is equal to 1.", "term": "barycentric coordinates."},
{"definition": "A smooth curve between two points defined by parametric\npolynomial equations.  A cubic Bezier curve segment is defined by its two endpoints P1 and P2 and\nby two control points C1 and C2.  The tangent to the curve (its direction and speed) at P1 is\ngiven by the line from P1 to C1.  The tangent vector to the curve at P2 is given by \nthe line from C2 to P2.  A quadratic Bezier curve is defined by its two endpoints and\na single control point C.  The tangent at each endpoint is the line between that endpoint\nand\u00a0C.", "term": "Bezier curve."},
{"definition": " A free and open source 3D modeling and animation program.", "term": "Blender."},
{"definition": "A specific algorithm for deciding which pixels to color\nto represent a geometric line segment, using only integer arithmetic.  The algorithm can\nbe implemented very efficiently in computer hardware", "term": "Bresenham's line algorithm."},
{"definition": "Bidirectional Scattering Distribution Function.  A generalization of the\nidea of \"material\" in 3D graphics.  A BSDF gives the probability that a light ray that arrives\nat point of space from one direction will leave that point heading in a another direction.\nThe probability is a function of the two directions, the point, and the wavelength of the light.\nOnce kind of scattering is reflection of light from a surface.  For that case, the term\nBRDF (Bidirectional Reflectance Distribution Function) is used.", "term": "BSDF."},
{"definition": "Using a texture to modify the normal vectors on a surface, to give\nthe appearance of variations in height without actually modifying the geometry of the surface.", "term": "bumpmapping."},
{"definition": "In 3D computer graphics, an object that combines the projection and\nviewing transforms into an abstraction that imitates a physical camera or eye.", "term": "camera."},
{"definition": "The default coordinate system in OpenGL.  The projection transform\nmaps the 3D scene to clip coordinates.  The rendered image will show the contents of the\ncube in the clip coordinate system that contains x, y, and z values in the range from -1 to 1; anything\noutside that range is \"clipped\" away.", "term": "clip coordinates."},
{"definition": "In OpenGL, the region of memory that holds the color data for the\nimage.  It acts as the drawing surface where images are rendered.", "term": "color buffer."},
{"definition": "One of the numbers used in a color model to specify a color.\nFor example, in the RGB color model, a color is specified by three color components representing\nthe amounts of red, green, and blue in the color.", "term": "color component."},
{"definition": "The color gamut of a display device, such as a printer or computer screen, \nis the set of colors can be displayed by the device. ", "term": "color gamut."},
{"definition": "In WebGL, a setting that determines which \"channels\" in the color\nbuffer are written during rendering.  The channels are the RGBA color components red, green, \nblue, and alpha. A color mask consists of four boolean values, one for each channel. A false\nvalue prevents any change from being made to the corresponding color component in the color\nbuffer.", "term": "color mask."},
{"definition": "A way of specifying colors numerically.  Each color that can represented\nin a color model is assigned one or more numerical component values.  An example is the RGB color\nmodel, where a color is specified by three numbers giving the red, green, and blue components\nof the color.", "term": "color model."},
{"definition": "Column-by-column ordering of the elements of a two-dimensional\nmatrix; that is, an ordering that starts with the elements in the first column,\nfollowed by the elements in the second column, and so on.  Column-major order is used for\nmatrices in OpenGL and GLSL.", "term": "column-major order."},
{"definition": "In object-oriented programming, a subroutine that is used to create\nobjects.  A constructor for a class creates and initializes objects belonging to that\nclass.  (JavaScript, which does not have classes as such, does have constructors, so that\na constructor in effect defines a class.)", "term": "constructor."},
{"definition": "A point that does not lie on the curve but that is used to help control\nthe shape of the curve.  For example, a control point for a Bezier curve segment is used to specify the\ntangent vector (direction and speed) of the curve at an endpoint.", "term": "control point."},
{"definition": "A convex geometric shape has the property that whenever two points are\ncontained in the shape, then the line segment between those two points is entirely contained\nin the shape.", "term": "convex."},
{"definition": "A way of assigning numerical coordinates to geometric points.  In two\ndimensions, each point corresponds to a pair of numbers.  In three dimensions, each point corresponds\nto a triple of numbers.", "term": "coordinate system."},
{"definition": "The Central Processing Unit in a computer, the component that actually\nexecutes programs.  The CPU reads machine language instructions from the computer's memory\nand carries them out.", "term": "CPU."},
{"definition": "A vector product of two 3D vectors.  The cross product of\nv and w is a vector that is perpendicular to both v and w and whose length is equal to\nthe absolute value of the sine of the angle between v and w.  If v=(x,y,z) and\nw=(a,b,c), then their cross product is the vector (yc-zb,za-xc,xb-ya).", "term": "cross product."},
{"definition": "Cascading Style Sheets.  A language that is used for specifying the style,\nor presentation, of the content of web pages.  CSS can control things like colors, backgrounds,\nfonts, shadows, borders, and the size and position of elements of the page.", "term": "CSS."},
{"definition": "A texture made up of six images, one for each of the directions\npositive x, negative x, positive y, negative y, positive z, and negative z.  The images\nare intended to include everything that can be seen from a given point. Cubemap textures\nare used for environment mapping and skyboxes.", "term": "cubemap texture."},
{"definition": "A multi-pass rendering technique where a first pass processes the geometry and\nsaves relevant information such as transformed coordinates, normal vectors, and material properties.  The\ndata can be stored in textures, which are called \"geometry buffers\" or \"G-buffers\" in this context.\nLighting and other effects can then be computed in additional passes, using the pre-computed\ninformation from the geometry buffers instead of re-computing it for each pass.", "term": "deferred shading."},
{"definition": "A region of memory that stores the information needed for the depth test\nin 3D graphics, that is, a depth value for each pixel in the image.  Also called the \"z-buffer.\"", "term": "depth buffer."},
{"definition": "In WebGL, a setting that controls whether depth values are\nwritten to the depth buffer during rendering.  When the depth mask is set to false,\nthe depth value is discarded and the depth buffer is unchanged.", "term": "depth mask."},
{"definition": "A solution to the hidden surface problem that involves keeping\ntrack of the depth, or distance from the viewer, of the object currently visible at each\npixel in the image.  When a new object is drawn at a pixel, the depth of the new object\nis compared to the depth of the current object to decide which one is closer to the viewer.\nThe advantage of the depth test is that objects can be rendered in any order.  A disadvantage\nis that only a limited range of depths can be represented in the image.", "term": "depth test."},
{"definition": "The coordinate system used on a display device or rendered image,\noften using pixels as the unit of measure.", "term": "device coordinates."},
{"definition": "A material property that represents the proportion of\nincident light that is reflected diffusely from a surface.", "term": "diffuse color."},
{"definition": "Reflection of incident light in all directions from a surface,\nso that diffuse illumination of a surface is visible to all viewers, independent of the\nviewer's position.", "term": "diffuse reflection."},
{"definition": " Also called a \"dag.\" A linked data structure in which there are no cycles.\nThat is, it is not possible to find a sequence of nodes where each node links to the next and\nthe last node links back to the first.", "term": "directed acyclic graph."},
{"definition": "A light source whose light rays are parallel, all arriving from\nthe same direction.  Can be considered to be a light source at an effectively infinite distance.\nAlso called a \"sun,\" since the Sun is an example of a directional light source.", "term": "directional light."},
{"definition": "A list of graphics primitives and attributes which can be traversed to create all or part \nof an image.  Display lists were used in some early vector-graphics hardware.  They were also available\nin traditional OpenGL.", "term": "display list."},
{"definition": "Document Object Model.  A specification for representing a web page (and other kinds of\nstructured document) as a tree-like data structure.  Can also refer to the data structure itself,\nas in \"the DOM for this web page.\"  A web page can be modified dynamically by manipulating its\nDOM, using the JavaScript programming language.", "term": "DOM."},
{"definition": "The dot product of two vectors is the sum of the products of corresponding\ncoordinates.  For 3D vectors v=(x,y,z) and w=(a,b,c), the dot product of v and w is\nx*a+y*b+z*c.  The dot product is equal to the cosine of the angle between the vectors,\ndivided by the product of their lengths.", "term": "dot product."},
{"definition": "A graphics technique in which an image is drawn off-screen, in a region\nof memory called an off-screen buffer or \"back buffer.\"  When the image is drawn, it can be copied to\nthe buffer that represents the contents of the screen, which is also known as the \"front buffer.\"\nIn true double buffering, the image doesn't have to be copied; instead, the buffers can be\n\"swapped\" so that the back buffer becomes the front buffer, and the front buffer becomes the\nback buffer.", "term": "double buffering."},
{"definition": "A computer program for creating images using vector-style graphics, where the user creates the image\nby specifying shapes that make up the image and their attributes.", "term": "drawing program."},
{"definition": "An integrated development environment for writing programs in Java (and other\nprogramming languages).  Eclipse is a free program that can be downloaded from \nhttp://eclipse.org.", "term": "Eclipse."},
{"definition": "A material property that represents color that is intrinsic\nto a surface, rather than coming from light from other sources that is reflected\nby the surface.  Emission color can make the object look like it is glowing, but\nit does not illuminate other objects.  Emission color is often called \"emissive color.\"", "term": "emission color."},
{"definition": "A way of simulating mirror-like reflection from the surface\nof an object.  The environment that is to be reflected from the surface \nis represented as a cubemap texture.  To determine what point in the texture\nis visible at a given point on the object,\na ray from the viewpoint is reflected from the surface point, and the reflected ray\nis intersected with the texture cube.  Environment mapping is also called reflection mapping.", "term": "environment mapping."},
{"definition": "A transform that preserves distances and angles.  A Euclidean\ntransform represents a \"rigid motion.\"  That is, the transform of an object is an exact\ncopy of the object, with the same size and shape.  Any Euclidean transform can be \nrepresented as a composition of rotations and translations.", "term": "Euclidean transform."},
{"definition": "Express the rotation of an object in its own coordinate system,\ngiven as individual rotations about the x, y, and z axes in that coordinate system.  \nThe cumulative effect of rotations about the three coordinate axes depends on the order in\nwhich the rotations are applied.", "term": "Euler angles."},
{"definition": "A technique for producing a solid from a 2D shape by\nmoving the shape along a curve in 3D.  The solid is the set of points through which\nthe shape passes as it moves along the curve.  The most common case is moving the shape\nalong a line segment that is perpendicular to the plane that contains the shape.  In practice,\nin computer graphics, the object that is produced by extrusion is just the surface of\nthe extruded solid.", "term": "extrusion."},
{"definition": "The coordinate system on 3D space defined by the viewer.\nIn eye coordinates in OpenGL 1.1, the viewer is located at the origin, looking in the\ndirection of the negative z-axis, with the positive y-axis pointing upwards, and the\npositive x-axis pointing to the right. The modelview transformation maps objects into\nthe eye coordinate system, and the projection transform maps eye coordinates to clip coordinates.", "term": "eye coordinates."},
{"definition": "Drawing the interior of a shape, by coloring the pixels that\nlie inside the shape.  Filling does not apply to shapes, such as lines, that have no\ninterior.", "term": "filling a shape."},
{"definition": "A graphics processing pipeline with a fixed set of processing\nstages that cannot be modified by a programmer.  Data for an image passes through a sequence of\nprocessing stages, with the image as the end product.  The sequence is called a \"pipeline.\"\nWith a fixed-function pipeline, the programmer can enable and disable stages and set options\nthat control the processing but cannot add to the functionality.", "term": "fixed-function pipeline."},
{"definition": "A lighting computation for the faces of a polygon or polygonal\nmesh that uses the same normal vector at each point in the polygon, giving the polygon a flat\nor faceted appearance.", "term": "flat shading."},
{"definition": "A shader program that will be executed once for\neach pixel in a primitive.  A fragment shader must compute a color for the pixel,\nor discard it.  Fragment shaders are also called pixel shaders.", "term": "fragment shader."},
{"definition": "In WebGL, a data structure that organizes the buffers for rendering an\nimage, possibly including a color buffer, a depth buffer, and a stencil buffer.  A WebGL graphics context has a\ndefault framebuffer for on-screen rendering, and additional framebuffers can be created for\noff-screen rendering.", "term": "framebuffer."},
{"definition": "A region of memory that contains color data for a digital image.  Most often\nrefers to the memory containing the image that appears on the computer's screen.", "term": "frame buffer."},
{"definition": "One of the two sides of a polygon in 3D.\nA polygon has two sides. One is taken to be the front face, and the other is the back face.  In OpenGL, the\ndifference is determined by the order in which the vertices of the polygon are\nenumerated.  The default is that, seen from the front, the vertices are enumerated\nin counterclockwise order around the polygon.", "term": "front face."},
{"definition": "A truncated pyramid; that is, a pyramid from which the top has\nbeen cut off.  In OpenGL 1.1, the view volume for a perspective projection is a frustum.", "term": "frustum."},
{"definition": "Creating a scene by specifying the geometric objects contained\nin the scene, together with geometric transforms to be applied to them and attributes that\ndetermine their appearance.", "term": "geometric modeling."},
{"definition": "Geometric objects in a graphics system, such as OpenGL, that are\nnot made up of simpler objects.  Examples in OpenGL include points, lines, and triangles,\nbut the set of available primitives depends on the graphics system.  (Note that as the term\nis used in OpenGL, a single primitive can be made up of many points, line segments, or triangles.)", "term": "geometric primitive."},
{"definition": "A coordinate transformation; that is, a function that can\nbe applied to each of the points in a geometric object to produce a new object.  Common\ntransforms include scaling, rotation, and translation. ", "term": "geometric transform."},
{"definition": "An open-source JavaScript library for vector and matrix math in\ntwo and three dimensions.", "term": "glMatrix."},
{"definition": "In OpenGL, ambient light that is present in the environment\nindependent of any light source.  Total ambient light is the sum of the global ambient light plus\nthe ambient light intensity of each enabled light source.", "term": "global ambient intensity."},
{"definition": "OpenGL Shader Language, the programming languauge that is used to write\nshader programs for use with OpenGL.", "term": "GLSL."},
{"definition": "The OpenGL Utility library.  Defines several functions for use with older\nversions of OpenGL, including gluPerspective and gluLookAt.  Not to be confused with GLUT.\nGLU is a standard part of OpenGL.", "term": "GLU."},
{"definition": "The OpenGL Utility Toolkit.  A platform-independent library for writing\nOpenGL applications.  OpenGL does not include support for windows or events.  GLUT adds\nsuch support.  It also has functions for drawing 3D shapes such as spheres and polyhedra\n(not to mention a teapot).  GLUT is written in the C programming language and is used\nwith the C API for OpenGL.  However, many GLUT functions are also available in JOGL,\nthe Java API for OpenGL.  A newer, and somewhat improved, version of the toolkit named\n\"FreeGLUT\" is commonly used in place of the original version.", "term": "GLUT."},
{"definition": "Graphics Processing Unit, a computer hardware component that performs graphical\ncomputations that create and manipulate images.  Operations such as drawing a line on the screen \nor rendering a 3D image are done in the GPU, which is optimized to perform such operations very\nquickly.", "term": "GPU."},
{"definition": "A pattern of color produced by assigning colors to certain reference points and\ncomputing color for other points by interpolating or extrapolating colors from the reference points.\nThe effect is a color progression along line segments between reference points.  Different rules\nfor extending the colors beyond those lines produce different types of gradient, such as\nlinear gradients and radial gradients.", "term": "gradient."},
{"definition": "Refers to a color scheme or image in which each color is a shade of gray (where the\nterm \"shade of gray\" here includes black and white).  Typically, 256 shades of gray are used.\nGrayscale is also called \"monochrome.\"", "term": "grayscale."},
{"definition": "(Graphical User Interface.) A user interface for a program where the user\ninteracts with the program using components such as windows, menus, buttons, and\ntext-input boxes.", "term": "GUI."},
{"definition": "The problem in 3D graphics of deciding which object is\nvisible at each pixel in an image.  When one object is behind another object from the point\nof view of the viewer, only the front object should appear in the image. A rendering\nalgorithm for 3D graphics must satisfy this constraint.  Algorithms that solve the hidden\nsurface problem include the painter's algorithm and the depth test algorithm.", "term": "hidden surface problem."},
{"definition": "Creating complex geometric models in a hierarchical fashion,\nstarting with geometric primitives, combining them into components that can then be further\ncombined into more complex components, and so on.", "term": "hierarchical modeling."},
{"definition": "A way of representing n-dimensional vectors as\n(n+1)-dimensional vectors where two (n+1) vectors represent the same n-dimensional vector\nif they differ by a scalar multiple.  In 3D, for example, if w is not zero, then the\nhomogeneous coordinates (x,y,z,w) are equivalent to homogeneous coordinates \n(x/w,y/w,z/w,1), since they differ by\nmultiplication by the scalar w.  Both sets of coordinates represent the 3D vector (x/w,y/w,z/w)", "term": "homogeneous coordinates."},
{"definition": "A color specified by three numbers giving the hue, saturation, and lightness\nof the component.  The HSL color model is similar to the HSV color model.  The main difference is that\nin HSL, pure spectral colors occur when L=0.5, while in HSV, they occur when V=1.", "term": "HSL color."},
{"definition": "A color specified by three numbers giving the hue, saturation, and value\nof the component.  The hue represents the basic color.\nThe saturation is the purity of the color, with a saturation value of zero producing a shade of gray, \nthat is a color with no actual hue at all.  The value represents the brightness of the color,\nwith a value of zero giving black.  (Value is also called brightness, and the name HSB is sometimes\nused instead of HSV.)", "term": "HSV color."},
{"definition": "HyperText Markup Language.   A language that is used for specifying\nthe content of web pages.  An HTML document is made  up of text, along with \"elements\" for adding\nother content, such as images, and for defining the structure of the document.  Because of\nnesting of elements, the document can be represented by a tree-like data structure.", "term": "HTML."},
{"definition": "A canvas element on a web page. The canvas appears as a rectangular area on the page.\nThe JavaScript programming language can use a canvas element as a drawing surface.  \nHTML is a language for specifying the content of a web page.  JavaScript is the\nprogramming language for web pages.  The canvas element supports a 2D graphics API.\nIn many browsers, it also supports the 3D graphics API, WebGL.", "term": "HTML canvas."},
{"definition": "The n-by-n identity matrix is an n-by-n matrix which has\nones on the diagonal and zeros elsewhere.  Multiplication of any matrix B by the identity\nmatrix, in either order, leaves B unchanged.  Multiplication of an n-dimensional vector\nby the n-by-n identity matrix leaves the vector unchanged; that is, the identity matrix\nis the matrix for the identity transformation.", "term": "identity matrix."},
{"definition": "A transform that has no effect on its argument.  For example,\nthe identity transform in 2D is given by the formula I(x,y) = (x,y).  The identity transform I\nhas the property that if T is any transform, then I followed by T is the same as T, and T followed\nby I is the same as T.", "term": "identity transform."},
{"definition": "An image that is applied to a surface as a texture, so that it looks\nat if the image is \"painted\" onto the surface.", "term": "image texture."},
{"definition": "A color scheme in which colors are selected from a limited palette of colors.\nFor example, if the palette contains 256 colors, then a color can be specified by an eight-bit integer,\ngiving its position, or index, in the list of colors.", "term": "indexed color."},
{"definition": " (IFS). A data structure that represents a polyhedron or polygonal\nmesh.  The data structure includes a numbered list of vertices and a list of faces.  A face\nis specified by listing the indices of the vertices of the face; that is, a face is given as \na list of numbers where each number is an index into the list of vertices.", "term": "indexed face set."},
{"definition": "A light source emits light at various wavelengths.\nThe intensity of a light at a given wavelength is the amount of energy in the light\nat that wavelength.  The total intensity of the light is its total energy at all wavelengths.\nThe color of a light is determined by its intensities at all wavelengths.", "term": "intensity of a light source."},
{"definition": "Given values for some quantity at certain reference points, computing\na value for that quantity at other points by some kind of averaging applied to the values at\nthe reference points.", "term": "interpolation."},
{"definition": "In GLSL, a modifier that ensures that when the same expression\nis used to compute the value of a variable in two different shaders, the value will be the\nsame in both shaders.  This can be important for multi-pass algorithms, where several shader\nprograms are applied in succession to render one image.", "term": "invariant qualifier."},
{"definition": "Given a transform T, the inverse transform of T is a transform\nthat reverses the operation of T.  For example, for a 2D transform, for R to be the inverse of T\nmeans that R(T(x,y)) = (x,y).  Scaling by 0.5 is the inverse of scaling by 2.  Translation by\n(-3,5) is the inverse of translation by (3,-5).  Not every transform has an inverse.  For example,\nscaling by a factor of zero has no inverse.", "term": "inverse transform."},
{"definition": "Index of Refraction.  A property of a medium, such as air or glass, that transmits light.\nThe refraction, or bending, of light rays that pass from one medium to another depends on the ratio of\nthe IORs of the two media.  The index of refraction of a medium depends on the speed of light in that\nmedium.", "term": "IOR."},
{"definition": "A programming language for web pages.  JavaScript code on a web\npage is executed by a web browser that displays the page, and it can interact with the contents\nof the web page and with the user.  There are JavaScript APIs for 2D and for 3D graphics", "term": "JavaScript."},
{"definition": "A Java implementation of OpenGL.  JOGL is very complicated, since it \nattempts to support all versions of OpenGL in one programming system.  JOGL integrates\nseamlessly with Java's Swing and AWT graphics.", "term": "JOGL."},
{"definition": " (JavaScript Object Notation.) A syntax for representing JavaScript objects\nas strings, similar to the object literal syntax that is used in JavaScript.  JSON objects\ncannot contain functions, but they can contain strings, numbers, and booleans.  JSON has\nbecome a popular standard for storage and transmission of structured data.", "term": "JSON."},
{"definition": "An animation technique in which the value of some quantity\nis given explicitly only at certain times during the animation.  The times when the quantity\nis specified are called keyframes.  Between keyframes, the value of the quantity is obtained\nby interpolating between the values specified for the keyframes.", "term": "keyframe animation."},
{"definition": "A technique for computing pixel colors on a primitive using\na lighting equation that takes into account ambient and diffuse reflection.\nIn Lambert shading, the lighting equation is applied only at the vertices of the\nprimitive.  Color values for pixels in the primitive are  calculated by interpolating the\nvalues that were computed for the vertices.  Lambert shading is named after Johann Lambert,\nwho developed the theory on which it is based in the eighteenth century.", "term": "Lambert shading."},
{"definition": "A technique for producing a surface by rotating a planar curve about a line\nthat lies in the same plane as the curve. As each point rotates about the line, it generates a circle.\nThe surface is the union of the circles generated by all the points on the curve. Lathing imitates\nshapes that can be produced by a mechanical lathe.", "term": "lathing."},
{"definition": "A vector is defined by its length and its direction, so length\nis a fundamental property.  When a vector is represented as an arrow, its length is just the length\nof that arrow.  For a 2D vector given by coordinates (x,y), the length is the square root of\nx*x+y*y.  For a 3D vector given as (x,y,z), the length is the square root of x*x+y*y+z*z.", "term": "length of a vector."},
{"definition": "Using light sources in a 3D scene, so that the appearance of objects in\nthe scene can be computed based on the interaction of light with the objects' material properties.", "term": "lighting."},
{"definition": "The equation that is used in OpenGL to compute the visible color of\na point on a surface from the material properties of the surface, the normal vector for that\npoint, the direction to the viewer, the ambient light level, and the direction and intensity\nof light sources.", "term": "lighting equation."},
{"definition": "The field of mathematics that studies vector spaces and\nlinear transformations between them.  Linear algebra is part of the essential mathematical foundation\nof computer graphics.", "term": "linear algebra."},
{"definition": "A color gradient pattern in which there is a color variation along\na certain line, with constant color along lines perpendicular to that line.", "term": "linear gradient."},
{"definition": "A function from one vector space to another that preserves\nvector addition and multiplication by constants.  Linear transformations can be represented\nby matrices.  In computer graphics, they are used to implement geometric operations such\nas rotation and translation.", "term": "linear transformation."},
{"definition": "A scheme for reducing the size of a dataset without losing any of the\ninformation in that dataset.  The original data can be recovered exactly from the compressed data.\nThe image formats GIF and PNG use lossless data compression to reduce the size of the image file.", "term": "lossless data compression."},
{"definition": "A scheme for reducing the size of a dataset in which some of the information\nin the dataset can be lost.  The data that is recovered from the compressed data can differ from the original data.\nThe image format JPEG use lossy data compression to reduce the size of the image file.", "term": "lossy data compression."},
{"definition": "A quantity representing the perceived brightness of a color. For\nan RGB color, it is a weighted average of the red, green, and blue components of the\ncolor. The usual formula is 0.3*red + 0.59*green + 0.11*blue.", "term": "luminance."},
{"definition": "An operation that is used when applying a texture to an object,\nwhen the texture has to be stretched to fit the object.  For an image texture, a magnification filter\nis applied to compute the color of a pixel when that pixel covers just a fraction of a pixel in the image.", "term": "magnification filter."},
{"definition": "The properties of an object that determine how that object interacts\nwith light in the environment.  Material properties in OpenGL include, for example, diffuse\ncolor, specular color, and shininess.", "term": "material."},
{"definition": "A rectangular array of numbers.  A matrix can be represented as a\ntwo-dimensional array, with numbers arranged in rows and columns.   An N-by-N matrix\nrepresents a linear transformation from N-dimensional space to itself.", "term": "matrix."},
{"definition": "In OpenGL 1.1, a state variable that determines which one of several\ntransformation matrices will be affected by functions such as glRotatef and glFrustum.  The matrix\nmode is set with the function glMatrixMode.  Possible values include GL_MODELVIEW, GL_PROJECTION,\nand GL_TEXTURE.", "term": "matrix mode."},
{"definition": "An operation that is used when applying a texture to an object,\nwhen the texture has to be shrunk to fit the object.  For an image texture, a minification filter\nis applied to compute the color of a pixel when that pixel covers several pixels in the image.", "term": "minification filter."},
{"definition": "One of a series of reduced-size copies of a texture image, of decreasing width and height.\nStarting from the original image, each mipmap is obtained by dividing the width and height of\nthe previous image by two (unless it is already 1).  The final mimpap is a single pixel.  Mipmaps\nare used for more efficient mapping of the texture image to a surface, when the image has to be\nshrunk to fit the surface.", "term": "mipmap."},
{"definition": "A transformation that is applied to an object to\nmap that object into the world coordinate system or into the object coordinate system for\na more complex, hierarchical object.", "term": "modeling transformation."},
{"definition": "In OpenGL 1.1, a transform that combines the\nmodeling transform with the viewing transform.  That is, it is the composition of\nthe transformation from object coordinates to world coordinates and the transformation\nfrom world coordinates to eye coordinates.  Because of the equivalence between\nmodeling and viewing transformations, world coordinates are not really meaningful for\nOpenGL, and only the combined transformation is tracked.", "term": "modelview transformation."},
{"definition": "A rendering algorithm that draws a scene several times\nand combines the results somehow to compute the final image.  A simple example is\nanaglyph stereo, in which a left-eye and right-eye image of the scene are rendered\nseparately and combined.", "term": "multi-pass algorithm."},
{"definition": "An integrated development environment for writing programs in Java (and other\nprogramming languages).  Netbeans is a free program that can be downloaded from \nhttps://netbeans.org.", "term": "Netbeans."},
{"definition": "A Java object belonging to the class java.nio.Buffer or one of its\nsubclasses.  Nio buffers are similar to arrays, but they are optimized for input/output operations.\nNio buffers are used instead of arrays for certain purposes in Java's JOGL API for OpenGL.", "term": "nio buffer."},
{"definition": "The result of dividing a non-zero vector by its length, giving\na unit vector, that is, a vector of length one.  (Note that \"normalized vector\" and\n\"normal vector\" are, confusingly, unrelated terms!)", "term": "normalized vector."},
{"definition": "A normal vector to a surface at a point on that \nsurface is a vector that is perpendicular to the surface at that point.\nNormal vectors to curves are defined similarly.  Normal vectors are important\nfor lighting calculations.", "term": "normal vector."},
{"definition": "Another term for the length of the vector.  For a 3D vector given as (x,y,z), \nthe norm is the square root of x*x+y*y+z*z.", "term": "norm of a vector."},
{"definition": "The coordinate system in which the coordinates for points in an \nobject are originally specified, before they are transformed by any modeling or other transform that\nwill be applied to the object.", "term": "object coordinates."},
{"definition": "My term for a segment of the computer's memory that can be\nused as a drawing surface, for drawing images that are not visible on the screen.  Some method\nshould exist for copying the image from an off-screen canvas onto the screen.  In Java, for example, an\noff-screen canvas can be implemented as an object of type BufferedImage.", "term": "off-screen canvas."},
{"definition": "A family of computer graphics APIs that is implemented in many graphics\nhardware devices.  There are several versions of the API, and there are implementations,\nor \"bindings\" for several different programming languages.  Versions of OpenGL for embedded\nsystems such as mobile phones are known as OpenGL ES.  WebGL is a version for use on \nWeb pages.  OpenGL can be used for 2D as well as for 3D graphics, but it is most commonly\nassociated with 3D.", "term": "OpenGL."},
{"definition": "A projection from 3D to 2D that simply discards the\nz-coordinate.  It projects objects along lines that are orthogonal (perpendicular) to the\nxy-plane.  In OpenGL 1.1, the view volume for an orthographic projection is a\nrectangular solid.", "term": "orthographic projection."},
{"definition": "A solution to the hidden surface algorithm that involves\ndrawing the objects in a scene in order from back to front, that is, in decreasing order of \ndistance from the viewer.  A disadvantage is that the order is usually not well-defined\nunless some objects are decomposed into smaller sub-objects.  Another issue is that the\norder of drawing has to change when objects move or when the point of view changes.", "term": "painter's algorithm."},
{"definition": "A computer program for creating images using raster-style graphics, where the user creates the image\nby controlling the colors of each pixel.", "term": "painting program."},
{"definition": "A rendering algorithm based on the idea of computing all the paths that\nlight could have followed to arrive at the position of a viewer from each direction.  Since that\nis literally impossible, the algorithm traces a random sample of paths and averages the results.\nAs the number of samples increases, the average converges to a very high-quality image.", "term": "path tracing."},
{"definition": "Using copies of an image to fill the interior of a two-dimensional shape. The image\ncan be repeated horizontally and vertically as necessary to cover the shape.", "term": "pattern fill."},
{"definition": "A technique invented by Ken Perlin in 1983 that is used in the computation of\nnatural-looking procedural textures.  A Perlin noise function has numerical inputs (usually 2 or 3)\nand produces an output number in the range -1.0 to\u00a01.0.  The output is pseudo-random, but\nhas some regularity, with features that are similarly sized and regularly distributed,\nand with variation on several scales.", "term": "Perlin noise."},
{"definition": "Doing lighting calculations at each pixel of a primitive, which\ngives better results in most cases than per-vertex lighting.  Phong shading uses per-pixel lighting,\nwith normal vectors interpolated from the vertices.", "term": "per-pixel lighting."},
{"definition": "A projection from 3D to 2D that projects objects along\nlines radiating out from a viewpoint.  A perspective projection attempts to simulate \nrealistic viewing.  A perspective projection preserves perspective;\nthat is, objects that are farther from the viewpoint are smaller in the projection.\nIn OpenGL 1.1, the view volume for a perspective projection is a frustum, or truncated pyramid.", "term": "perspective projection."},
{"definition": "Doing lighting calculations only at the vertices of a primitive,\nand interpolating the results to get the colors of interior pixels.  Per-vertex lighting is\nthe standard in traditional OpenGL. Per-vertex lighting without specular reflection is\nLambert shading.", "term": "per-vertex lighting."},
{"definition": "A technique for computing pixel colors on a primitive using\na lighting equation that takes into account ambient, diffuse, and specular reflection.\nIn Phong shading, the lighting equation is applied at each pixel.  Normal vectors are\nspecified only at the vertices of the primitive.  The normal vector that \nis used in the lighting equation at a pixel is obtained by interpolating the\nnormal vectors for the vertices. Phong shading is named after \nBui Tuong Phong, who developed the theory in the 1970s.", "term": "Phong shading."},
{"definition": "A digital image is made up of rows and columns of small rectangles called pixels.\nTo specify a digital image, a color is assigned to each pixel in the image.", "term": "pixel."},
{"definition": "A light source whose light rays eminate from a single point.  Also\ncalled a \"lamp,\" since a lamp approximates a point source of light. Also called a positional\nlight.", "term": "point light."},
{"definition": "A multi-sided shape lying in a plane and \nspecified by a list of points, called its vertices, and made up\nof the line segments from each point in the list to the next point in the list, plus a line\nsegment from the last point in the list to the first point.  All the points are required to\nlie in the same plane.  Sometimes the term \"polygon\" includes the interior of the shape as well\nas its boundary.", "term": "polygon."},
{"definition": " A collection of polygons, where the polygons can be joined together\nalong their edges.  A polygonal mesh can represent a polyhedron, or can\nbe used as an approximation for a curved surface.  A polygonal mesh can be represented as\nan indexed face set.", "term": "polygonal mesh."},
{"definition": "A 3D graphics technique that slightly increases or decreases the depth of\nthe pixels in a primitive as it is rendered.  Polygon offset is used to avoid having several\nobjects at exactly the same depth, a situation that is not handled well by the depth test.", "term": "polygon offset."},
{"definition": "A closed 3D figure whose faces, or sides, are polygons.  Usually, it is\nassumed that the faces of a polyhedron do not intersect, except along their edges.", "term": "polyhedron."},
{"definition": "A texture image whose width and height are powers of two.  In some\ngraphics systems, this is a requirement of any image that is to be used as a texture.", "term": "power-of-two texture."},
{"definition": "In GLSL, one of the following modifiers on a numeric variable declaration:\nlowp, mediump, or highp.  A precision modifier specifies the minimum number of bits or range\nof values for the variable.", "term": "precision qualifier."},
{"definition": "A texture for which the value at a given set of texture\ncoordinates is computed as a mathematical function of the coordinates, as opposed to an\nimage texture where the value is obtained by sampling an image.", "term": "procedural texture."},
{"definition": "A graphics processing pipeline in which some of the processing\nstages can or must be implemented by programs.  Data for an image passes through a sequence of\nprocessing stages, with the image as the end product.  The sequence is called a \"pipeline.\"\nProgrammable pipelines are used in modern GPUs to provide more flexibility and control to the\nprogrammer.  The programs for a programmable pipeline are known as shaders and are written in \na shader programming language such as GLSL.", "term": "programmable pipeline."},
{"definition": "A transformation that maps coordinates in 3D to coordinates in 2D.\nProjection is used to convert a three-dimensional scene into a two-dimensional image.", "term": "projection."},
{"definition": "In 3D graphics, a transformation that maps\na scene in 3D space onto a 2D image.  In OpenGL 1.1, the projection maps the view\nvolume (that is, the region in 3D space that is visible in the image) \nto clip coordinates, in which the values of x, y, and z range from -1 to 1.\nThe x- and y-coordinates are then mapped to the image, while the z coordinate provides\ndepth information.", "term": "projection transformation."},
{"definition": "A quadrilateral, that is a four-sided figure in the plane.  OpenGL 1.1 has\nthe primitives GL_QUADS and GL_QUAD_STRIP for drawing quads, but it assumes without checking\nthat the vertices that are provided are in fact planar and define quadrilaterals that are convex.", "term": "quad."},
{"definition": "A vector in the quaternion algebra, which is a four dimensional vector space\nin which two vectors, in addition to being added, can be multiplied.  In computer graphics, quaternions of \nlength one are often used to represent rotations.  An advantage is that in the quaternion representation,\nit is possible to smoothly interpolate between two rotations.", "term": "quaternion."},
{"definition": "A color gradient pattern in which there are concentric circles, or sometimes\nellipses, of constant color, with a color variation along the radius of the circles.", "term": "radial gradient."},
{"definition": "Pixel-based graphics in which an image is specified by assigning a color\nto each pixel in a grid of pixels.", "term": "raster graphics."},
{"definition": "The process of creating a raster image, that is one made of pixels,\nfrom other data that specifies the content of the image.  For example, a vector graphics image\nmust be rasterized in order to be displayed on a computer screen.", "term": "rasterization."},
{"definition": "The process of following a ray (that is, half of an infinite line) starting\nat a given point and extending in a given direction, in order to find points of intersection of\nthe ray with objects in a scene.  Usually, only the intersection point that is closest to the\nstarting point of the ray is of interest.", "term": "ray casting."},
{"definition": "A recursive rendering algorithm that uses ray casting.  A ray is cast\nfrom the viewpoint through a point in the image and into the scene, to determine what is seen at\nthat point.  To determine the color that is seen at that point, further rays are cast\nfrom the point, including a reflected ray (if the object has specular reflections),\na refracted ray (if the object is translucent) and shadow rays towards light sources (to determine\nwhether the object is illuminated by that light).  Finding a color for a reflected or refracted\nray can use a recursive application of the ray tracing algorithm.", "term": "ray tracing."},
{"definition": "The type of computer graphics that is needed for computer\nanimation or other applications where the images must be rendered quickly, at the time\nwhen they are viewed.  For computer animation, real-time graphics generally requires the\nability to render the scene sixty times per second.", "term": "real-time graphics."},
{"definition": "Another name for environment mapping.", "term": "reflection mapping."},
{"definition": "The proportion or fraction of incident light that is reflected\nby an object.  An object can have different reflectivities at different wavelengths.\nThe color of an object is determined by its reflectivities at all wavelengths.", "term": "reflectivity."},
{"definition": "The bending of light as it passes from one transparent or translucent\nmedium into another.", "term": "refraction."},
{"definition": "A polygon in which all the sides have the same length and all the\nangles between consecutive sides are equal.  Usually the term is restricted to simple polygons,\nwhich have sides that do not intersect except at their endpoints.", "term": "regular polygon."},
{"definition": "A polyhedron in which each face is a regular polygon, and all the\nfaces and angles are identical.  There are only five regular polyhedra: the tetarhedron with 4 triangular\nfaces, the cube with 6 square faces, the octahedron with 8 triangular faces, the dodecahedron with\n12 pentagonal faces, and the icosahedron, with 20 triangular faces.", "term": "regular polyhedron."},
{"definition": "In WebGL, a buffer (that is, a region of memory) that can be\nattached to a framebuffer for use as a color buffer, depth buffer, or stencil buffer.", "term": "renderbuffer."},
{"definition": "The process of producing a 2D image from a 3D scene description.", "term": "rendering."},
{"definition": "A technique in which the output of a rendering operation\nis written directly to a texture.  In WebGL, render-to-texture can be implemented by\nattaching the texture as one of the buffers in a framebuffer.", "term": "render-to-texture."},
{"definition": "An RGB color\u2014specified by red, green, and blue component values\u2014together\nwith an alpha component.  The alpha component is most often take to specify the degree of transparency\nof the color, with a maximal alpha value giving a fully opaque color.", "term": "RGBA color."},
{"definition": "A color specified by three numbers giving the amount of red, green, and blue\nin the color.", "term": "RGB color."},
{"definition": "A coordinate system on 3D space in which the\nx, y, and z-axes satisfy this property:  If you point the thumb of your right hand in\nthe direction of the positive z-axis, then your fingers will curl from the positive x-axis\ntowards the positive y-axis.", "term": "right-handed coordinate system."},
{"definition": "A rule that is used to determine the positive direction of rotation \nabout an axis in 3D space: If you point the thumb of your right hand in the direction of the\naxis, then your fingers will curl in the direction of positive angles of rotation.  Note that\nthis assumes that the axis has a direction; in OpenGL, an axis of rotation is determined\nby the point (0,0,0) and another point (x,y,z), and the direction of the axis is from\n(0,0,0) towards (x,y,z).", "term": "right-hand rule."},
{"definition": "A geometric transform that rotates each point by a specified angle\nabout some point (in 2D) or axis (in 3D).", "term": "rotation."},
{"definition": "In GLSL, a variable in a shader program that can be used\nto do lookup in an image texture.  The value of a sampler variable specifies the texture\nunit that will be used to do the lookup.  In WebGL, sampler variables are of type \"sampler2D\"\nor \"samplerCube.\"", "term": "sampler variable."},
{"definition": "The operation of mapping texture coordinates to colors from a texture,\nincluding using mipmaps if available and applying a minification or magnification filter if\nnecessary.", "term": "sampling."},
{"definition": "The product of a number and a vector.\nThe scalar product of a number s and vector v is the vector obtained by multiplying\neach coordinate of v by s.  In 3D, if s is a number and\nv=(x,y,z), then the scalar product of s times v is the vector (sx,sy,sz).", "term": "scalar product."},
{"definition": "A geometric transform that multiplies each coordinate of a point by\na number called the scaling factor.  Scaling increases or decreases the size of an object,\nbut also moves its points closer to or farther from the origin. Scaling can be uniform\u2014the same\nin every direction\u2014or non-uniform\u2014with a different scaling factor in each coordinate\ndirection.  A negative scaling factor can be used to apply a reflection.", "term": "scaling."},
{"definition": "A language that can be used to specify graphics images\nby stating what's in the image.  That is, the scene is created \"declaratively,\" by stating what\nit contains, as opposed to being created \"procedurally,\" by a program.  A document written in\na scene description language can be used to generate a scene graph for the scene.", "term": "scene description language."},
{"definition": "A data structure that represents the objects in a scene, together\nwith attributes of the objects and the modeling transformations that are applied to the\nobjects.  An image of the scene is created by traversing the scene graph data structure.\nA scene graph might exist only conceptually, or it might be an actual data structure\nin a program.", "term": "scene graph."},
{"definition": "A program to be executed at some stage of the rendering pipeline.  OpenGL\nshaders are written in the GLSL programming languages.  For WebGL, only vertex shaders\nand fragment shaders are supported.", "term": "shader."},
{"definition": "A technique for determining which parts of a scene are illuminated\nand which are in shadow from a given light source.  The technique involves rendering the scene\nfrom the point of the view of the light source, but uses only the depth buffer from that\nrendering.  The depth buffer is the \"shadow map.\"   Along a given direction from the light\nsource, the object that is illuminated by the light is the one that is closest to the light.\nThe distance to that object is essentially encoded in the depth buffer.  Objects at\ngreater distance are in shadow.", "term": "shadow mapping."},
{"definition": "In the ray tracing algorithm, a ray that is cast from a point on object in the\ndirection of a light source to determine whether that point is illuminated by that light source\nor is in shadow.", "term": "shadow ray."},
{"definition": "A shear transformation in 2D leaves some line, L, fixed, and lines perpendicular\nto L are \"tilted\" relative to L by the same angle.  Another description is that a line parallel to L is\nmapped to itself, but is moved by an amount proportional to its distance from L.  In 3D, a shear\ntransformation leaves some plane, P, fixed, and it maps a plane parallel to P to itself, but\nmoved by an amount proportional to its distance from P.", "term": "shear transform."},
{"definition": "A material property that determines the size and sharpness\nof specular highlights.  Also called the \"specular exponent\" because of the way it is\nused in lighting calculations.  In OpenGL, shininess is a number in the range 0 to 128.", "term": "shininess."},
{"definition": "As opposed to double buffering, a graphics technique in which\nthe image is drawn directly to the screen (that is, to the buffer that serves as the source\nfor the screen image).  The disadvantage of single buffering is that, for a complex image, \nthe user can observe the process of drawing the image.", "term": "single buffering."},
{"definition": "A large cube that surrounds a scene and is textured with images that\nform a background for that scene, in all directions.", "term": "skybox."},
{"definition": "A lighting computation for the faces of a polygon or polygonal\nmesh that uses a different normal vector at each vertex of the polygon.  When two polygons\nshare a vertex, both polygons use the same normal vector for that vertex, resulting in a\nsmooth appearance at that vertex.  Smooth shading is appropriate when a polygonal mesh is\nused as an approximation for a smooth surface.", "term": "smooth shading."},
{"definition": "A material property that represents the proportion of\nincident light that is reflected specularly by a surface.", "term": "specular color."},
{"definition": "A material property that determines the size and sharpness\nof specular highlights.  Called \"shininess\" in OpenGL.", "term": "specular exponent."},
{"definition": "Illumination of a surface produced by specular reflection.\nA specular highlight is seen at points on the surface where the angle from the surface to\nthe viewer is approximately equal to the angle from the surface to a light source.", "term": "specular highlight."},
{"definition": "Mirror-like reflection of light rays from a surface.  A ray\nof light is reflected as a ray in the direction that makes the angle of reflection equal\nto the angle of incidence.  A specular reflection can only be seen by a viewer whose\nposition lies on the path of the reflected ray.", "term": "specular reflection."},
{"definition": " A light that emits a cone of illumination.  A spotlight is\nsimilar to a point light in that it has a position in 3D space, and light radiates from\nthat position.  However, the light only affects objects that are in the spotlight's\ncone of illumination.", "term": "spotlight."},
{"definition": "A data structure with the operations push() and pop().  Pushing an item\nonto a stack just adds that item to the stack.  Popping from the stack will remove and\nreturn the item that was most recently pushed onto the stack.", "term": "stack."},
{"definition": "In GLSL, one of the following modifiers on a variable declaration:\nuniform, attribute, varying, or const.", "term": "storage qualifier."},
{"definition": "Drawing the outline of a shape, as if a pen is dragged along the\nboundary of the shape.  For a shape with no interior, such as a line segment, stroking the\nshape simply means dragging the pen along the shape.", "term": "stroking a shape."},
{"definition": "A lighting effect in which light enters a slightly translucent\nobject, is reflected internally one or more times, and then exits the object at a different point.\nSubsurface scattering contributes to the appearance of materials such as jade, milk, and skin.", "term": "subsurface scattering."},
{"definition": "Scalable Vector Graphics.  An XML language for specifying 2D vector graphics.\nSVG is a scene description language. It is designed to integrate into web pages.", "term": "SVG."},
{"definition": "In GLSL, a notation such as v.yzx, where v is a vector and\nv.yzx represents the three-component vector made up of the y, z, and x components of v.  Technically,\nany use of the dot notation with vectors is considered to be a swizzler.", "term": "swizzler."},
{"definition": "A pixel in a texture image.", "term": "texel."},
{"definition": "Variation in some property from point-to-point on an object.  The most common type\nis image texture.  When an image texture is applied to a surface, the surface color varies from\npoint to point.", "term": "texture."},
{"definition": "Refers to the 2D coordinate system on a texture image, or to\nsimilar coordinate systems for 1D and 3D textures.  Texture coordinates typically range from 0 to 1\nboth vertically and horizontally, with (0,0) at the lower left corner of the image.  The\nterm also refers to coordinates that are given for a surface and that are used to specify\nhow a texture image should be mapped to the surface.", "term": "texture coordinates."},
{"definition": "A data structure that can potentially be stored\non the graphics card, and which can hold a texture image, a set of mipmaps, \nand configuration data such as the current setting for the minification and magnification\nfilters.  Using texture objects makes it possible to switch rapidly between textures\nwithout having to reload the data into the graphics card.", "term": "texture object."},
{"definition": "Determines how texture coordinates outside the range 0.0 to 1.0\nare treated when sampling an image texture.  The texture image itself has vertical and\nhorizontal coordinates in the range\n0.0 to 1.0. For coordinates outside that range, the texture repeat mode CLAMP or\nCLAMP_TO_EDGE, for example, clamps the coordinates to the range 0.0 to 1.0, essentially extending the color\nat the edge of the image indefinitely in all directions. Other repeat modes include\nREPEAT and MIRRORED_REPEAT.", "term": "texture repeat mode."},
{"definition": "In OpenGL, one of several kinds of texture, such as 2D image\ntexture, 1D texture, and cube map texture.  A texture target is specified by a constant\nsuch as GL_TEXTURE_2D or GL_TEXTURE_CUBE_MAP_POSITIVE_X.  The texture target is a parameter to\nmany OpenGL functions that work with textures.", "term": "texture target."},
{"definition": "A transformation that is applied to texture coordinates before\nthey are used to sample data from a texture.  The effect is to translate, rotate, or scale the\ntexture on the surface to which it is applied.", "term": "texture transformation."},
{"definition": "A hardware component in a GPU that does texture\nlookup. (Can also refer to an abstraction for such a component, whether or not it is\nactually implemented in hardware.)  \nThat is, it maps texture coordinates to colors from an image texture.  This is \nthe operation called \"sampling,\" and texture units are associated with sampler variables in\nGLSL shader programs.", "term": "texture unit."},
{"definition": "A JavaScript library for 3D graphics.  The library implements an\nobject-oriented scene graph API.  While it is used primarily with WebGL, three.js can\nalso render 3D scenes using the 2D canvas graphics API.", "term": "three.js."},
{"definition": "Texture Mapping Unit, another name for texture unit (perhaps with a stronger\nimplication of actual hardware support).  Also called a TPU (Texture Processing Unit).", "term": "TMU."},
{"definition": "A 3D geometric object having the shape of a doughnut (or bagel).", "term": "torus."},
{"definition": "A geometric transform that adds a given translation amount to\neach coordinate of a point.  Translation is used to move objects without changing their\nsize or orientation.", "term": "translation."},
{"definition": "An option in OpenGL that allows the back face of a polygon to\nhave different material properties from the front face.  Also, when this option is on, the\nnormal vector that is used in lighting calculations for the back face is taken to be the\nnegative of the vector for the front face.  (The negative of a vector points in the opposite\ndirection.)", "term": "two-sided lighting."},
{"definition": "In JavaScript, an array type that is limited to holding numerical values\nof a single type.  For example, the type Float32Array represents arrays that can hold 32-bit floating\npoint values, and Uint8Array arrays can hold only 8-bit integer values.  Such arrays are more efficient\nthan general JavaScript arrays for numerical calculations.  The were introduced into JavaScript\nalong with HTML canvas graphics and WebGL.", "term": "typed array."},
{"definition": "A scaling transformation in which the scaling factors in all\ndirections are the same.  Uniform scaling changes the size of an object without distorting\nits shape.", "term": "uniform scaling."},
{"definition": "Variables that represent input to a shader program in a\nprogrammable graphics pipeline.  A uniform variable has the same value at every vertex\nand at every pixel of a primitive.", "term": "uniform variable."},
{"definition": "A normal vector of length one; that is, a unit vector that is\nperpendicular to a curve or surface at a given point on the curve or surface.", "term": "unit normal."},
{"definition": "A vector of length one.", "term": "unit vector."},
{"definition": "A data type representing 8-bit non-negative integer values, taking\nvalues in the range from 0 to 255.", "term": "unsigned byte."},
{"definition": "Uniform Resource Locator. An address of some resource on the World Wide Web.\nFor example, \"http://math.hws.edu/grahicsbook\".", "term": "URL."},
{"definition": " A variable that is used to communicate values from the\nvertex shader to the fragment shader in the WebGL or OpenGL ES 2.0 graphics pipeline.\nA varying variable is assigned a value in the vertex shader.  The value of the variable in\nthe fragment shader for a pixel in the primitive is obtained by interpolating the values \nfrom the vertices of the primitive.  (In newer versions of GLSL, which support additional\nshader stages, the term \"varying variable\" is replaced by the more general terms \"in variable\" \nand \"out variable,\" which refer to variables that are used for input to or output from a shader.)", "term": "varying variable."},
{"definition": "Vertex Buffer Object.  A block of memory that can hold the\ncoordinates or other attributes for a set of vertices.  A VBO can be stored on a GPU.\nVBOs make it possible to send\nsuch data to the GPU once and then reuse it several times.  In OpenGL, VBOs are\nused with the functions glDrawArrays and glDrawElements.", "term": "VBO."},
{"definition": "An element of a vector space.  Elements of a vector space can\nbe added and can be multiplied by constants. For computer graphics, a vector is\njust a list or array containing two, three, or four numbers.  Vectors in that sense are often\nused to represent points in 2D, 3D, or 4D space.  Properly, however, a vector represents a\nquantity that has a length and a direction; a vector used in this way can be visualized\nas an arrow.", "term": "vector."},
{"definition": "Shape-based graphics in which an image is specified as a list of the shapes or\nobjects that appear in the image.", "term": "vector graphics."},
{"definition": "One of the points that define a geometric primitive, such as the\ntwo endpoints of a line segment or the three vertices of a triangle.  (The plural is \"vertices.\")\nA vertex can be specified in a coordinate system by giving its x and y coordinates in\n2D graphics, or its x, y, and z coordinates in 3D graphics.", "term": "vertex."},
{"definition": "In OpenGL, an array that is used to store coordinates or other\nattribute values for vertices, to be used with the functions glDrawArrays and glDrawElements.\nA vertex array exists on the \"client side\" of OpenGL, and it must be transmitted to the\nGPU to be used.  In Java's JOGL API for OpenGL, nio buffers are used instead of arrays.", "term": "vertex array."},
{"definition": "A shader program that will be executed once for each vertex in a primitive.\nA vertex shader must compute the vertex coordinates in the clip coordinate system.\nIt can also compute other properties, such as color.", "term": "vertex shader."},
{"definition": "Setting the position and orientation of the viewer in a 3D world, which determine what will\nbe visible when the 2D image of a 3D world is rendered.", "term": "viewing."},
{"definition": "The transformation in 3D graphics that maps world\ncoordinates to eye coordinates.  The viewing transform establishes the position, orientation,\nand scale of the viewer in the world.", "term": "viewing transformation."},
{"definition": "The rectangular area in which the image for 2D or 3D graphics is \ndisplayed.  The coordinates on the viewport are pixel coordinates, more properly called \ndevice coordinates since they are actual physical coordinates on the device where the \nimage is being displayed.", "term": "viewport."},
{"definition": "In OpenGL 1.1, the final transformation from\nclip coordinates to device coordinates.  The viewport transformation maps the\nclipping cube (the cube in 3D given by x, y, and z coordinates in the range from -1 to 1)\nto the viewport (the rectangle in the drawing surface where the image is rendered).", "term": "viewport transformation."},
{"definition": "In OpenGL 1.1, the region is 3D space that is visible in\nthe rendered image.  For orthographic projections, the view volume is a rectangular solid.\nFor perspective projection, the view volume is a frustum (truncated pyramid).", "term": "view volume."},
{"definition": "As used in this book, the window, or view window, for 2D graphics\nis the rectangle in the xy-plane that contains the portion of the plane that will be displayed\nin the image.  (The corresponding term in 3D graphics is \"view volume.\")", "term": "view window."},
{"definition": "A 3D graphics API for use on web pages.  WebGL programs are written\nin the JavaScript programming language and display their images in HTML canvas\nelements.  WebGL is based on OpenGL ES, the version of OpenGL for embedded systems, with\na few changes to adapt it to the JavaScript language and the Web environment.", "term": "WebGL."},
{"definition": "An optional capability in WebGL that is not available in all\nimplementations.  The WebGL API has a function for checking whether a given extension is available and, \nif so, activating it.", "term": "WebGL extension."},
{"definition": "The winding number of a path about a point that does not lie on the path\nis the number of times that the path winds around the point, counting each 360-degree rotation in the positive direction\nabout the point as one and each 360-degree turn in the negative direction as minus one.  To compute the\nwinding number, draw a ray extending from the point to infinity.  Each crossing of the ray by the\npath counts as 1 if it crosses the ray going in the positive direction and as negative 1 if it \ncrosses in the negative direction.", "term": "winding number."},
{"definition": "A style of drawing a polyhedron or polygonal mesh in which only the\nedges are drawn, resulting in an image made up of line segments.", "term": "wireframe."},
{"definition": "The coordinate system in which a scene is defined.  The image \nthat is produced of the scene will show the contents of the world coordinate system that\nlie within some some view volume (for 3D) or view window (for 2D).  Objects are defined\nin their own object coordinate system. Modeling transformations are then applied to place \nobjects into the scene; that is, they transform object coordinates to world coordinates.", "term": "world coordinates."},
{"definition": "eXtensible Markup Language.  Not a single language as such, but a class of languages\nthat follow certain syntax rules.  For example, SVG is an XML language because it follows those\nrules, but it also has further restrictions on its syntax that make it appropriate for specifying\n2D graphics.  XML documents, like HTML documents, have a tree-like structure defined by \"elements.\"\nHowever, HTML is not an XML language since it does not follow all the syntax rules.  XHTML is an\nalternative language for web pages that is similar to HTML but follows XML syntax rules.", "term": "XML."}
]