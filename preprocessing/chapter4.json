[{"section_title": "null", "chapter_id": "Chapter 3", "section_id": "Section 3.0", "content": ["It is time to move on to computer graphics in three dimensions, although\nit won't be until Section\u00a02 of this chapter that we really get into 3D.\nYou will find that many concepts from 2D graphics carry over to 3D, but the move into\nthe third dimension brings with it some new features that take a while to\nget used to.", "Our focus will be ", ", a graphics API\nthat was introduced in 1992 and has gone through many versions and many \nchanges since then.  OpenGL is a  low-level graphics API, similar to the 2D APIs we have\ncovered.  It is even more primitive in some ways, but of course it is\ncomplicated by the fact that it supports 3D.", "For the next two chapters, the discussion is\nlimited to OpenGL\u00a01.1.  OpenGL 1.1 is a large API, and we will \nonly cover a part of it. The goal is to introduce 3D graphics concepts, \nnot to fully cover the API.  A significant part of what we cover here\nhas been removed from the most modern versions of OpenGL.  However,\nmodern OpenGL in its pure form has a very steep initial learning curve,\nand it is really not a good starting place for someone who is encountering\n3D graphics for the first time.  Some additional support is needed\u2014if not OpenGL 1.1\nthen some similar framework.  Since OpenGL 1.1 is\nstill supported, at least by all desktop implementations of OpenGL,\nit's a reasonable place to start.", "This chapter concentrates on the geometric aspects of 3D graphics, such as defining\nand transforming objects and projecting 3D scenes into 2D images.  The images that\nwe produce will look very unrealistic.  In the next chapter, we will see how to add\nsome realism by simulating the effects of lighting and of the material properties of surfaces."], "chapter_title": "OpenGL 1.1: Geometry", "id": 3.0}, {"section_title": "null", "chapter_id": "Chapter 2", "section_id": "Section 2.0", "content": ["With this chapter, we begin our study of computer graphics by looking at the two-dimensional case.\nThings are simpler, and a lot easier to visualize, in 2D than in 3D, but most of\nthe ideas that are covered in this chapter will also be very relevant to 3D.", "The chapter begins with four sections that examine 2D graphics in a general way,\nwithout tying it to a particular programming language or graphics API.  The coding\nexamples in these sections are written in pseudocode that should make sense to\nanyone with enough programming background to be reading this book.\nIn the next three sections, we will take quick looks at 2D graphics in three\nparticular languages: Java with ", ",\nJavaScript with HTML ", " graphics, and SVG.  We will see how these\nlanguages use many of the general ideas from earlier in the chapter."], "chapter_title": "Two-Dimensional Graphics", "id": 2.0}, {"section_title": "null", "chapter_id": "Chapter 1", "section_id": "Section 1.0", "content": ["The term \"computer graphics\" refers to anything involved in the creation or\nmanipulation of images on computer, including animated images.  It is a very\nbroad field, and one in which changes and advances seem to come at a dizzying pace.\nIt can be difficult for a beginner to know where to start.  However, there is\na core of fundamental ideas that are part of the foundation of most applications\nof computer graphics.  This book attempts to cover those foundational ideas, or\nat least as many of them as will fit into a one-semester college-level course.\nWhile it is not possible to cover the entire field in a first course\u2014or even a large\npart of it\u2014this should be a good place to start.", "This short chapter provides an overview and introduction to the material\nthat will be covered in the rest of the book, without going into a lot of detail."], "chapter_title": "Introduction", "id": 1.0}, {"section_title": "null", "chapter_id": "Chapter 4", "section_id": "Section 4.0", "content": ["One of the goals of computer graphics is physical realism, that is, making\nimages that look like they could be photographs of reality.  This is not the only \ngoal.  For example, for scientific visualization, the goal is to use computer \ngraphics to present information accurately and clearly.  Artists can use computer\ngraphics to create abstract rather than realistic art.  However, realism is a\nmajor goal of some of the most visible uses of computer graphics, such as video\ngames, movies, and advertising.", "One important aspect of physical realism is ", ":\nthe play of light and shadow, the way that light reflects from different \n", ", the\nway it can bend or be diffracted into a spectrum as it passes through translucent\nobjects.  The techniques that are used to produce the most realistic graphics\ncan take all these factors and more into account.", "However, another goal of computer graphics is ", ".  OpenGL, in particular,\nwas designed for ", ", where the time that is available\nfor rendering an image is a fraction of a second.  For an animated movie, it's OK if\nit takes hours to ", " each frame.  But a video game is expected to\nrender sixty frames every second.  Even with the incredible speed of modern computer graphics\nhardware, compromises are necessary to get that speed.  And twenty years ago, when OpenGL\nwas still new, the compromises were a lot bigger", "In this chapter, we look at light and material in OpenGL 1.1.   You will learn how to\nconfigure light sources and how to assign material properties to objects.  Material properties determine how\nthe objects interact with light.  And you will learn how to apply an image to a surface\nas a ", ".  The support for light, material, and texture in OpenGL 1.1\nis relatively crude and incomplete, by today's standards.  But the concepts that it uses\nstill serve as the foundation for modern real-time graphics and, to a significant extent,\neven for the most realistic computer graphics."], "chapter_title": "OpenGL 1.1: Light and Material", "id": 4.0}, {"section_title": "Hardware and Software", "chapter_id": "Chapter 1", "section_id": "Section 1.3", "content": ["We will be using OpenGL as the primary basis for 3D graphics programming.\nThe original version of OpenGL was released in 1992 by a company named\nSilicon Graphics, which was known for its graphics workstations\u2014powerful,\nexpensive computers designed for intensive graphical applications.  (Today,\nyou probably have more graphics computing power on your smart phone.)  OpenGL\nis supported by the graphics hardware in most modern computing devices, including\ndesktop computers, laptops, and many mobile devices.  This section will give\nyou a bit of background about the history of OpenGL and about the graphics \nhardware that supports it.", "In the first desktop computers, the contents of the screen were managed\ndirectly by the ", ".  For example, to draw a line segment on the screen, the CPU\nwould run a loop to set the color of each pixel that lies along the line.\nNeedless to say, graphics could take up a lot of the CPU's time.  And graphics\nperformance was very slow, compared to what we expect today.  So what has changed?\nComputers are much faster in general, of course, but the big change is that\nin modern computers, graphics processing is done by a specialized component\ncalled a ", ", or Graphics Processing Unit.  A GPU includes processors\nfor doing graphics computations; in fact, it can include a large number of such\nprocessors that work in parallel to greatly speed up graphical operations.  \nIt also includes its own dedicated memory for storing things like images and \nlists of coordinates.  GPU processors have very fast\naccess to data that is stored in GPU memory\u2014much faster than their access to data\nstored in the computer's main memory.", "To draw a line or perform some other graphical operation, the CPU simply has to\nsend commands, along with any necessary data, to the GPU, which is responsible\nfor actually carrying out those commands.  The CPU offloads most of the graphical\nwork to the GPU, which is optimized to carry out that work very quickly.\nThe set of commands that the GPU understands make up the ", "\nof the GPU.  OpenGL is an example of a graphics API, and most GPUs support\nOpenGL in the sense that they can understand OpenGL commands, or at least\nthat OpenGL commands can efficiently be translated into commands that the\nGPU can understand.", "OpenGL is not the only graphics API.  The best-known alternative is probably \nDirect3D, a 3D graphics API used for Microsoft Windows.  OpenGL is more widely\navailable, since it is not limited to Microsoft, but Direct3D is supported by\nmost graphics cards, and it has often introduced new features earlier than OpenGL. ", "I have said that OpenGL is an API, but in fact it is a series of APIs that have\nbeen subject to repeated extension and revision.  The current version, in early\n2015, is 4.5, and it is very different from the 1.0 version from 1992.  Furthermore,\nthere is a specialized version called OpengGL\u00a0ES for \"embedded systems\" such\nas mobile phones and tablets.  And there is also WebGL, for use in Web browsers,\nwhich is basically a port of OpenGL ES\u00a02.0.  It's useful to know something\nabout how and why OpenGL has changed.", "First of all, you should know that OpenGL was designed as a \"client/server\"\nsystem.  The server, which is responsible for controlling the computer's\ndisplay and performing graphics computations, carries out commands issued by the\nclient.  Typically, the server is a GPU, including its graphics processors and memory.\nThe server executes OpenGL commands.  The client is the CPU in the same computer, along \nwith the application program that it is running. OpenGL commands come from the\nprogram that is running on the CPU.  However,\nit is actually possible to run OpenGL programs remotely over a network.  That\nis, you can execute an application program on a remote computer (the OpenGL client), while\nthe graphics computations and display are done on the computer that you are\nactually using (the OpenGL server).", "The key idea is that the client and the server are separate components, and there\nis a communication channel between those components.  OpenGL commands and the\ndata that they need are communicated from the client (the CPU) to the server (the GPU)\nover that channel.  The capacity of the channel can be a limiting factor in graphics\nperformance.  Think of drawing an image onto the screen.  If the GPU can draw the\nimage in microseconds, but it takes milliseconds to send the data for the image\nfrom the CPU to the GPU, then the great speed of the GPU is irrelevant\u2014most of\nthe time that it takes to draw the image is communication time.", "For this reason, one of the driving factors in the evolution of OpenGL has been\nthe desire to limit the amount of communication that is needed between the CPU and\nthe GPU.  One approach is to store information in the GPU's memory.  If some data\nis going to be used several times, it can be transmitted to the GPU once and\nstored in memory there, where it will be immediately accessible to the GPU.\nAnother approach is to try to decrease the number of OpenGL commands that must\nbe transmitted to the GPU to draw a given image.", "OpenGL draws ", " such as triangles.\nSpecifying a primitive means specifying ", "\nand ", " for each of its ", ".  In the\noriginal OpenGL\u00a01.0, a separate command was used to specify the coordinates of each vertex,\nand a command was needed each time the value of an attribute changed.  To draw a single \ntriangle would require three or more commands.  Drawing a complex object made up of\nthousands of triangles would take many thousands of commands.  Even in OpenGL\u00a01.1,\nit became possible to draw such an object with a single command instead of thousands.  All the data\nfor the object would be loaded into arrays, which could then be sent in a single\nstep to the GPU.  Unfortunately, if the object was going to be drawn more than\nonce, then the data would have to be retransmitted each time the object was drawn.\nThis was fixed in OpenGL\u00a01.5 with ", ".\nA VBO is a block of memory in the GPU that can store the coordinates or attribute values for\na set of vertices.  This makes it possible to reuse the data without having to retransmit it\nfrom the CPU to the GPU every time it is used.", "Similarly, OpenGL 1.1 introduced ", "\nto make it possible to store several images on the GPU for use as ", ".\nThis means that texture images that are going to be reused several times can be loaded once\ninto the GPU, so that the GPU can easily switch between images without having to reload them.", "As new capabilities were added to OpenGL, the API grew in size.  But the growth was still\noutpaced by the invention of new, more sophisticated techniques for doing graphics.  Some\nof these new techniques were added to OpenGL, but\nthe problem is that no matter how many features you add, there will always be demands for \nnew features\u2014as well as complaints that all the new features are making things too \ncomplicated! OpenGL was a giant machine, with new pieces always being tacked onto it, \nbut still not pleasing everyone. The real solution was to make the machine ", ".\nWith OpenGL 2.0, it became possible to write programs to be executed as part of the\ngraphical computation in the GPU.  The programs are run on the GPU at GPU speed.\nA programmer who wants to use a new graphics technique can write a program to \nimplement the feature and just hand it to the GPU.  The OpenGL API doesn't have to\nbe changed.  The only thing that the API has to support is the ability to send programs\nto the GPU for execution.", "The programs are called ", " (although the term does't\nreally describe what most of them actually do).  The first shaders to be introduced were\n", " and ", ".\nWhen a ", " is drawn, some work has to be done at each vertex of the primitive,\nsuch as applying a ", " to the vertex coodinates or\nusing the ", " and global ", " environment\nto compute the color of that vertex.  A vertex shader is a program that can take over the\njob of doing such \"per-vertex\" computations.  Similarly, some work has to be done for each\npixel inside the primitive.  A fragment shader can take over the job of performing such\n\"per-pixel\" computations.  (Fragment shaders are also called pixel shaders.)", "The idea of programmable graphics hardware was very successful\u2014so successful that\nin OpenGL\u00a03.0, the usual per-vertex and per-fragment processing\nwas deprecated (meaning that its use was discouraged). \nAnd in OpenGL\u00a03.1, it was removed from\nthe OpenGL standard, although it is still present as an optional extension.  In practice,\nall the original features of OpenGL are still supported in desktop versions of OpenGL and will\nprobably continue to be available in the future.  On the embedded system side, however,\nwith OpenGL\u00a0ES\u00a02.0 and later, the use of shaders is mandatory, and a large part\nof the OpenGL\u00a01.1 API has been completely removed.\nWebGL, the version of OpenGL for use in web browsers, \nis based on OpenGL\u00a0ES\u00a02.0, and it also requires shaders to get anything at all done.\nNevertheless, we will begin our study of OpenGL with version 1.1.  Most of the concepts and\nmany of the details from that version are still relevant, and it offers an easier entry point\nfor someone new to 3D graphics programming.", "OpenGL shaders are written in ", " (OpenGL Shading Language).  Like\nOpenGL itself, GLSL has gone through several versions. We will spend some time later in the\ncourse studying GLSL\u00a0ES\u00a01.0, the version used with WebGL\u00a01.0 and\nOpenGL\u00a0ES\u00a02.0.  GLSL uses a syntax similar to the C programming language.", "As a final remark on GPU hardware, I should note that the computations that are done for\ndifferent vertices are pretty much independent, and so can potentially be done in parallel.\nThe same is true of the computations for different fragments.  In fact, GPUs can\nhave hundreds or thousands of processors that can operate in parallel.  Admittedly, the\nindividual processors are much less powerful than a CPU, but then typical per-vertex\nand per-fragment computations are not very complicated.  The large number of processors,\nand the large amount of parallelism that is possible in graphics computations, makes\nfor impressive graphics performance even on fairly inexpensive GPUs."], "chapter_title": "Introduction", "id": 1.3}, {"section_title": "SVG: A Scene Description Language", "chapter_id": "Chapter 2", "section_id": "Section 2.7", "content": ["We finish this chapter with a look at one more 2D graphics system:\n", ", or Scalable Vector Graphics.  So far, we have\nbeen considering graphics programming APIs.  SVG, on the other\nhand is a ", " rather\nthan a programming language.  Where a programming language creates\na scene by generating its contents procedurally, a scene description\nlanguage specifies a scene \"declaratively,\" by listing its content.\nSince SVG is a ", " language, the content of\nof a scene includes shapes, attributes such as color and line width,\nand geometric transforms.  Most of this should be familiar to you,\nbut it should be interesting to see it in a new context.", "SVG is an ", " language, which means it has a very strict\nand somewhat verbose syntax.  This can make it a little annoying to write,\nbut on the other hand, it makes it possible to read and understand\nSVG documents even if you are not familiar with the syntax.  It's possible\nthat SVG originally stood for \"Simple\" Vector Graphics, but it is by\nno means a simple language at this point.  I will cover only a part of it\nhere, and there are many parts of the language and many options that I will\nnot mention.  My goal is to introduce the idea of a scene description language\nand to show how such a language can use the same basic ideas that are\nused in the rest of this chapter.", "SVG can be used as a file format for storing vector graphics\nimages, in much the same way that PNG and JPEG are file formats for\nstoring pixel-based images.  That means that you can open an SVG\nfile with a web browser to view the image.  (This is true, at least,\nfor modern web browsers.)  An SVG image can be included in a web page\nby using it as the source of an ", " element.  That's how the\nSVG examples on this page are displayed.  Since SVG documents are written in plain text,\nyou can create SVG images using a regular text editor, and you can read the\nsource for an SVG image by opening it in a text editor or by viewing the\nsource of the image when it is displayed in a web browser.", "An SVG file, like any XML document, starts with some standard code that almost\nno one memorizes.  It should just be copied into a new document.  Here\nis some code that can be copied as a starting point for SVG \ndocuments of the type discussed in this section (which, remember use \nonly a subset of the full SVG specification):", "The first three lines say that this is an XML SVG document.  The rest of\nthe document is an ", " element that acts as a container for the entire\nscene description.  You'll need to know a little about XML syntax.\nFirst, an XML \"element\" in its general form looks like this:\n", "The element starts with a \"start tag,\" which begins with a \"<\" followed by an identifier\nthat is the name of the tag, and ending with a\u00a0\">\".  The start tag can include\n\"attributes,\" which have the form ", ".  The ", " is an identifier;\nthe ", " is a string.  The value must be enclosed in single or double quotation marks.\nThe element ends with an \"end tag,\" which has an element name that matches the element name\nin the start tag and has the form </", ">.  Element names and attribute names\nare case-sensitive.  Between the start and end tags\ncomes the \"content\" of the element.  The content can consist of text and nested elements.\nIf an element has no content, you can replace the \">\" at the end of the start tag with\n\"/>\", and leave out the end tag.  This is called a \"self-closing tag.\" For example,\n", "This is an actual SVG element that specifies a circle.  It's easy to forget the \"/\"\nat the end of a self-closing tag, but it has to be there to have a legal XML document.", "Looking back at the SVG document, the five lines starting with <svg are just a long\nstart tag.  You can use the tag as shown, and customize the values of the ", ",\n", ", ", ", and ", " attributes.  The next line\nis a comment; comments in XML start with \"", "\" and end with \"", "\".", "The ", " and ", " attributes of the ", " tag specify a\nnatural or preferred size for the image.  It can be forced into a different size, for\nexample if it is used in an ", " element on a web page that specifies a different\nwidth and height.  The size can be specified using units of measure such as ", " for\ninches, ", " for centimeters, and ", ", for pixels, with 90 pixels to the inch.\nIf no unit of measure is specified, pixels are used.  There cannot be any space between\nthe number and the unit of measure.", "The ", " attribute sets up the ", " that will be used for \ndrawing the image.  It is what I called the ", " in ", ".\nThe value for viewBox is a list of four numbers,\ngiving the minimum ", "value, the minimum ", ", the width, and the height\nof the view window.  The width and the height must be positive, so ", " increases from\nleft-to-right, and ", " increases from top-to-bottom.  The four numbers in the list\ncan be separated either by spaces or by commas; this is typical for lists of numbers in SVG.", "Finally, the ", " attribute tells what happens when the\n", " of the viewBox does not match the aspect ratio of the rectangle\nin which the image is displayed.  The default value, \"xMidYMid\", will extend the limts\non the viewBox either horizontally or vertically to preserve the aspect ratio, and the\nviewBox will appear in the center of the display rectangle.  If you would like your \nimage to stretch to fill the display rectangle, ignoring the aspect ratio, set the\nvalue of ", " to \"none\".  (The aspect ratio issue was\ndiscussed in ", ".)", "Let's look at a complete SVG document that draws a few simple shapes.  Here's the\ndocument.  You could probably figure out what it draws even without knowing any more\nabout SVG:", "and here's the image that is produced by this example:", "\n", "In the drawing coordinate system for this example, ", " ranges from 0 to 3, and\n", " ranges from 0 to 2.  All values used for drawing, including stroke width\nand font size, are given in terms of this coordinate system.  Remember that you can\nuse any coordinate system that you find convenient!  Note, by the way, that parts\nof the image that are not covered by the shapes that are drawn will be transparent.", "Here's another example, with a larger variety of shapes.  The source code for this\nexample has a lot of comments. It uses features that we will discuss in the remainer of\nthis section.", "\n", "You can take a look at the source code, ", ".\n(For example, open it in a text editor, or open it in a web browser and use the\nbrowser's \"view source\" command.)", "In SVG, a basic shape is specified by an element in which the tag name gives the\nshape, and attributes give the properties of the shape.  There are attributes to specify\nthe geometry, such as the endpoints of a line or the radius of a circle.\nOther attributes specify style properties, such as fill color and line width.\n(The style properties are what I call ", " elsewhere\nin this book; in this section, I am using the term \"attribute\" in its XML sense.)\nAnd there is a ", " attribute that can be used to apply a\n", " to the shape.", "For a detailed example, consider the ", " element, which specifies a rectangle.  \nThe geometry of the rectangle is given by attributes named ", ", ", ", ", "\nand ", " in the usual way.  The default value for ", " and ", " is zero;\nthat is, they are optional, and leaving them out is the same as setting their value to zero.\nThe ", " and the ", " are required attributes.  Their values must be\nnon-negative.  For example, the element", "specifies a rectangle with corner at (0,0), width 3, and height 2, while", "gives a rectangle with corner at (100,200), width 640, and height 480.  (Note, by\nthe way, that the attributes in an XML element can be given in any order.)  The ", "\nelement also has optional attributes ", " and ", " that can be used to make\n\"roundRects,\" with their corners replaced by elliptical arcs.  The values of ", "\nand ", " give the horizontal and vertical radii of the elliptical arcs.", "Style attributes can be added to say how the shape should be stroked and filled.\nThe default is to use a black fill and no stroke.  (More precisely, as we will see later,\nthe default for is for a shape to inherit the values of style attributes from its \nenvironment.  Black fill and no stroke is the initial environment.)  Here are some\ncommon style attributes:", "As an example that uses many of these options, let's make a square is rounded rather than pointed \nat the corners, with size 1, centered\nat the origin, and using a translucent red fill and a gray stroke:", "and a simple outline of a rectangle with no fill:", "The ", " attribute can be used to apply a transform or a series of\ntransforms to a shape.  As an example, we can make a rectangle tilted 30 degrees from\nthe horizontal:", "The value \"rotate(30)\" represents a rotation of 30 degrees (not radians!) about the \norigin, (0,0). The positive direction of rotation, as usual, rotates the positive x-axis in the\ndirection of the positive y-axis.  You can specify a different center of rotation by\nadding arguments to ", ".  For example, to rotate the same rectangle about its\ncenter", "Translation and scaling work as you probably expect, with transform values of\nthe form \"translate(", ")\" and \"scale(", ")\".  There are also\n", " transforms, but they go by the\nnames ", " and ", ", and the argument is a skew angle rather\nthan a shear amount.  For example, the transform \"skewX(45)\" tilts the y-axis\nby 45 degrees and is equivalent to an x-shear with shear factor\u00a01.\n(The function that tilts the y-axis is called ", " because it modifies,\nor skews, the x-coordinates of points while leaving their y-coordinates unchanged.)\nFor example, we can use ", " to tilt a rectangle and make it into a\nparallelogram:", "I used an angle of -30 degrees to make the rectangle tilt to the right\nin the usual pixel coordinate system.", "The value of the ", " attribute can be a list of transforms,\nseparated by spaces or commas.  The transforms are applied to the object, as\nusual, in the opposite of the order in which they are listed. So,", "would first skew the rectangle into a parallelogram, then rotate the parallelogram\nby 45 degrees about the origin, then translate it by 50 units in the y-direction.", "In addition to rectangles, SVG has lines, circles, ellipses, and text as basic\nshapes.  Here are some details.  A ", " element represents a line segement and\nhas geometric attributes ", ", ", ", ", ", and ", " to specify the \ncoordinates of the endpoints of the line segment.  These four attributes have\nzero as default value, which makes it easier to specify horizontal and vertical lines.\nFor example,", "Without the ", " attribute, you wouldn't see the line, since the default\nvalue for ", " is \"none\".", "For a ", " element, the geometric attributes are ", ", ", ", and ", "\ngiving the coordinates of the center of the circle and the radius.  The center coordinates\nhave default values equal to zero.  For an ", " element, the attributes are\n", ", ", ", ", ", and ", ", where ", " and ", " give\nthe radii of the ellipse in the x- and y-directions.", "A ", " element is a little different.  It has attributes ", " and ", ",\nwith default values zero, to specify the location of the basepoint of the text.  However,\nthe text itself is given as the content of the element rather than as an attribute.  That is,\nthe element is divided into a start tag and an end tag, and the text that will appear in\nthe drawing comes between the start and end tags.  For example,", "The usual stroke and fill attributes apply to text, but text has additional style\nattributes.  The ", " attribute specifies the font itself.  Its value\ncan be one of the generic font names \"serif\", \"sans-serif\", \"monospace\", or the name of\na specific font that is available on the system.  The ", " can be a number\ngiving the (approximate) height of the characters in the coordinate system.  (Font size\nis subject to coordinate and modeling transforms like any other length.)  You can get\nbold and italic text by setting ", " equal to \"bold\" and\n", " equal to \"italic\".  Here is an example that uses all of these options,\nand applies some additional styles and a transform for good measure:", "SVG has some nice features for making more complex shapes.  The ", " element\nmakes it easy to create a polygon from a list of coordinate pairs.  For example,", "creates a five-sided polygon with vertices at (0,0), (100,0), (100,75), (50,100), and\n(0,75).  Every pair of numbers in the ", " attribute specifies a vertex.  The numbers\ncan be separated by either spaces or commas.  I've used a mixture of spaces and commas here to\nmake it clear how the numbers pair up.   Of course, you can add the usual style attributes\nfor stroke and fill to the polygon element.  A ", " is similar to a ", ",\nexcept that it leaves out the last line from the final vertex back to the starting vertex.\nThe difference only shows up when a polyline is stroked; a polyline is filled as if the\nmissing side were added.", "The ", " element is much more interesting. In fact, all of the other basic shapes,\nexcept text, could be made using path elements.  A path can consist of line segments,\n", ", and elliptical arcs (although I won't\ndiscuss elliptical arcs here).  The syntax for\nspecifying a path is very succinct, and it has some features that we have not seen before.\nA path element has an attribute named ", " that contains the data for the path.  The\ndata consists of one or more commands, where each command consists of a single letter followed\nby any data necessary for the command.  The moveTo, lineTo, cubic Bezier, and quadratic\nBezier commands that you are already familiar with are coded by the letters M, L, C, and Q.\nThe command for closing a path segment is Z, and it requires no data.\nFor example the path data \"M\u00a010\u00a020\u00a0L\u00a0100\u00a0200\" would draw a line segment\nfrom the point (10,20) to the point (100,200).  You can combine several connected line segments\ninto one L command.  For example, the ", " example given above could be created\nusing the ", " element", "The Z at the end of the data closes the path by adding the final side to the polygon.\n(Note that, as usual, you can use either commas or spaces in the data.)", "The C command takes six numbers as data, to specify the two control points and the final\nendpoint of the cubic Bezier curve segment.  You can also give a multiple of six values to get\na connected sequence of curve segements.  Similarly, the Q command uses four data values to\nspecify the control point and final endpoint of the quadratic Bezier curve segment.\nThe large, curvy, yellow shape shown in the picture earlier in this section was created\nas a path with two line segments and two Bezier curve segments:", "SVG paths add flexibility by defining \"relative\" versions of the path commands,\nwhere the data for the command is given relative to the current position.\nA relative move command, for example, instead of telling ", " to move,\ntells ", " to move from the current position.  The names of the \nrelative versions of the path commands are lower case letters instead of upper case.\n\"M\u00a010,20\" means to move to the point with coordinates (10,20), while\n\"m\u00a010,20\" means to move 10 units horizontally and 20 units vertically\nfrom the current position.  Similarly, if the current position is (", "), then\nthe command \"l\u00a03,5\", where the first character is a lower case L, draws a line from (", ") to\n(", "+3,", ").", "SVG would not be a very interesting language if it could only work with\nindividual simple shapes.  For complex scenes, we want to be able to do\n", ", where objects can be constructed from\nsub-objects, and a transform can be applied to an entire complex object.\nWe need a way to group objects so that they can be treated as a unit.\nFor that, SVG has the ", " element.  The content of a ", "\nelement is a list of shape elements, which can be simple shapes or\nnested ", " elements.", "You can add style and ", " attributes to a ", " element.\nThe main point of grouping is that a group can be treated as a single\nobject.  A ", " attribute in a ", " will transform the\nentire group as a whole.  A style attribute, such as ", " or\n", ", on a ", " element will set a default value \nfor the group, replacing the current default.  Here is an example:", "The nested shapes use fill=\"none\" stroke=\"black\" stroke-width=\"2\" for the\ndefault values of the attributes.  The default can be overridden by specifying\na different value for the element, as is done for the stroke-width of the\n", " element in this example.  Setting transform=\"scale(1,\u22121)\"\nfor the group flips the entire image vertically.  I do this only because\nI am more comfortable working in a coordinate system in which y increases\nfrom bottom-to-top rather than top-to-bottom.  Here is the simple line\ndrawing of a face that is produced by this group:", "\n", "Now, suppose that we want to include multiple copies of an object in\na scene.  It shouldn't be necessary to repeat the code for drawing the object.\nIt would be nice to have something like reusable subroutines.  In fact,\nSVG has something very similar: You can define reusable objects inside a\n", " element.  An object that is defined inside ", " is\nnot added to the scene, but copies of the object can be added to the scene\nwith a single command.  For this to work, the object must have an ", " attribute\nto identify it.  For example, we could define an object that looks like a plus sign:", "A ", " element can then be used to add a copy of the plus sign\nobject to the scene.  The syntax is", "The value of the ", " attribute must be the ", " of the object,\nwith a \"#\" character added at the beginning. (Don't forget the\u00a0#.  If you leave it out,\nthe ", " element will simply be ignored.)  You can add a ", " attribute\nto the ", " element to apply a transformation to the copy of the object.  You can also apply\nstyle attributes, which will be used as default values for the attributes in the copy.  For\nexample, we can draw several plus signs with different transforms and stroke widths:", "Note that we can't change the color of the plus sign, since it already specifies\nits own stroke color.", "An object that has been defined in the ", " section can also be used\nas a sub-object in other object definitions.  This makes it possible to create\na hierarchy with multiple levels.  Here is an example from ", "\nthat defines a \"wheel\" object, then uses two copies of the wheel as sub-objects in a \n\"cart\" object:", "The SVG file goes on to add one copy of the wheel and four copies of the\ncart to the image.  The four carts have different colors and transforms.\nHere is the image:", "\n", "SVG has a number of advanced features that I won't discuss here, but I do want to\nmention one: ", ".  It is possible to animate almost any property\nof an SVG object, including geometry, style, and transforms.  The syntax for animation\nis itself fairly complex, and I will only do a few examples.  But I will tell you enough\nto produce a fairly complex hierarchical animation like the \"cart-and-windmills\"\nexample that was discussed and used as a demo in ", ".\nAn SVG version of that animation can be found in ", ".\nHere is what it looks like, although some web browsers might show it as a static\nimage instead of an animation:", "\n", "Many attributes of a shape element can be animated by adding an ", "\nelement to the content of the shape element.   Here is an example that makes a rectangle\nmove across the image from left to right:", "Note that the ", " is nested inside the ", ".\nThe ", " attribute tells which attribute of the ", "\nis being animated, in this case,\u00a0", ".  The ", " and ", " attributes\nsay that ", " will take on values from 0 to 430.  The ", " attribute is the\n\"duration\", that is, how long the animation lasts; the value \"7s\" means \"7 seconds.\"\nThe attribute ", "=\"indefinite\" means that after the animation completes,\nit will start over, and it will repeat indefinitely, that is, as long as the image is\ndisplayed.  If the ", " attribute is omitted, then after the animation\nruns once, the rectangle will jump back to its original position and remain there.\nIf ", " is replaced by ", "=\"freeze\", then after the animation runs,\nthe rectangle will br frozen in its final position, instead of jumping back to the starting\nposition.  The animation begins when the image first loads.  If you want the animation to\nstart at a later time, you can add a ", " attribute whose value gives the time\nwhen the animation should start, as a number of seconds after the image loads.", "What if we want the rectangle to move back and forth between its initial and final\nposition?  For that, we need something called ", ",\nwhich is an important idea in its own right.  The ", " and ", " attributes\nallow you to specify values only for the beginning and end of the animation.  In a keyframe\nanimation, values are specified at additional times in the middle of the animation.\nFor a keyframe animation in SVG, the ", " and ", " attributes are replaced\nby ", " and ", ".  Here is our moving rectangle example,\nmodified to use keyframes:", "The ", " attribute is a list of numbers, separated by semicolons.\nThe numbers are in the range 0 to 1, and should be in increasing order.  The first number\nshould be 0 and the last number should be 1.  A number specifies a time during the animation,\nas a fraction of the complete animation.  For example, 0.5 is a point half-way through the\nanimation, and 0.75 is three-quarters of the way.  The ", " attribute is a list\nof values, with one value for each key time.  In this case, the value for ", " is\n0 at the start of the animation, 430 half-way through the animation, and 0 again at the\nend of the animation.  Between the key times, the value for ", " is obtained by interpolating\nbetween the values specified for the key times.  The result in this case is that the rectangle\nmoves from left to right during the first half of the animation and then back from right to\nleft in the second half.", "Transforms can also be animated, but you need to use the ", "\ntag instead of ", ", and you need to add a ", " attribute to specify\nwhich transform you are animating, such as \"rotate\" or \"translate\".  Here, for example,\nis a transform animation applied to a group:", "The animation shows a growing \"tree\" made from a green triangle and a brown rectangle.\nIn the animation, the transform goes from ", "(0,0) to ", "(0.4,0.7).\nThe animation starts 3 seconds after the image loads and lasts 15 seconds.  At the end\nof the animation, the tree freezes at its final scale.  The ", " attribute\non the ", " element specifies the scale that is in effect until the animation\nstarts.  (A scale factor of 0 collapses the object to size zero, so that it is invisible.)\nYou can find this example, along with a moving rectangle and a keyframe animation, in \nthe sample file ", ". Here is the\nanimation itself.  To see the growing trees, you might have to reload this page or view\nthe image in a separate window:", "\n", "You can create animated objects in the ", " section of an SVG file,\nand you can apply animation to ", " elements.  This makes it possible\nto create hierarchical animations.  Here is a simple example:", "\n", "The example shows a rotating hexagon with a rotating square at each vertex of the\nhexagon.  The hexagon is constructed from six copies of one object, with a different rotation\napplied to each copy.  (A copy of the basic object is shown in the image to the right of the\nhexagon.)  The square is defined as an animated object with its own rotation.  It is used\nas a sub-object in the hexagon.  The rotation that is applied to the hexagon applies to the\nsquare, on top of its own built-in rotation.  That's what makes this an example of\nhierarchical animation.", "If you look back at the ", " \nexample now, you can probably see how to do the animation.  Don't forget to check out the source code,\nwhich is surprisingly short!"], "chapter_title": "Two-Dimensional Graphics", "id": 2.7}, {"section_title": "Using GLUT and JOGL", "chapter_id": "Chapter 3", "section_id": "Section 3.6", "content": ["OpenGL is an ", " for graphics only, with no support for things like\nwindows or events.  OpenGL depends on external mechanisms to\ncreate the drawing surfaces on which it will draw.  Windowing APIs\nthat support OpenGL often do so as one library among many others that\nare used to produce a complete application.  We will look at\ntwo cross-platform APIs that make it possible to use OpenGL\nin applications, one for C/C++ and one for Java.", "For simple applications written in C or C++, one possible\nwindowing API is ", " (OpenGL Utility Toolkit).  GLUT is a very small\nAPI.  It is used to create windows that serve as\nsimple frames for OpenGL drawing surfaces.  It has support for\nhandling mouse and keyboard events, and it can do basic animation.\nIt does not support controls such as buttons or input fields,\nbut it does allow for a menu that pops up in response to\na mouse action.  You can find information about the GLUT API at", "\n", "\n", "If possible, you should use FreeGLUT, which is compatible with GLUT but has\na few extensions and a fully open source license.   See", "\n", "\n", "\n", " (Java OpenGL) is a collection of classes that make it\npossible to use OpenGL in Java applications.  JOGL is integrated\ninto Swing and AWT, the standard Java graphical user interface APIs.\nWith JOGL, you can create Java GUI components on which\nyou can draw using OpenGL.  These OpenGL components can be\nused in any Java application, in much the same way that you\nwould use a ", "\nor ", " as a drawing surface.\nLike many things Java, JOGL is immensely complicated.  We will use it\nonly in fairly simple applications.\nJOGL is not a standard part of Java.  It's home web site is", "\n", "\n", "This section contains information to get you started using GLUT and JOGL, assuming\nthat you already know how the basics of programming with C and Java.  It also briefly\ndiscusses ", ", a JavaScript library that I have written to simulate the subset\nof OpenGL 1.1 that is used in this book.", "To work with GLUT, you will need\na C compiler and copies of the OpenGL and GLUT (or FreeGLUT)\ndevelopment libraries.  I can't tell you exactly that means on\nyour own computer.  On my computer, which runs Linux Mint, for example,\nthe free C compiler gcc is already available.  To do OpenGL\ndevelopment, I installed several packages, including\n", " and ", ".\n(Mesa is a Linux implementation of OpenGL.)  If ", " contains\na complete C program that uses GLUT, I can compile it using a command such as\n", "The \"-o glutprog\" tells the compiler to use \"glutprog\" as the\nname of its output file, which can then be run as a normal executable file;\nwithout this option, the executable file would be named \"a.out\".\nThe \"-lglut\" and \"-lGL\" options tell the compiler to link the program with the GLUT and OpenGL libraries.\n(The character after the \"-\" is a lower case \"L\".)\nWithout these options, the compiler won't recognize any GLUT or OpenGL functions.  If the program\nalso uses the ", " library, compiling it would require the option \"-lGLU, and if it uses\nthe math library, it would need the option \"-lm\".  If a program requires additional .c files,\nthey should be included as well.  For example, the sample program\n", " depends on ", ", and it\ncan be compiled with the Linux gcc compiler using the command:", "The sample program ", " can be used as a starting\npoint for writing programs that use GLUT.  While it doesn't do anything except open a\nwindow, the program contains the framework needed to do OpenGL drawing, including doing\nanimation, responding to mouse and keyboard events, and setting up a menu.  The source\ncode contains comments that tell you how to use it.", "The GLUT library makes it easy to write basic OpenGL applications in\u00a0C.  GLUT\nuses event-handling functions.  You write functions to handle events that occur\nwhen the display needs to be redrawn or when the user clicks the mouse or presses a key\non the keyboard.", "To use GLUT, you need to include the header file ", " (or ", ")\nat the start of any source code file that uses it, along with the general OpenGL header file,\n", ".  The header files should be installed in a standard location, in a folder named ", ".\nSo, the program usually begins with", "On my computer, saying ", " actually includes the subset\nof FreeGLUT that corresponds to GLUT.  To get access to all of FreeGLUT, I would\nsubstitute ", ".  Depending on the features that it uses,\na program might need other header files, such as ", " \nand ", ".", "The program's ", "() function must contain some code to initialize GLUT, to\ncreate and open a window, and to set up event handling by registering the functions that\nshould be called in response to various events.  After this setup, it must\ncall a function that runs the GLUT event-handling loop.  That function\nwaits for events and processes them by calling the functions that have been registered\nto handle them.  The event loop runs until the program ends, which happens when\nthe user closes the window or when the program calls the standard ", "() function.", "To set up the event-handling functions,\nGLUT uses the fact that in C, it is possible to pass a function name as a parameter\nto another function.  For example, if ", "() is the function that \nshould be called to draw the content of the window, then the\nprogram would use the command", "to install this function as an event handler for\ndisplay events. A display event occurs when the contents of the window need to be redrawn, including\nwhen the window is first opened.\nNote that ", " must have been previously defined, as a function with no parameters:", "Keep in mind that it's not the name of this function that makes it an OpenGL display\nfunction.  It has to be set as the display function by calling ", "(", ").\nAll of the GLUT event-handling functions work in a similar way (except many of them do need\nto have parameters).", "There are a lot of possible event-handling functions, and I will only cover some of\nthem here.  Let's jump right in and look at a possible ", "() routine for a GLUT\nprogram that uses most of the common event handlers:", "The first five lines do some necessary initialization, the next seven lines install event\nhandlers, and the call to ", "() runs the GLUT event loop.  I will discuss all of\nthe functions that are used here.  The first GLUT function call must be ", ",\nwith the parameters as shown.  (Note that ", " and ", "\nrepresent command-line arguments for the program.  Passing them to ", " allows\nit to process certain command-line arguments that are recognized by GLUT.  I won't discuss those\narguments here.)  The functions ", " and ", "\ndo the obvious things; size is given in pixels, and \nwindow position is given in terms of pixel coordinates on the computer\nscreen, with (0,0) at the upper left corner of the screen.  The function ", "\ncreates the window, but note that nothing can happen in that window until ", "\nis called.  Often, an additional, user-defined function is called in ", "() to do\nwhatever initialization of global variables and OpenGL state is required by the program.\nOpenGL initialization can be done after calling ", " and before\ncalling ", ".  Turning to the other functions used in ", "(),", "\n", " \u2014 Must be called to\ndefine some characteristics of the OpenGL drawing context.  The parameter specifies\nfeatures that you would like the OpenGL context to have.  The features are represented by\nconstants that are OR'ed together in the parameter.  ", " says that a depth buffer\nshould be created; without it, the depth test won't work.  If you are doing 2D graphics, you\nwouldn't include this option.  ", " asks for ", ", \nwhich means that drawing is actually done off-screen, and the\noff-screen copy has to copied to the screen to be seen.  The copying is done by\n", ", which ", " be called at the end of the display function.\n(You can use ", " instead of ", " to get ", "; \nin that case, you have to call ", "() at the end of the display function instead\nof ", "().  However, all of the examples in this book use ", ".)", "\n", " \u2014 The display function\nshould contain OpenGL drawing code that can completely redraw the scene.  This is\nsimilar to ", "() in Java.\nThe display function can have any name, but it must be declared as a void\nfunction with no parameters: ", "().", "\n", " \u2014 The reshape function\nis called when the user changes the size of the window.  Its parameters tell the\nnew width and height of the drawing area:", "For example, you might use this method to set up the projection transform, if the\nprojection depends only on the window size.  A reshape function is not required, but\nif one is provided, it should always set the\nOpenGL ", ", which is the part of the window that\nis used for drawing.  Do this by calling", "The viewport is set automatically if no reshape function is specified.", "\n", " \u2014 The keyboard function is\ncalled when the user types a character such as 'b' or 'A' or a space.  It is not called\nfor special keys such as arrow keys that do not produce characters when pressed.\nThe keyboard function has a parameter of type ", " which\nrepresents the character that was typed.  It also has two ", " parameters \nthat give the location of the mouse when the key was pressed, in pixel coordinates\nwith (0,0) at the upper left corner of the display area.  So, the definition of\nthe key function must have the form:", "Whenever you make any changes to the program's data that require the display to be redrawn,\nyou should call ", "().  This is similar to calling ", "() in\nJava.  It is better to call ", "()\nthan to call the display function directly.  (I also note that it's possible to\ncall OpenGL drawing commands directly in the event-handling functions, but it probably only makes\nsense if you are using single buffering; if you do this, call ", "()\nto make sure that the drawing appears on the screen.)", "\n", " \u2014 The \"special\"\nfunction is called when the user presses certain special keys, such as an arrow\nkey or the Home key.  The parameters are an integer code for the key that was pressed, plus the\nmouse position when the key was pressed:", "GLUT has constants to represent the possible key codes, including\n", ", ", ", ", ", and ", "\nfor the arrow keys and ", " for the Home key. For example,\nyou can check whether the user pressed the left arrow key by testing\n", "\u00a0", ".", "\n", " \u2014 The mouse function is\ncalled both when the user presses and when the user releases a button on the mouse, with a parameter to tell\nwhich of these occurred.  The function will generally look like this:", "The first parameter tells which mouse button was pressed or released; its\nvalue is the constant ", " for the left, ", " for the \nmiddle, and ", " for the right mouse button.  The other\ntwo parameters tell the position of the mouse.  The mouse position\nis given in pixel coordinates with (0,0) in the top left corner of the display area and\nwith y increasing from top to bottom.", "\n", " \u2014 The motion function\nis called when the user moves the mouse while dragging, that is, while a mouse button\nis pressed.  After the user presses the mouse in the OpenGL window, this function will\ncontinue to be called even if the mouse moves outside the window, and the mouse\nrelease event will also be sent to the same window.  The function has two parameters\nto specify the new mouse position:", "\n", " \u2014 The idle function is called by the\nGLUT event loop whenever there are no events waiting to be processed.  The\nidle function has no parameters.  It is called as often as possible, not at\nperiodic intervals.  GLUT also has a timer function, which schedules some function to be\ncalled once, after a specified delay.  To set a timer, call", "and define ", " as", "The parameter to ", " when it is called will be the same integer that was passed as\nthe third parameter to ", ".  If you want to use ", "\nfor animation, then ", " should end with another call to ", ".", "A GLUT window does not have a menu bar, but it is possible to add a hidden popup menu to the window.\nThe menu will appear in response to a mouse click on the display.  You can set whether it\nis triggered by the left, middle, or right mouse button.", "A menu is created using the function ", ",\nwhere the parameter is the name of a function that will be called when the user\nselects a command from the menu.  The function must be defined with a parameter of\ntype ", " that identifies the command that was selected:", "Once the menu has been created, commands are added to the menu by calling the function\n", "(", ").  The first parameter is the string that\nwill appear in the menu.  The second is an ", " that identifies the\ncommand; it is the integer that will be passed to the menu-handling function when\nthe user selects the command from the menu.", "Finally, the function ", "(", ") attaches the menu to the\nwindow.  The parameter specifies which mouse button will trigger the menu.  Possible\nvalues are ", ", ", ", and ", ".\nAs far as I can tell, if a mouse click is used to trigger the popup menu, than the same\nmouse click will ", " also produce a call to the mouse-handler function.", "Note that a call to ", " doesn't mention the menu, and a\ncall to ", " doesn't mention either the menu or the window.\nWhen you call ", ", the menu that is created becomes the \"current\nmenu\" in the GLUT state.  When ", " is called, it adds a command\nto the current menu.  When ", " is called, it attaches the current\nmenu to the current window, which was set by a call to ", ".\nAll this is consistent with the OpenGL \"state machine\" philosophy, where functions\nact by modifying the current state.", "As an example, suppose that we want to let the user set the background color for\nthe display.  We need a function to carry out commands that we will add to the menu.  For example,\nwe might define", "We might have another function to create the menu.  This function would be called\nin ", "(), after calling ", ":", "It's possible to have submenus in a menu.  I won't discuss the procedure here, but you can look\nat the sample program ", " for an example of using submenus.", "In addition to window and event handling, GLUT includes some functions for drawing basic 3D shapes\nsuch as spheres, cones, and ", ".  \nIt has two functions for each shape, a \"solid\" version that draws\nthe shape as a solid object, and a ", " version that draws \nsomething that looks like it's made of wire mesh.  (The wireframe is produced by drawing \njust the outlines of the polygons that make up the object.)  For example, the function", "draws a solid sphere with the given radius, centered at the origin.  Remember that this is\njust an approximation of a sphere, made up of polygons.  For the approximation, the sphere is divided by\nlines of longitude, like the slices of an orange, and by lines of latitude, like a stack of disks.\nThe parameters ", " and ", " tell how many subdivisions to use.  Typical values\nare 32 and 16, but the number that you need to get a good approximation for a sphere depends on the\nsize of the sphere on the screen.  The function ", " has the same parameters but\ndraws only the lines of latitude and longitude.  Functions for a cone, a cylinder, \nand a ", " (doughnut) are similar:", "For a torus, the ", " is the size of the doughnut hole.  The function", "draws a cube of a specified size.\nThere are functions for the other regular polyhedra that have no parameters and draw the \nobject at some fixed size:  ", "(), ", "(),\n", "(), and ", "().\nThere is also ", "(", ") that draws a famous object that is often used as an\nexample.  Here's what the teapot looks like:", "\n", "Wireframe versions of all of the shapes are also available.  For example,\n", "(", ") draws a wireframe teapot.  Note that \nGLUT shapes come with ", " that\nare required for lighting calculations.  However, except for the teapot, they do\nnot come with ", ", which are required for applying\ntextures to objects. ", "GLUT also includes some limited support for drawing text in an OpenGL drawing\ncontext.  I won't discuss that possibility here.  You can check the API\ndocumentation if you are interested, and you can find an example in the\nsample program ", ".", "JOGL is a framework for using OpenGL in Java programs.  It is a large and complex API that\nsupports all versions of OpenGL, but it is fairly easy to use for basic applications.\nIn my examples and discussion, I will be using JOGL\u00a02.3, the latest version\nas of March, 2015.  Note that version 2.3 is not fully compatible with earlier versions.\n(Hopefully, later versions will remain compatible with 2.3.)", "The sample program ", " can be used as a starting\npoint for writing OpenGL programs using JOGL. While it doesn't do anything except open a\nwindow, the program contains the framework needed to do OpenGL drawing, including doing\nanimation, responding to mouse and keyboard events, and setting up a menu.  The source\ncode contains comments that tell you how to use it.", "To use JOGL, you will need two .jar files containing the Java classes for JOGL:\n", " and ", ".  In addition, you will\nneed two native library files.  A native library is\na collection of routines that can be called from Java but are not written in Java.  Routines\nin a native library will work on only kind of computer; you need a different native library\nfor each type of computer on which your program is to be used.  The native libraries for\nJOGL are stored in additional .jar files, which are available in several versions for\ndifferent computers.  For example, for 64-bit Linux, you need\n", " and ", ".\nFor 32-bit Linux, the files are\n", " and ", ".\nIt is unfortunate that there are different versions for 64 and 32 bit operating systems, since\nmany people don't know which they are using.  However, if you are in doubt, you can get\nboth; JOGL will figure out which of the two to use.\nFor Mac\u00a0OS, you need\n", " and ", ".\nFor 64-bit Windows, the files are\n", " and ", ".", "You can get the jar files from the JOGL web site, ", ".\nI extracted them from the very large (54 megabyte) archive file", "\n\n", "\n\n", "I have also made the necessary files available on my own web site, at", "\n\n", "\n\n", "JOGL is open-source, and the files are freely redistributable, according to their\n", ".", "To do JOGL development, you should create a directory somewhere on your computer to hold the jar\nfiles.  Place the two JOGL jar files in that directory, along with the two native library jar files\nfor your platform.  (Having extra native library jar files doesn't hurt, as long as you have\nthe ones that you need.)", "It is possible to do JOGL development on the command line.  You have to tell the\n", " command where to find the two JOGL jar files. You do that in the\nclasspath (\"-cp\") option to the ", " command.  For example, if you are working\nin Linux or MacOS, and if the jar\nfiles happen to be in the same directory where you are working, you might say:", "It's similar for Windows, except that the classpath uses a \";\" instead of a \":\" to\nseparate the items in the list:", "There is an essential period at the end of the classpath, which makes it possible for Java to\nfind .java files in the current directory.\nIf the jar files are not in the current directory,\nyou can use full path names or relative path names to the files.  For example,", "Running a program with the ", " command is exactly similar. For example:", "Note that you don't have to explicitly reference the native library jar files.\nThey just have to be in the same directory with the JOGL jar files.", "I do most of my Java development using the Eclipse IDE (", ").\nTo do development with JOGL in Eclipse, you will have to configure Eclipse\nwith information about the jar files.  To do that, start up Eclipse.  You want to\ncreate a \"User Library\" to contain the jar files:\nOpen the Eclipse Preferences window, and select \"Java\" / \"Build\u00a0Path\" / \"User\u00a0Libraries\"\non the left.  Click the \"New\" button on the right.  Enter \"JOGL\" (or any name you like) as the\nname of the user library.  Make sure that the new user library is selected in the\nlist of libraries, then click the \"Add External Jars\" button.  In the file selection box,\nnavigate to the directory that contains the JOGL jar files, and select the two jar files that\nare needed for JOGL, ", " and ", ".  \n(Again, you do not need to add the native libraries; they just need to be in the same directory\nas the JOGL jar files.)  Click \"Open.\"  The selected\njars will be added to the user library. (You could also add them one at a time, if you don't\nknow how to select multiple files.)  It should\nlook something like this:", "\n", "Click \"OK.\"  The user library has been created. You will only have to do this\nonce, and then you can use it in all of your JOGL projects.", "Now, to use OpenGL in a project, create a new Java project as usual in Eclipse.\nRight-click the project in the Project Explorer view, and select \"Build\u00a0Path\" /\n\"Configure\u00a0Build\u00a0Path\" from the menu.  You will see the project Properties\ndialog, with \"Build Path\" selected on the left.  (You can also access this through the\n\"Properties\" command in the \"Project\" menu.)  Select \"Libraries\" at the top of the\nwindow, and then click the \"Add\u00a0Library\" button.  In the popup window, select \"User\u00a0Library\"\nand click \"Next.\"  In the next window, select your JOGL User Library and click \"Finish.\"\nFinally, click \"OK\" in the main Properties window.  Your project should now be set up\nto do JOGL development.  You should see the JOGL User Library listed as part of the\nproject in the Project Explorer.  Any time you want to start a new JOGL project, you can go through\nthe same setup to add the JOGL User Library to the build path in the project.", "With all that setup out of the way, it's time to talk about actually\nwriting OpenGL programs with Java.  With JOGL,\nwe don't have to talk about mouse and keyboard handling or animation, since that can be done\nin the same way as in any Java program.  You will only need to know about a few classes from\nthe JOGL API.", "First, you need a GUI component on which you can draw using OpenGL.  For that, you\ncan use ", ", which is a subclass of ", ".\n(", " is for use in programs based on the Swing API; an alternative\nis ", ", which is a subclass of the older AWT class\n", ".)  The class is defined in the package ", ".\nAll of the other classes that we will need for basic OpenGL programming \nare in the package ", ".", "JOGL uses Java's event framework to manage OpenGL drawing contexts, and it defines a\ncustom event listener interface, ", ", to manage\nOpenGL events.  To draw on a ", " with OpenGL, you need to\ncreate an object that implements the ", " interface, and\nregister that listener with your ", ".  The ", "\ninterface defines the following methods:\n", "The ", " parameter in these methods tells which OpenGL drawing surface\nis involved.  It will be a reference to the ", ".\n(", "  is an interface that is implemented by\n", " and other OpenGL drawing surfaces.)\nThe ", "() method is a place to do OpenGL initialization.  (According to the\ndocumentation, it can actually be called several times, if the OpenGL context\nneeds to be recreated for some reason. So ", "() should not be used to\ndo initialization that shouldn't be done more than once.) The \n", "() method will be called to give you a chance to\ndo any cleanup before the OpenGL drawing context is destroyed.\nThe ", "() method is called when the window first opens and\nwhenever the size of the ", " changes.\nOpenGL's ", "() function is called automatically before ", "()\nis called, so you won't need to do it yourself.  Usually, you won't need to write\nany code in ", "() or ", "(), but they have to be there to\nsatisfy the definition of the ", " interface.", "The ", "() method is where the actual drawing is done and where you\nwill do most of your work.  It should ordinarily clear the drawing area and completely redraw the scene.\nTake a minute to study an outline for a minimal JOGL program.  It creates a\n", " which also serves as the\n", ":", "At this point, the only other thing you need to know is how to use OpenGL\nfunctions in the program.  In JOGL, the OpenGL\u00a01.1 functions are collected into\nan object of type ", ".  (There are different classes\nfor different versions of OpenGL;  ", " contains\nOpenGL\u00a01.1 functionality, along with later versions that are compatible with 1.1.)\nAn object of type ", " is an OpenGL graphics context,\nin the same way that an object of type ", "\nis a graphics context for ordinary Java 2D drawing.  The statement\n", "in the above program obtains the drawing context for\nthe ", ", that is, for the\n", " in that program.  The name of the\nvariable could, of course, be anything, but ", " or ", " is conventional.", "For the most part, using OpenGL functions in JOGL is the same as in C,\nexcept that the functions are now methods in the object ", ".  For example,\na call to ", "(", ") becomes", "The redundant \"gl.gl\" is a little annoying, but you get used to it.  OpenGL constants\nsuch as ", " are static members of ", ", so that, for\nexample, ", " becomes ", " in JOGL.\nParameter lists for OpenGL functions\nare the same as in the C API in most cases.  One exception is for functions such as ", "()\nthat take an array/pointer parameter in C.  In JOGL, the parameter becomes an ordinary\nJava array, and an extra integer parameter is added to give the position of the data in\nthe array.  Here, for example, is how one might draw a triangle in JOGL, with all the\nvertex coordinates in one array:", "The biggest change in the JOGL API is the use of ", "\ninstead of arrays in functions such as ", ".  This is discussed\nin ", ".  We will see in ", " that texture images also get special\ntreatment in JOGL.", "The JOGL API includes a class named ", " that makes GLUT's\nshape-drawing functions available in Java.  (Since you don't need GLUT's window or event functions\nin Java, only the shape functions are included.)  Class ", "\nis defined in the package ", ".\nTo draw shapes using this class, you need\nto create an object of type GLUT.  It's only necessary to make one of these for use in a program:", "The methods in this object include all the shape-drawing functions from the GLUT C API,\nwith the same names and parameters.  For example:", "(I don't know why these are instance methods in an object rather than\nstatic methods in a class; logically, there is no need for the object.)", "The GLU library is available through the class ", ",\n and it works similarly to GLUT.   That is, you have to create an object of type\n ", ", and the GLU functions will be available as methods\n in that object.  We have encountered GLU only for the functions ", "\n and ", ", which are discussed in ", ".\n For example,", "The JavaScript library ", " was written to accompany and support this textbook.\nIt implements the subset of OpenGL 1.1 that is discussed in ", " and\n", ", except for display lists (", ").\nIt is used in the demos that appear in\nthose chapters.  Many of the sample programs that are discussed in those chapters are available\nin JavaScript versions that use glsim.js.", "If you would like to experiment with OpenGL 1.1, \nbut don't want to go through the trouble of setting up a C or Java environment that supports \nOpenGL programming, you can consider writing your programs as web pages using glsim.js.\nNote that glsim is meant for experimentation and practice only, not for serious applications.", "The OpenGL API that is implemented by glsim.js is essentially the same as the C API, although \nsome of the details of semantics are different.  Of course the techniques for creating a\ndrawing surface and an OpenGL drawing context are specific to JavaScript and differ from\nthose used in GLUT or JOGL.", "To use glsim.js, you need to create an ", " document with a <canvas> element\nto serve as the drawing surface.  The HTML file has to import the script; if glsim.js is in the\nsame directory as the HTML file, you can do that with", "To create the OpenGL drawing context, use the JavaScript command", "where ", " is either a string giving the ", " of the <canvas> element or\nis the JavaScript ", " object corresponding to the <canvas> element. Once you\nhave created the drawing context in this way, any OpenGL commands that you give will apply to\nthe canvas.  To run the program, you just need to open the HTML document in a web browser that\nsupports ", ".", "The easiest way to get started programming is to modify a program that already exists.\nThe sample program ", ", from ", "\nis a very minimal example of using glsim.js.\nThe sample web page ", " can be used as a starting\npoint for writing longer programs that use glsim.js.  It provides a framework for doing OpenGL drawing,\nwith support for animation and mouse and keyboard events.  The code contains comments that tell \nyou how to use it.  Some documentation for the glsim.js library can be found in\n", "."], "chapter_title": "OpenGL 1.1: Geometry", "id": 3.6}, {"section_title": "Lights, Camera, Action", "chapter_id": "Chapter 4", "section_id": "Section 4.4", "content": ["A scene in computer graphics can be a complex collection of objects, each with\nits own ", ".  In ", ",\nwe saw how a ", " can be used to organize all the objects in a 2D\nscene.  ", " a scene means traversing the\nscene graph, rendering each object in the graph as it is encountered.\nFor 3D graphics, scene graphs must deal with a larger variety of objects,\nattributes, and transforms.  For example, it is often useful to consider lights\nand cameras to be objects and to be able to include them in scene graphs.  In this\nsection, we consider scene graphs in 3D, and how to treat cameras and lights\nas objects.", "When designing scene graphs, there are many options to consider.  For example,\nshould transforms be properties of object nodes, or should there be separate nodes\nto represent transforms?  The same question can be asked about attributes.\nAnother question is whether an attribute value should apply only to the node\nof which it is a property, or should it be inherited by the children of that node?", "A fundamental choice is the shape of the graph.  In general, a scene graph can\nbe a ", ", or \"dag,\" which is a tree-like structure except\nthat a node can have several parents in the graph.  The scene graphs in\n", " were dags.  This has the advantage that a\nsingle node in the graph can represent several objects in the scene, since in a\ndag, a node can be encountered several times as the graph is traversed.  On the other\nhand, representing several objects with one scene graph node can lead to a lack of flexibility,\nsince those objects will all have the same value for any property encoded in\nthe node.  So, in some applications, scene graphs are required to be trees.  \nIn a tree, each node has a unique parent, and the node will be encountered only\nonce as the tree in traversed.  The distinction between trees and dags will show\nup when we discuss camera nodes in scene graphs.", "We have seen how the functions ", " and ", " are used\nto manipulate the transform stack.  These functions are useful when traversing a\nscene graph: When a node that contains a transform is encountered during a traversal\nof the graph, ", " can be called before applying the transform.  Then, after the\nnode and its descendants have been rendered, ", " is called to restore the\nprevious modelview transformation.", "Something similar can be done for attributes such as color and material, if it is assumed \nthat an attribute value in a scene graph node should be inherited as the default value of\nthat attribute for children of the node.  OpenGL 1.1 maintains an attribute stack, which is\nmanipulated using the functions ", " and ", ".  In addition\nto object attributes like the current color, the attribute stack can store global\nattributes like the global ambient color and the enabled state of the depth test.\nSince there are so many possible attributes, ", " does not simply\nsave the value of every attribute.  Instead, it saves a subset of the\npossible attributes.  The subset that is to be saved is specified as a parameter to\nthe function.  For example, the command", "will save a copy of each of the OpenGL state variables that can be enabled or\ndisabled.  This includes the current state of ", ", ", ",\n", ", and others.  Similarly,", "saves a copy of the current color, normal vector, and texture coordinates.  And", "saves attributes relevant to lighting such as the values of material properties and light properties,\nthe global ambient color, color material settings, and the enabled state for lighting and each of\nthe individual lights.  Other constants can be used to save other sets of attributes; see the\nOpenGL documentation for details.  It is possible to OR together several constants to combine\nsets of attributes.  For example,", "will save the attributes in both the ", " set and in the\n", " set.", "Calling ", "() will restore all the values that were saved by the\ncorresponding call to ", ".  There is no need for a parameter to\n", ", since the set of attributes that are restored is determined\nby the parameter that was passed to ", ".", "It should be easy to see how ", " and ", " can be used\nwhile traversing a scene graph:  When processing a node, before changing attribute values,\ncall ", " to save a copy of the relevant set or sets of attributes.\nRender the node and its descendants. Then call ", " to restore the\nsaved values.  This limits the effect of the changes so that they apply only to the node and\nits descendants.", "There is an alternative way to save and restore values.  OpenGL has a variety of \"get\" functions\nfor reading the values of various state variables.  I will discuss just some of them here.\nFor example,", "retrieves the current color value, as set by ", ".  The ", " parameter\nshould be an array of ", ", whose length is at least four.  The RGBA color components\nof the current color will be stored in the array.  Note that, later, you can simply call\n", "(", ") to restore the color.  The same function can be used\nwith different first parameters to read the values of different floating-point state variables.\nTo find the current value of the ", ", use", "This will set ", "[0] and ", "[1] to be the ", " and ", " coordinates\nof the lower left corner of the current viewport, ", "[2] to be its width, and ", "[3]\nto be its height. To read the current values of material properties, use", "The ", " must be ", " or ", ".  The property must be\n", ", ", ", ", ", ", ", or ", ".\nThe current value of the property will be stored in ", ", which must be of length at least\nfour for the color properties, or length at least one for ", ".  There is\na similar command, ", ", for reading properties of lights.", "Finally, I will mention ", "(", "), which can be used to check the\nenabled/disabled status of state variables such as ", " and ", ".\nThe parameter should be the constant that identifies the state variable.  The function returns 0 if the state\nvariable is disabled and 1 if it is enabled.  For example, ", "(", ")\ntests whether lighting is enabled.  Suppose that a node in a scene graph has an attribute\n", " to tell whether that node (and its descendants) should be rendered with lighting\nenabled.  Then the code for rendering a node might include something like this:", "Since ", " can be used to push large\ngroups of attribute values, you might think that it would\nbe more efficient to use ", " and the ", " family of commands\nto read the values of just those state variables that you are \nplanning to modify.  However, recall that OpenGL can queue a number\nof commands into a batch to be sent to the graphics card, and those commands\ncan be executed by the ", " at the same time that your program\ncontinues to run.  A ", " command can require your \nprogram to communicate with the graphics card and wait for the response.\nThis means that any pending OpenGL commands will have to be sent to the\ngraphics card and executed before the ", " command can complete.\nThis is the kind of thing that can hurt performance.  \nIn contrast, calls to ", " and ", " can\nbe queued with other OpenGL commands and sent to the graphics\ncard in batches, where they can be executed efficiently by\nthe graphics hardware.  In fact, you should generally prefer\nusing ", "/", " instead of a\n", " command when possible.", "Let's turn to another aspect of modeling.  Suppose that we want to implement a\nviewer that can be moved around in the world like other objects.  Sometimes, such\na viewer is thought of as a moving camera.  The camera is used to take pictures of\nthe scene.  We want to be able to apply transformations\nto a camera just as we apply transformations to other objects.  The position\nand orientation of the camera determine what should be visible when the scene is \nrendered.  And the \"size\" of the camera, which can be affected by a scaling transformation,\ndetermines how large a field of view it has.   But a camera is not\njust another object.  A camera really represents the viewing transformation that\nwe want to use.  Recall that modeling and viewing transformations have opposite effects:\nMoving objects to the right with a modeling transform is equivalent to moving the\nviewer to the left with a viewing transformation.  (See ", ".)\nTo apply a modeling transformation to the camera, we\nreally want to apply a viewing transformation to the scene as a whole, and that viewing transformation\nis the ", " of the camera's modeling transformation.", "The following illustration shows a scene viewed from a moving camera.  The camera starts\nin the default viewing position, at the origin, looking in the direction of the negative ", "-axis.\nThis corresponds to using the identity as the viewing transform.  For the second image,\nthe camera has moved forward by ten units.  This would correspond to applying the modeling\ntransformation ", "(0,0,\u221210) to the camera (since it is moving in the negative\n", "-direction).  But to implement this movement as a change of view, \nwe want to apply the inverse operation as a viewing transformation.  So, the viewing\ntransform that we actually apply is ", "(0,0,10).  This can be seen, \nif you like, as a modeling transformation\nthat is applied to all the ", " objects in the scene:  Moving the camera ten units in\none direction is equivalent to moving all the other objects 10 units in the opposite direction.", "\n", "For the third image, the camera has rotated in place by 21 degrees to the right\u2014a 21-degree\nclockwise rotation about the ", "-axis\u2014", " it has been translated.  This can be \nimplemented by the transformation ", "(21,0,1,0)\u2014a 21-degree counterclockwise\nrotation about the ", "-axis\u2014applied ", " the translation. Remember that the\ninverse of a composition of transformations is the composition of their inverses, in the opposite\norder.  Mathematically, using ", " to represent the inverse of a\ntransformation ", ", we have that \n", " for\ntwo transformations ", " and ", ".", "The images in the illustration are from the following demo.  The demo lets you move around in a scene.  More accurately, of course, it \nlets you change the viewing transformation to see the scene from different viewpoints.", "\n", "\n", "When using scene graphs, it can be useful to include a camera object in the graph.  That is,\nwe want to be able to include a node in the graph that represents the camera, and we want to\nbe able to use the camera to view the scene.  It can even be useful to have several cameras\nin the scene, providing alternative points of view.  To implement this, we need to be able\nto render a scene from the point of view of a given camera.  From the previous discussion,\nwe know that in order to do that, we need to use a viewing transformation that is the\ninverse of the modeling transformation that is applied to the camera object.\nThe viewing transform must be applied before any of the objects in the scene are rendered.", "When a scene graph is traversed, a modeling transformation can be applied at any node.\nThe modeling transform that is in effect when a given node is encountered is the composition\nof all the transforms that were applied at nodes along the path that led to given node.\nHowever, if the node is a camera node, we don't want to apply that modeling transform;\nwe want to apply its inverse as a viewing transform.  To get the inverse, we can\nstart at the camera node and follow the path backwards, applying the inverse of\nthe modeling transform at each node.", "\n", "To easily implement this, we can add \"parent pointers\" to the scene graph data structure.  \nA parent pointer for a node is a link to the parent of that node in the graph. Note that this only works\nif the graph is a tree; in a tree, each node has a unique parent, but that is not true in a general\ndirected acyclic graph.  It is possible to move up the tree by following parent pointers.", "We this in mind, the algorithm for rendering the scene from the point of view of a camera\ngoes as follows: Set the modelview transform to be the identity, by calling ", "().\nStart at the camera node, and follow parent pointers until you reach the root of the tree.\nAt each node, apply the ", " of any modeling transformation in that node.\n(For example, if the modeling transform is translation by (a,b,c), call\n", "(", ").)  Upon reaching the root, the viewing\ntransform corresponding to the camera has been established.  Now, traverse the scene graph\nto render the scene as usual.  During this traversal, camera nodes should be ignored.", "Note that a camera can be attached to an object, in the sense that the camera and the object\nare both subject to the same modeling transformation and so move together as a unit.\nIn modeling terms, the camera and the object\nare sub-objects in a complex object.  For example, a camera might be attached\nto a car to show the view through the windshield of that car.  If the car moves, because its\nmodeling transformation changes, the camera will move along with it.  ", "It can also be useful to think of lights as objects, even as part of a complex object.\nSuppose that a scene includes a model\nof a lamp.  The lamp model would include some geometry to make it visible, but if it\nis going to cast light on other objects in the scene, it also has\nto include a source of light.  This means that the lamp is a complex\nobject made up of an OpenGL light source plus some geometric objects.\nAny modeling transformation that is applied to the lamp should\naffect the light source as well as the geometry.  In terms of the\nscene graph, the light is represented by a node in the graph,\nand it is affected by modeling transformations in the same\nway as other objects in the scene graph.  You can even have\nanimated lights\u2014or animated objects that include lights\nas sub-objects, such as the headlights on a car.", "Recall from ", " that a light source is subject to the\nmodelview transform that is in effect at the time the position of the\nlight source is set by ", ".  If the light is represented as a node in\na scene graph, then the modelview transform that we need is the one that\nis in effect when that node is encountered during a traversal of the scene\ngraph.  So, it seems like we should just traverse the graph and set the position\nof the light when we encounter it during the traversal.", "But there is a problem:  Before any geometry is rendered,\nall the light sources that might affect that geometry must already be\nconfigured and enabled.  In particular, the lights' positions must be set\nbefore rendering any geometry.  This means that you can't simply set the\nposition of light sources in the scene graph as you traverse the graph in the\nusual way.  If you do that, objects that are drawn before the\nlight is encountered won't be properly illuminated by the\nlight.  Similarly,\nif the light node contains values for any other properties of\nthe light, including the enabled/disabled state of the light,\nthose properties must be set before rendering any geometry.", "One solution is to do two traversals of the scene graph, the first\nto set up the lights and the second to draw the geometry.  Since\nlights are affected by the modelview transformation, you have to\nset up the modeling transform during the first traversal\nin exactly the same way that you do in the second traversal.\nWhen you encounter the lights during the first traversal,\nyou need to set the position of the light, since setting the\nposition is what triggers the application of the current modelview\ntransformation to the light.  You also need to set any other\nproperties of the light.  During the first traversal, geometric\nobjects in the scene graph are ignored.  During the second traversal, when\ngeometry is being rendered, light nodes can be ignored."], "chapter_title": "OpenGL 1.1: Light and Material", "id": 4.4}]