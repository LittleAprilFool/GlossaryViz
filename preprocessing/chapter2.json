[{"section_title": "null", "chapter_id": "Chapter 2", "section_id": "Section 2.0", "content": ["With this chapter, we begin our study of computer graphics by looking at the two-dimensional case.\nThings are simpler, and a lot easier to visualize, in 2D than in 3D, but most of\nthe ideas that are covered in this chapter will also be very relevant to 3D.", "The chapter begins with four sections that examine 2D graphics in a general way,\nwithout tying it to a particular programming language or graphics API.  The coding\nexamples in these sections are written in pseudocode that should make sense to\nanyone with enough programming background to be reading this book.\nIn the next three sections, we will take quick looks at 2D graphics in three\nparticular languages: Java with ", ",\nJavaScript with HTML ", " graphics, and SVG.  We will see how these\nlanguages use many of the general ideas from earlier in the chapter."], "chapter_title": "Two-Dimensional Graphics", "id": 2.0}, {"section_title": "null", "chapter_id": "Chapter 1", "section_id": "Section 1.0", "content": ["The term \"computer graphics\" refers to anything involved in the creation or\nmanipulation of images on computer, including animated images.  It is a very\nbroad field, and one in which changes and advances seem to come at a dizzying pace.\nIt can be difficult for a beginner to know where to start.  However, there is\na core of fundamental ideas that are part of the foundation of most applications\nof computer graphics.  This book attempts to cover those foundational ideas, or\nat least as many of them as will fit into a one-semester college-level course.\nWhile it is not possible to cover the entire field in a first course\u2014or even a large\npart of it\u2014this should be a good place to start.", "This short chapter provides an overview and introduction to the material\nthat will be covered in the rest of the book, without going into a lot of detail."], "chapter_title": "Introduction", "id": 1.0}, {"section_title": "Transforms", "chapter_id": "Chapter 2", "section_id": "Section 2.3", "content": ["In ", ", we discussed ", "\nand how it is possible to transform coordinates from one coordinate system to another.  In this section,\nwe'll look at that idea a little more closely, and also look at how \n", " can\nbe used to place graphics objects into a coordinate system.", "In a typical application, we have a rectangle made of pixels, with its natural pixel coordinates, \nwhere an image will be displayed.  This rectangle will be called the ", ".\nWe also have a set of geometric objects that are defined in a possibly different coordinate system,\ngenerally one that uses real-number coordinates rather than integers.  These objects make up the\n\"scene\" or \"world\" that we want to view, and the coordinates that we use to define the scene\nare called ", ".", "For 2D graphics, the world\nlies in a plane.  It's not possible to show a picture of the entire infinite plane.  We need to pick some rectangular\narea in the plane to display in the image.  Let's call that rectangular area the ", ",\nor view window.  A coordinate transform is used to map the window to the viewport.", "\n", "In this illustration, ", " represents the coordinate transformation.  ", "\u00a0is a function that\ntakes world coordinates (", ",", ") in some window and maps them to pixel coordinates ", "(", ",", ")\nin the viewport.  (I've drawn the viewport and window with different sizes to emphasize that they\nare not the same thing, even though they show the same objects, but in fact they don't even exist in\nthe same space, so it doesn't really make sense to compare their sizes.) In this example, as you\ncan check,", "Look at the rectangle with corners at (-1,2) and (3,-1) in the window. When this rectangle\nis displayed in the viewport, it is displayed as the\nrectangle with corners ", "(-1,2) and ", "(3,-1). In this example,\n", "(-1,2)\u00a0=\u00a0(300,100) and ", "(3,-1)\u00a0=\u00a0(700,400).", "We use coordinate transformations in this way because it allows us to choose a world\ncoordinate system that is natural for describing the scene that we want to display, and it\nis easier to do that than to work directly with viewport coordinates.\nAlong the same lines, suppose that we want to define some complex object, and suppose that there will be several\ncopies of that object in our scene.  Or maybe we are making an animation, and we would like the\nobject to have different positions in different frames.  We would like to choose\nsome convenient coordinate system and use it to define the object once and for all.\nThe coordinates that we use to define an object are called ", "\nfor the object.  When we want to place the object into a scene, we need to transform\nthe object coordinates that we used to define the object into the world coordinate system\nthat we are using for the scene.  The transformation that we need is called a\n", ".  This picture illustrates an object defined\nin its own object coordinate system and then mapped by three different modeling transformations\ninto the world coordinate system:", "\n", "Remember that in order to view the scene, there will be another transformation that maps the object\nfrom a view window in world coordinates into the viewport.", "Now, keep in mind\nthat the choice of a view window tells which part of the scene is shown in the image.  Moving,\nresizing, or even rotating the window will give a different view of the scene.  Suppose we make\nseveral images of the same car:", "\n", "What happened between making the top image in this illustration and making the image on the bottom left?\nIn fact, there are two possibilities:  Either the car was moved to the ", ", or the view window that\ndefines the scene was moved to the ", ".  This is important, so be sure you understand it.\n(Try it with your cell phone camera. Aim it at some objects, take a step to the left, and notice\nwhat happens to the objects in the camera's viewfinder: They move to the right  in the picture!)\nSimilarly, what happens between the top picture and the middle picture on the bottom?  Either\nthe car rotated ", ", or the window was rotated ", ".  (Again, try it with a\ncamera\u2014you might want to take two actual photos so that you can compare them.)  Finally,\nthe change from the top picture to the one on the bottom right could happen because the car got\n", " or because the window got ", ".  (On your camera, a bigger window means that\nyou are seeing a larger field of view, and you can get that by applying a zoom to the camera or by\nbacking up away from the objects that you are viewing.)", "There is an important general idea here.  When we modify the view window, we change the\ncoordinate system that is applied to the viewport.  But in fact, this is the same as leaving\nthat coordinate system in place and moving the objects in the scene instead.  \nExcept that to get the same effect\nin the final image, you  have to apply the opposite transformation to the objects (for example,\nmoving the window to \nthe ", " is equivalent to moving the objects to the ", ").  So, there is\nno essential distinction between transforming the window and transforming the object.  Mathematically,\nyou specify a ", " by giving coordinates in some natural coordinate system, \nand the computer applies a sequence of transformations to those coordinates to produce, in the end,\nthe coordinates that are used to actually draw the primitive in the image.  You will think of some of\nthose transformations as modeling transforms and some as coordinate transforms, but to the computer,\nit's all the same.", "\nHere is a live demo that can help you to understand the equivalence between modeling transformations\nand viewport transformations.  The sliders control objects applied to the objects in the picture.\nIn the lower section of the demo, you see a larger view in which the viewport for the upper\nimage is represented as a translucent black rectangle.\n\nRead the help text in the demo for more information.\n", "\n", "\n", "We will return to this idea several times later in the book, but in any case, you can see that\n", " are a central concept in computer \ngraphics.  Let's look at some basic types of transformation in more detail.  The transforms\nwe will use in 2D graphics can be written in the form", "where (", ",", ") represents the coordinates of some point before the transformation\nis applied, and (", ",", ") are the transformed coordinates.  The transform is\ndefined by the six constants ", ", ", ", ", ", ", ", ", ", and ", ".  Note\nthat this can be written as a function ", ", where", "A transformation of this form is called an ", ".  An affine\ntransform has the property that, when it is applied to two parallel lines, the transformed \nlines will also be parallel.  Also, if you follow one affine transform by another affine\ntransform, the result is again an affine transform.", "A ", " transform simply moves every point by a certain amount \nhorizontally and a certain amount vertically.  If (", ",", ") is the \noriginal point and (", ",", ") is the transformed point, then the formula for a translation is", "where ", " is the number of units by which the point is moved horizontally and ", " \nis the amount by which it is moved vertically.\n(Thus for a translation, ", " = ", " = 1, and ", " = ", " = 0 in the\ngeneral formula for an affine transform.)\nA 2D graphics system will typically have a function such as", "to apply a translate transformation.  The translation would apply to everything that is\ndrawn ", " the command is given.  That is,  for all\nsubsequent drawing operations, ", " would be added to the x-coordinate and ", " would\nbe added to the y-coordinate.  Let's look at an example.  Suppose that you draw\nan \"F\" using coordinates in which the \"F\" is centered at (0,0).  \nIf you say ", "(4,2) ", " drawing the \"F\", then every point of the \"F\" \nwill be moved horizontally by 4 units and vertically by 2 units before the coordinates are\nactually used, so that after the translation, the \"F\" will be centered at (4,2):\n", "\n", "The light gray \"F\" in this picture shows what would be drawn without the translation; the\ndark red \"F\" shows the same \"F\" drawn after applying a translation by (4,2).  The top arrow shows\nthat the upper left corner of the \"F\" has been moved over 4 units and up 2 units.  Every point\nin the \"F\" is subjected to the same displacement.  Note that in my examples, I am assuming that\nthe y-coordinate increases from bottom to top.  That is, the y-axis points up.", "Remember that when you give the command ", "(", ",", "), the translation applies\nto ", " the drawing that you do after that, not just to the next shape that you draw.\nIf you apply another transformation after the translation, the second transform will not\nreplace the translation.  It will be combined with the translation, so that subsequent drawing\nwill be affected by the combined transformation.  For example, if you combine\n", "(4,2) with ", "(-1,5), the result is the same as a single\ntranslation, ", "(3,7).  This is an important point, and there will be a lot more to say about it later.", "Also remember that you don't compute coordinate transformations yourself.  You just specify the\noriginal coordinates for the object (that is, the object coordinates), and you specify the\ntransform or transforms that are to be applied. The computer takes care of applying the\ntransformation to the coordinates.  You don't even need to know the equations that are used\nfor the transformation; you just need to understand what it does geometrically.", "A ", " transform, for our purposes here, rotates each point about the origin, (0,0).\nEvery point is rotated through the same\nangle, called the angle of rotation.  For this purpose, angles can be measured either\nin degrees or in radians.  (The 2D graphics ", " that we will look at\nlater in this chapter use radians, but OpenGL uses degrees.)\nA rotation with a positive angle rotates objects in the direction from the positive x-axis towards the positive y-axis.  \nThis is counterclockwise in a coordinate system where the y-axis points up, \nas it does in my examples here, but it is\nclockwise in the usual pixel coordinates, where the y-axis points down rather than up.\nAlthough it is not obvious, when rotation through\nan angle of ", " radians about the origin is applied to the point (", ",", "),\nthen the resulting point (", ",", ") is given by\n", "That is, in the general formula for an affine transform, ", " = ", " = 0,\n", " = ", " = cos(", "), ", " = -sin(", "), and ", " = sin(", ").\nHere is a picture that illustrates a rotation about the origin by the angle  negative 135 degrees:\n", "\n", "Again, the light gray \"F\" is the original shape, and the dark red \"F\" is the shape that\nresults if you apply the rotation.  The arrow shows how the upper left corner of the original \"F\"\nhas been moved.", "A 2D graphics API would typically have a command ", "(", ") to apply a rotation.\nThe command is used ", " drawing the objects to which the rotation applies.", "We are now in a position to see what can happen when you\ncombine two transformations.  Suppose that before drawing some object, you say\n", "Assume that angles are measured in degrees.  \nThe translation will then apply to all subsequent drawing.  But, because of the rotation command,\nthe things that you draw after the translation are ", " objects.  That is, the translation\napplies to objects that have ", " been rotated.  \nAn example is shown on the left in the illustration below, where the light gray \"F\" is the original shape, and\nred \"F\" shows the result of applying the two transforms to the original.  The original \"F\"\nwas first rotated through a 90 degree angle, and then moved 4 units to the right.", "\n", "Note that transforms are\napplied to objects in the reverse of the order in which they are given in the code (because the\nfirst transform in the code is applied to an object that has already been affected by the second\ntransform).  And note that the order in which the transforms are applied is important.  If we reverse\nthe order in which the two transforms are applied in this example, by saying", "then the result is as shown on the right in the above illustration. In that picture,\nthe original \"F\" is first moved 4 units to the right and the resulting shape\nis then rotated through an angle of 90 degrees about the origin to give the shape that actually appears\non the screen.", "For another example of applying several transformations, suppose that we want to rotate a shape through\nan angle ", " about a point (", ",", ") instead of about the point (0,0).  We can do this by\nfirst moving the point (", ",", ") to the origin, using ", "(", ",", ").\nThen we can do a standard rotation about the origin by calling ", "(", "). Finally,\nwe can move the origin back to the point (", ",", ") by applying ", "(", ",", ").\nKeeping in mind that we have to write the code for the transformations in the reverse order, we need to say\n", "before drawing the shape.  (In fact, some graphics APIs let us accomplish this transform with a\nsingle command such as ", "(", ",", ",", ").  This would apply a rotation\nthrough the angle ", " about the point (", ",", ").)", "A ", " transform can be used to make objects bigger or smaller. Mathematically,\na scaling transform simply multiplies each x-coordinate by a given amount and each y-coordinate by\na given amount. That is, if a point (", ",", ") is scaled by a factor of ", " in the\nx direction and by a factor of ", " in the y direction, then the resulting point (", ",", ")\nis given by", "If you apply this transform to a shape that is centered at the origin, it will stretch the shape\nby a factor of ", " horizontally and ", " vertically.  Here is an example, in which the\noriginal light gray \"F\" is scaled by a factor of 3 horizontally and 2 vertically to give the\nfinal dark red \"F\":", "\n", "The common case where the horizontal and vertical scaling factors are the same is\ncalled ", ".  Uniform scaling stretches or shrinks a shape without\ndistorting it.", "When scaling is applied to a shape that is not centered at (0,0), then in addition to being\nstretched or shrunk, the shape will be moved away from 0 or towards 0.  In fact, the true description\nof a scaling operation is that it pushes every point away from (0,0) or pulls every point towards (0,0).\nIf you want to scale about a point other than (0,0), you can use a sequence of three transforms,\nsimilar to what was done in the case of rotation.", "A 2D graphics API can provide a function ", "(", ",", ") for\napplying scaling transformations.  As usual, the transform applies to all ", " and ", "\ncoordinates in subsequent drawing operations. Note that negative scaling factors are allowed and will result in reflecting the\nshape as well as possibly stretching or shrinking it.  For example, ", "(1,-1) will\nreflect objects vertically, through the ", "-axis.", "It is a fact that every affine transform can be created by combining translations, rotations\nabout the origin, and scalings about the origin.  I won't try to prove that, but \nhere is an\ninteractive demo that will let you experiment with translations, rotations, and scalings, and with the\ntransformations that can be made by combining them.", "\n", "\n", "I also note that a transform that is made from translations and rotations, with no scaling, will preserve\nlength and angles in the objects to which it is applied.  It will also preserve\n", " of rectangles.  Transforms with this property\nare called \"", ".\"   If you also allow ", " \nscaling, the resulting transformation will preserve angles and aspect ratio, but not lengths.", "We will look at one more type of basic transform, a ", ".\nAlthough shears can in fact be built up out of rotations and scalings if necessary, it is not\nreally obvious how to do so.  A shear will \"tilt\" objects.  A horizontal shear will tilt things \ntowards the left (for negative shear) or right (for positive shear).  A vertical shear tilts them\nup or down.  Here is an example of horizontal shear: ", "\n", "A horizontal shear does not move the x-axis.  Every other horizontal line is moved to the left\nor to the right by an amount that is proportional to the y-value along that line.  When a horizontal\nshear is applied to a point (", ",", "), the resulting point (", ",", ") is\ngiven by", "for some constant shearing factor ", ".  Similarly, a vertical shear with shearing factor ", "\nis given by the equations", "Shear is occasionally called \"skew.\"", "The last transformation that is applied to an object before it is displayed in an\nimage is the window-to-viewport transformation, which maps the rectangular ", "\nin the xy-plane that contains the scene to the rectangular grid of pixels where the \nimage will be displayed.  I'll assume here that the view window is not rotated; that it, its\nsides are parallel to the x- and y-axes.  In that case, the window-to-viewport transformation\ncan be expressed in terms of translation and scaling transforms.  Let's look at the\ntypical case where the viewport has pixel coordinates ranging from 0 on the left to \n", " on the right and from 0 at the top to ", " at the bottom.\nAnd assume that the limits on the view window are ", ", ", ",\n", ", and ", ".  In that case, the window-to-viewport transformation\ncan be programmed as:", "These should be the last transforms that are applied to a point.  Since transforms\nare applied to points in the reverse of the order in which they are specified in the\nprogram, they should be the first transforms that are specified in the program. To see how this works,\nconsider a point (", ",", ") in the view window.  (This point comes from some object in\nthe scene.  Several modeling transforms might have already been applied to the\nobject to produce the point (", ",", "), and that point is now ready for its final transformation\ninto viewport coordinates.)  The coordinates (", ",", ") are first translated by (", ",", ")\nto give (", ",", ").  These coordinates are then multiplied by the\nscaling factors shown above, giving the final coordinates", "Note that the point (", ",", ") is mapped to (0,0), while the\npoint (", ",", ") is mapped to (", ",", "),\nwhich is just what we want.", "There is still the question of ", ".  As noted in\n", ", if we want to force the aspect ratio of the\nwindow to match the aspect ratio of the viewport, it might be necessary\nto adjust the limits on the window.   Here is pseudocode for a subroutine\nthat will do that, again assuming that the top-left corner of the viewport\nhas pixel coordinates (0,0):", "The transforms that are used in computer graphics can be represented as\nmatrices, and the points on which they operate are represented as\nvectors.  Recall that a ", ", from the point of view of a\ncomputer scientist, is a two-dimensional array of numbers, while a\n", " is one-dimensional.  Matrices and vectors are\nstudied in the field of mathematics called ", ".\nLinear algebra is fundamental to computer graphics.  In fact,\nmatrix and vector math is built into ", ".\nYou won't need to know a great deal about linear algebra for this textbook,\nbut a few basic ideas are essential.", "The vectors that we need are lists of two, three, or four numbers.  They\nare often written as (", ",", "), (", ",", ",", "), and (", ",", ",", ",", ").  A matrix with N rows\nand M columns is called an \"N-by-M matrix.\"  For the most part,\nthe matrices that we need are N-by-N matrices, where N is 2, 3, or 4.\nThat is, they have 2, 3, or 4 rows and columns, and the number of \nrows is equal to the number of columns.", "If ", " and ", " are two N-by-N matrices, then they can be multiplied to\ngive a product matrix ", "\u00a0=\u00a0", ".  If ", "\u00a0is an N-by-N\nmatrix, and ", " is a vector of length N, then ", " can be multiplied\nby ", " to give another vector ", "\u00a0=\u00a0", ".  The function\nthat takes ", " to ", " is a transformation; it transforms any given\nvector of length N into another vector of length\u00a0N.  A\u00a0transformation of this\nform is called a ", ".", "Now, suppose that ", " and ", " are N-by-N matrices and ", " is \na vector of length N.  Then, we can form two different products:\n", "(", ") and (", ".  It is a central fact that these\ntwo operations have the same effect.  That is, we can multiply ", " by ", "\nand then multiply the result by ", ", or we can multiply the matrices\n", " and ", " to get the matrix product ", " and then multiply\n", " by ", ".  The result is the same.", "Rotation and scaling, as it turns out, are linear transformations.  That\nis, the operation of rotating (", ",", ") through an angle\u00a0", "\nabout the origin can be done by multiplying (", ",", ") by a 2-by-2 matrix.\nLet's call that matrix ", ".  Similarly, scaling by a factor\n", " in the horizontal direction and ", " in the vertical direction\ncan be given as a matrix ", ".  If we want to apply\na scaling followed by a rotation to the point ", " = (", ",", "), we can\ncompute ", "  ", "(", ") ", "\n(", ")", ".", "So what?  Well, suppose that we want to apply the same two operations, scale then rotate, \nto thousands of points,  as we typically do when transforming objects for computer graphics.  The point \nis that we could compute the product matrix ", " once \nand for all, and then apply the combined transform to each point with a single multiplication.\nThis means that if a program says", "the computer doens't have to keep track of two separate operations.  It combines the\noperations into a single matrix and just keeps track of that. Even if you apply, say, 50 \ntransformations to the object, the computer can just combine them all into one matrix.\nBy using matrix algebra, multiple transformations can be handled as efficiently as a\nsingle transformation!", "This is really nice, but there is a gaping problem: ", "\nTo bring translation into this framework, we do something that looks a little strange at first:\nInstead of representing a point in 2D as a pair of numbers (", ",", "), we represent\nit as the triple of numbers (", ",", ",1).  That is, we add a one as the third coordinate.\nIt then turns out that we can then represent rotation, scaling, and translation\u2014and hence\nany affine transformation\u2014on 2D space as multiplication by a 3-by-3 matrix.  The matrices \nthat we need have a bottom row containing (0,0,1).   Multiplying (", ",", ",1)\nby such a matrix gives a new vector (", ",", ",1).  We ignore the extra coordinate and consider this\nto be a transformation of (", ",", ") into (", ",", "). For the record, the 3-by-3\nmatrices for translation (", "), scaling (", "),\nand rotation (", ") in 2D are", "\n", "You can compare multiplication by these matrices to the formulas given above for translation, scaling,\nand rotation.  However, you won't need to do the multiplication yourself.  For now,\nthe important idea that you should take away from this discussion is that a sequence of transformations\ncan be combined into a single transformation.  The computer only needs to keep track of a single matrix, which we\ncan call the \"current matrix\" or \"current transformation.\"  To implement transform commands such as ", "(a,b)\nor ", "(d), the computer simply multiplies the current matrix by the matrix that represents the\ntransform."], "chapter_title": "Two-Dimensional Graphics", "id": 2.3}, {"section_title": "Shapes", "chapter_id": "Chapter 2", "section_id": "Section 2.2", "content": ["We have been talking about low-level graphics concepts like ", " \nand ", ", but\nfortunately we don't usually have to work on the lowest levels.  Most graphics systems let\nyou work with higher-level shapes, such as triangles and circles, rather than individual\npixels.  And a lot of the hard work with coordinates is done using \n", " rather than by working with coordinates\ndirectly.  In this section and the next, we will look at some of the higher-level capabilities\nthat are typically provided by 2D graphics APIs.", "In a graphics ", ", there will be certain basic shapes that can be drawn with one command, whereas\nmore complex shapes will require multiple commands.  Exactly what qualifies as a basic shape varies\nfrom one API to another.  In the JavaScript API for drawing on an ", ", for example,\nthe only basic shapes are lines and rectangles.  In this subsection, I consider lines, rectangles, and ovals\nto be basic.", "By \"line,\" I really mean line segment, that is a straight line segment connecting two given\npoints in the plane.  A simple one-pixel-wide line segment, without ", ", is \nthe most basic shape.  It can be drawn by coloring pixels that lie along the infinitely thin\ngeometric line segment.  An algorithm for drawing the line has to decide exactly which pixels\nto color.  One of the first computer graphics algorithms, \n", " for line drawing, implements\na very efficient procedure for doing so.  I won't discuss such low-level details here, but it's\nworth looking them up if you want to start learning about what graphics hardware actually has to do.\nIn any case, lines are typically more complicated. Antialiasing is one complication.  Line width is\nanother.  A wide line might actually be drawn as a rectangle.", "Lines can have other ", ", or properties, that affect\ntheir appearance. One question is, what should happen at the end of a wide line?  Appearance might\nbe improved by adding a rounded \"cap\" on the ends of the line.  A square cap\u2014that is, extending the\nline by half of the line width\u2014might also make sense.  Another question is, when two lines meet\nas part of a larger shape, how should the lines be joined?  And many graphics systems support lines \nthat are patterns of dashes and dots.  This illustration shows some of the possibilities:", "\n", "On the left are three wide lines with no cap, a round cap, and a square cap.  The geometric line\nsegment is shown as a dotted line.  (The no-cap style is called \"butt.\")  To the right are four lines\nwith different patters of dots and dashes.  In the middle are three different styles of line joins:\nmitered, rounded, and beveled.", "The basic rectangular shape has sides that are vertical and horizontal.  (A tilted rectangle generally\nhas to be made by applying a ", ".) Such a rectangle can be specified \nwith two points, (x1,y1) and (x2,y2), that give the endpoints of one of the diagonals of the rectangle.\nAlternatively, the width and the height can be given, along with a single base point, (x,y).  In that\ncase, the width and height have to be positive, or the rectangle is empty.  The base point (x,y) will\nbe the upper left corner of the rectangle if y increases from top to bottom, and it will be the\nlower left corner of the rectangle if y increases from bottom to top.", "\n", "Suppose that you are given points (x1,y1) and (x2,y2), and that you want to draw the rectangle\nthat they determine.  And suppose that the only rectangle-drawing command that you have available\nis one that requires a point (x,y), a width, and a height. For that command, x must be the\nsmaller of x1 and x2, and the width can be computed as the absolute value of x1 minus x2. And\nsimilarly for y and the height.  In pseudocode,\n", "A common variation on rectangles is to allow rounded corners.  For a \"round rect,\" the corners\nare replaced by elliptical arcs.  The degree of rounding can be specified by giving the horizontal radius\nand vertical radius of the ellipse.  Here are some examples of round rects.  For the shape at the\nright, the two radii of the ellipse are shown:", "\n", "My final basic shape is the oval.  (An oval is also called an ellipse.)  An oval is a closed\ncurve that has two radii.  For a basic oval, we assume that the radii are vertical and horizontal.\nAn oval with this property can be specified by giving the rectangle that just contains it.\nOr it can be specified by giving its center point and the lengths of its vertical radius and\nits horizontal radius.  In this illustration, the oval on the left is shown with its\ncontaining rectangle and with its center point and radii:", "\n", "The oval on the right is a circle.  A circle is just an oval in which the two radii have\nthe same length.  ", "If ovals are not available as basic shapes, they can be approximated by drawing a large\nnumber of line segments.  The number of lines that is needed for a good approximation depends on\nthe size of the oval.  It's useful to know how to do this. Suppose that an oval has center point (x,y), \nhorizontal radius r1, and vertical radius r2.  Mathematically, the points on the oval are given by", "where ", " takes on values from 0 to 360 if angles are measured in degrees or\nfrom 0 to 2\u03c0 if they are measured in radians.  Here ", " and ", " are the\nstandard sine and cosine functions.  To get an approximation for an oval, we can use this\nformula to generate some number of points and then connect those points with line segments.\nIn pseudocode, assuming that angles are measured in radians and that ", " represents\nthe mathematical constant\u00a0\u03c0,", "For a circle, of course, you would just have r1 = r2.  This is the first time\nwe have used the sine and cosine functions, but it won't be the last.  These\nfunctions play an important role in computer graphics because of their\nassociation with circles, circular motion, and rotation.  We will meet them\nagain when we talk about transforms in the ", ".", "Here's a little demo\nthat you can use to experiment with using line segements to approximate ovals:", "\n", "\n", "There are two ways to make a shape visible in a drawing.  You can ", " it.\nOr, if it is a closed shape such as a rectangle or an oval, you can ", " it.\nStroking a line is like dragging a pen along the line.  Stroking a rectangle or oval is like\ndragging a pen along its boundary.  Filling a shape means coloring all the points that are contained\ninside that shape.  It's possible to both stroke and fill the same shape; in that case, the\ninterior of the shape and the outline of the shape can have a different appearance.", "When a shape intersects itself, like the two shapes in the illustration below, it's not\nentirely clear what should count as the interior of the shape.  In fact, there are at least\ntwo different rules for filling such a shape.  Both are based on something called the\n", ".  The winding number of a shape about a point is, roughly,\nhow many times the shape winds around the point in the positive direction, which I take here\nto be counterclockwise.\nWinding number can be negative when the winding is in the opposite direction.  \nIn the illustration, the shapes\non the left are traced in the direction shown, and the winding number about each region is \nshown as a number inside the region.", "\n", "The shapes are also shown filled using the two fill rules.  For the shapes in the center,\nthe fill rule is to color any region that has a non-zero winding number.  For the shapes\nshown on the right, the rule is to color any region whose winding number is odd; regions with\neven winding number are not filled.", "There is still the question of what a shape should be filled ", ".  Of course, it\ncan be filled with a color, but other types of fill are possible, including \n", " and ", ". \nA pattern is an image, usually a small image.  When used to fill a shape, a pattern can be\nrepeated horizontally and vertically as necessary to cover the entire shape.\nA gradient is similar in that it is a way for color to vary from point to point, but \ninstead of taking the colors from an image, they are computed.  There are a lot of variations\nto the basic idea, but there is always a line segment along which the color varies.\nThe color is specified at the endpoints of the line segment, and possibly at additional\npoints; between those points, the color is ", ".\nFor other points on the line that contains the line segment, the pattern on the line segment\ncan be repeated, or the color of the endpoint can simply be extended.  For a\n", ", the color is constant along lines perpendicular to the basic\nline segment, so you get lines of solid color going in that direction.\nIn a ", ", the color is constant along circles centered at one\nof the endpoints of the line segment.  And that doesn't exhaust the possibilities.\nTo give you an idea what patterns and gradients can look like,\nhere is a shape, filled with two gradients and two patterns:\n", "\n", "The first shape is filled with a simple linear gradient defined by just two colors,\nwhile the second shape uses a radial gradient.", "Patterns and gradients are not necessarily restricted to filling shapes.  Stroking a shape is,\nafter all, the same as filling a band of pixels along the boundary of the shape,\nand that can be done with a gradient or a pattern, instead of with  a solid color.", "Finally, I will mention that a string of text can be considered to be a shape for the purpose of\ndrawing it.  The boundary of the shape is the outline of the characters.\nThe text is drawn by filling that shape.  In some graphics systems, it is also possible to\nstroke the outline of the shape that defines the text.  \nIn the following illustration, the string \"Graphics\" is shown, on top, filled with a pattern and,\nbelow that, filled with a gradient and stroked with solid black:", "\n", "It is impossible for a graphics API to include every possible shape as a basic shape, but there\nis usually some way to create more complex shapes.   For example, consider\n", ".  A polygon is a closed shape consisting of a\nsequence of line segments.  Each line segment is joined to the next at its endpoint, and the\nlast line segment connects back to the first.  The endpoints are called the vertices of the\npolygon, and a polygon can be defined by listing its vertices.", "In a ", ", all the sides are the same length and all the\nangles between sides are equal.  Squares and equilateral triangles are examples of regular\npolygons.  A ", " has the property that whenever two points are inside\nor on the polygon, then the entire line segment between those points is also inside or on the polygon.\nIntuitively, a convex polygon has no \"indentations\" along its boundary.  (Concavity can be a property\nof any shape, not just of polygons.)", "\n", "Sometimes, polygons are required to be \"simple,\" meaning that the polygon has no self-intersections.\nThat is, all the vertices are different, and a side can only intersect another side at its\nendpoints. And polygons are usually required to be \"planar,\" meaning that all the\nvertices lie in the same plane.  (Of course, in 2D graphics,\n", " lies in the same plane, so this is not an issue.  However, it does become\nan issue in 3D.)", "How then should we draw polygons?  That is, what capabilities would we like to have in a \ngraphics API for drawing them.  One possibility is to have commands for stroking and for\nfilling polygons, where the vertices of the polygon are given as an array of points or as an array\nof x-coordinates plus an array of y-coordinates.  In fact, that is sometimes done; for example,\nthe Java graphics API includes such commands.  Another, more flexible, approach is to introduce\nthe idea of a \"path.\"  Java, SVG, and the HTML canvas API all\nsupport this idea.  A path is a general shape that can include both line\nsegments and curved segments.  Segments can, but don't have to be, connected to other segments\nat their endpoints.  A path is created by giving a series of commands that tell, essentially,\nhow a pen would be moved to draw the path.  While a path is being created, there is a point\nthat represents the pen's current location.  There will be a command for moving the pen without\ndrawing, and commands for drawing various kinds of segments.  For drawing polygons, we\nneed commands such as", "(For ", ", I need to define \"starting point.\"  A path can be made up\nof \"subpaths\"  A subpath consists of a series of connected segments.  A ", "\nalways starts a new subpath.  A ", " ends the current segment and implicitly\nstarts a new one.  So \"starting point\" means the position of the pen after the most recent\n", " or ", ".)", "Suppose that we want a path that represents the triangle with vertices at (100,100), (300,100),\nand (200, 200).  We can do that with the commands", "The ", " command at the end could be replaced by ", ",\nto move the pen back to the first vertex.", "A path represents an abstract geometric object.  Creating\none does not make it visible on the screen.  Once we have a path, to make it visible we need additional\ncommands for stroking and filling the path.", "Earlier in this section, we saw how to approximate an oval by drawing, in effect, a regular\npolygon with a large number of sides.  In that example, I drew each side as a separate line segment,\nso we really had a bunch of separate lines rather than a polygon.  There is no way to fill such\na thing.  It would be better to approximate the oval with a polygonal path.  For an oval with\ncenter (x,y) and radii r1 and r2:", "Using this path, we could draw a filled oval as well as stroke it.  \nEven if we just want to draw the outline of a polygon,\nit's still better to create the polygon as a path rather than to draw the line segments as\nseparate sides.  With a path, the computer knows that the sides are part of single shape.\nThis makes it possible to control the appearance of the \"join\" between consecutive sides, as noted\nearlier in this section.", "I noted above that a path can contain other kinds of segments besides lines.  For example,\nit might be possible to include an arc of a circle as a segment.  Another type of curve\nis a ", ".  Bezier curves can be used to create very general \ncurved shapes.  They are fairly intuitive, so that they are often used in programs that\nallow users to design curves interactively.  Mathematically, Bezier curves are defined\nby parametric polynomial equations, but you don't need to understand what that means to\nuse them.  There are two kinds of Bezier curve in common use, cubic Bezier curves and\nquadratic Bezier curves; they are defined by cubic and quadratic polynomials respectively.\nWhen the general term \"Bezier curve\" is used, it usually refers to cubic Bezier curves.", "A cubic Bezier curve segment is defined by the two endpoints of the segment together\nwith two ", ".  To understand how it works,\nit's best to think about how a pen would draw the curve segment.  The pen starts at the\nfirst endpoint, headed in the direction of the first control point.  The distance of the\ncontrol point from the endpoint controls the speed of the pen as it starts drawing the\ncurve.  The second control point controls the direction and speed of the pen as it gets\nto the second endpoint of the curve.  There is a unique cubic curve that satisfies\nthese conditions.", "\n", "The illustration above shows three cubic Bezier\ncurve segments.  The two curve segments on the right are connected at an endpoint to form a longer\ncurve.  The curves are drawn as thick black lines.  The endpoints are shown as black dots\nand the control points as blue squares, with a thin red line connecting each control point\nto the corresponding endpoint. (Ordinarily, only the curve would be drawn, except in an\ninterface that lets the user edit the curve by hand.)  Note that at an endpoint, the\ncurve segment is tangent to the line that connects the endpoint to the control point.\nNote also that there can be a sharp point or corner where two curve segments meet.  However,\none segment will merge smoothly into the next if control points are properly chosen.\n", "This will all be easier to understand\nwith some hands-on experience. \nThis interative demo lets you edit cubic Bezier curve segments by dragging their endpoints \nand control points:\n", "\n", "\n", "When a cubic Bezier curve segment is added to a path, the path's current pen location acts\nas the first endpoint of the segment.  The command for adding the segment to the path must specify\nthe two control points and the second endpoint.  A typical command might look like", "This would add a curve from the current location to point (x,y), using (cx1,cy1) and (cx2,cy2) as the\ncontrol points.  That is, the pen leaves the current location heading towards (cx1,cy1), and it \nends at the point (x,y), arriving there from the direction of (cx2,cy2).  ", "Quadratic Bezier curve segments are similar to the cubic version, but in the quadratic\ncase, there is only one control point for the segment.  The curve leaves the first endpoint\nheading in the direction of the control point, and it arrives at the second endpoint coming\nfrom the direction of the control point.  The curve in this case will be an arc of a\nparabola.", "Again, this is easier to understand this with some hands-on experience.  Try this interactive demo:", "\n", "\n"], "chapter_title": "Two-Dimensional Graphics", "id": 2.2}, {"section_title": "SVG: A Scene Description Language", "chapter_id": "Chapter 2", "section_id": "Section 2.7", "content": ["We finish this chapter with a look at one more 2D graphics system:\n", ", or Scalable Vector Graphics.  So far, we have\nbeen considering graphics programming APIs.  SVG, on the other\nhand is a ", " rather\nthan a programming language.  Where a programming language creates\na scene by generating its contents procedurally, a scene description\nlanguage specifies a scene \"declaratively,\" by listing its content.\nSince SVG is a ", " language, the content of\nof a scene includes shapes, attributes such as color and line width,\nand geometric transforms.  Most of this should be familiar to you,\nbut it should be interesting to see it in a new context.", "SVG is an ", " language, which means it has a very strict\nand somewhat verbose syntax.  This can make it a little annoying to write,\nbut on the other hand, it makes it possible to read and understand\nSVG documents even if you are not familiar with the syntax.  It's possible\nthat SVG originally stood for \"Simple\" Vector Graphics, but it is by\nno means a simple language at this point.  I will cover only a part of it\nhere, and there are many parts of the language and many options that I will\nnot mention.  My goal is to introduce the idea of a scene description language\nand to show how such a language can use the same basic ideas that are\nused in the rest of this chapter.", "SVG can be used as a file format for storing vector graphics\nimages, in much the same way that PNG and JPEG are file formats for\nstoring pixel-based images.  That means that you can open an SVG\nfile with a web browser to view the image.  (This is true, at least,\nfor modern web browsers.)  An SVG image can be included in a web page\nby using it as the source of an ", " element.  That's how the\nSVG examples on this page are displayed.  Since SVG documents are written in plain text,\nyou can create SVG images using a regular text editor, and you can read the\nsource for an SVG image by opening it in a text editor or by viewing the\nsource of the image when it is displayed in a web browser.", "An SVG file, like any XML document, starts with some standard code that almost\nno one memorizes.  It should just be copied into a new document.  Here\nis some code that can be copied as a starting point for SVG \ndocuments of the type discussed in this section (which, remember use \nonly a subset of the full SVG specification):", "The first three lines say that this is an XML SVG document.  The rest of\nthe document is an ", " element that acts as a container for the entire\nscene description.  You'll need to know a little about XML syntax.\nFirst, an XML \"element\" in its general form looks like this:\n", "The element starts with a \"start tag,\" which begins with a \"<\" followed by an identifier\nthat is the name of the tag, and ending with a\u00a0\">\".  The start tag can include\n\"attributes,\" which have the form ", ".  The ", " is an identifier;\nthe ", " is a string.  The value must be enclosed in single or double quotation marks.\nThe element ends with an \"end tag,\" which has an element name that matches the element name\nin the start tag and has the form </", ">.  Element names and attribute names\nare case-sensitive.  Between the start and end tags\ncomes the \"content\" of the element.  The content can consist of text and nested elements.\nIf an element has no content, you can replace the \">\" at the end of the start tag with\n\"/>\", and leave out the end tag.  This is called a \"self-closing tag.\" For example,\n", "This is an actual SVG element that specifies a circle.  It's easy to forget the \"/\"\nat the end of a self-closing tag, but it has to be there to have a legal XML document.", "Looking back at the SVG document, the five lines starting with <svg are just a long\nstart tag.  You can use the tag as shown, and customize the values of the ", ",\n", ", ", ", and ", " attributes.  The next line\nis a comment; comments in XML start with \"", "\" and end with \"", "\".", "The ", " and ", " attributes of the ", " tag specify a\nnatural or preferred size for the image.  It can be forced into a different size, for\nexample if it is used in an ", " element on a web page that specifies a different\nwidth and height.  The size can be specified using units of measure such as ", " for\ninches, ", " for centimeters, and ", ", for pixels, with 90 pixels to the inch.\nIf no unit of measure is specified, pixels are used.  There cannot be any space between\nthe number and the unit of measure.", "The ", " attribute sets up the ", " that will be used for \ndrawing the image.  It is what I called the ", " in ", ".\nThe value for viewBox is a list of four numbers,\ngiving the minimum ", "value, the minimum ", ", the width, and the height\nof the view window.  The width and the height must be positive, so ", " increases from\nleft-to-right, and ", " increases from top-to-bottom.  The four numbers in the list\ncan be separated either by spaces or by commas; this is typical for lists of numbers in SVG.", "Finally, the ", " attribute tells what happens when the\n", " of the viewBox does not match the aspect ratio of the rectangle\nin which the image is displayed.  The default value, \"xMidYMid\", will extend the limts\non the viewBox either horizontally or vertically to preserve the aspect ratio, and the\nviewBox will appear in the center of the display rectangle.  If you would like your \nimage to stretch to fill the display rectangle, ignoring the aspect ratio, set the\nvalue of ", " to \"none\".  (The aspect ratio issue was\ndiscussed in ", ".)", "Let's look at a complete SVG document that draws a few simple shapes.  Here's the\ndocument.  You could probably figure out what it draws even without knowing any more\nabout SVG:", "and here's the image that is produced by this example:", "\n", "In the drawing coordinate system for this example, ", " ranges from 0 to 3, and\n", " ranges from 0 to 2.  All values used for drawing, including stroke width\nand font size, are given in terms of this coordinate system.  Remember that you can\nuse any coordinate system that you find convenient!  Note, by the way, that parts\nof the image that are not covered by the shapes that are drawn will be transparent.", "Here's another example, with a larger variety of shapes.  The source code for this\nexample has a lot of comments. It uses features that we will discuss in the remainer of\nthis section.", "\n", "You can take a look at the source code, ", ".\n(For example, open it in a text editor, or open it in a web browser and use the\nbrowser's \"view source\" command.)", "In SVG, a basic shape is specified by an element in which the tag name gives the\nshape, and attributes give the properties of the shape.  There are attributes to specify\nthe geometry, such as the endpoints of a line or the radius of a circle.\nOther attributes specify style properties, such as fill color and line width.\n(The style properties are what I call ", " elsewhere\nin this book; in this section, I am using the term \"attribute\" in its XML sense.)\nAnd there is a ", " attribute that can be used to apply a\n", " to the shape.", "For a detailed example, consider the ", " element, which specifies a rectangle.  \nThe geometry of the rectangle is given by attributes named ", ", ", ", ", "\nand ", " in the usual way.  The default value for ", " and ", " is zero;\nthat is, they are optional, and leaving them out is the same as setting their value to zero.\nThe ", " and the ", " are required attributes.  Their values must be\nnon-negative.  For example, the element", "specifies a rectangle with corner at (0,0), width 3, and height 2, while", "gives a rectangle with corner at (100,200), width 640, and height 480.  (Note, by\nthe way, that the attributes in an XML element can be given in any order.)  The ", "\nelement also has optional attributes ", " and ", " that can be used to make\n\"roundRects,\" with their corners replaced by elliptical arcs.  The values of ", "\nand ", " give the horizontal and vertical radii of the elliptical arcs.", "Style attributes can be added to say how the shape should be stroked and filled.\nThe default is to use a black fill and no stroke.  (More precisely, as we will see later,\nthe default for is for a shape to inherit the values of style attributes from its \nenvironment.  Black fill and no stroke is the initial environment.)  Here are some\ncommon style attributes:", "As an example that uses many of these options, let's make a square is rounded rather than pointed \nat the corners, with size 1, centered\nat the origin, and using a translucent red fill and a gray stroke:", "and a simple outline of a rectangle with no fill:", "The ", " attribute can be used to apply a transform or a series of\ntransforms to a shape.  As an example, we can make a rectangle tilted 30 degrees from\nthe horizontal:", "The value \"rotate(30)\" represents a rotation of 30 degrees (not radians!) about the \norigin, (0,0). The positive direction of rotation, as usual, rotates the positive x-axis in the\ndirection of the positive y-axis.  You can specify a different center of rotation by\nadding arguments to ", ".  For example, to rotate the same rectangle about its\ncenter", "Translation and scaling work as you probably expect, with transform values of\nthe form \"translate(", ")\" and \"scale(", ")\".  There are also\n", " transforms, but they go by the\nnames ", " and ", ", and the argument is a skew angle rather\nthan a shear amount.  For example, the transform \"skewX(45)\" tilts the y-axis\nby 45 degrees and is equivalent to an x-shear with shear factor\u00a01.\n(The function that tilts the y-axis is called ", " because it modifies,\nor skews, the x-coordinates of points while leaving their y-coordinates unchanged.)\nFor example, we can use ", " to tilt a rectangle and make it into a\nparallelogram:", "I used an angle of -30 degrees to make the rectangle tilt to the right\nin the usual pixel coordinate system.", "The value of the ", " attribute can be a list of transforms,\nseparated by spaces or commas.  The transforms are applied to the object, as\nusual, in the opposite of the order in which they are listed. So,", "would first skew the rectangle into a parallelogram, then rotate the parallelogram\nby 45 degrees about the origin, then translate it by 50 units in the y-direction.", "In addition to rectangles, SVG has lines, circles, ellipses, and text as basic\nshapes.  Here are some details.  A ", " element represents a line segement and\nhas geometric attributes ", ", ", ", ", ", and ", " to specify the \ncoordinates of the endpoints of the line segment.  These four attributes have\nzero as default value, which makes it easier to specify horizontal and vertical lines.\nFor example,", "Without the ", " attribute, you wouldn't see the line, since the default\nvalue for ", " is \"none\".", "For a ", " element, the geometric attributes are ", ", ", ", and ", "\ngiving the coordinates of the center of the circle and the radius.  The center coordinates\nhave default values equal to zero.  For an ", " element, the attributes are\n", ", ", ", ", ", and ", ", where ", " and ", " give\nthe radii of the ellipse in the x- and y-directions.", "A ", " element is a little different.  It has attributes ", " and ", ",\nwith default values zero, to specify the location of the basepoint of the text.  However,\nthe text itself is given as the content of the element rather than as an attribute.  That is,\nthe element is divided into a start tag and an end tag, and the text that will appear in\nthe drawing comes between the start and end tags.  For example,", "The usual stroke and fill attributes apply to text, but text has additional style\nattributes.  The ", " attribute specifies the font itself.  Its value\ncan be one of the generic font names \"serif\", \"sans-serif\", \"monospace\", or the name of\na specific font that is available on the system.  The ", " can be a number\ngiving the (approximate) height of the characters in the coordinate system.  (Font size\nis subject to coordinate and modeling transforms like any other length.)  You can get\nbold and italic text by setting ", " equal to \"bold\" and\n", " equal to \"italic\".  Here is an example that uses all of these options,\nand applies some additional styles and a transform for good measure:", "SVG has some nice features for making more complex shapes.  The ", " element\nmakes it easy to create a polygon from a list of coordinate pairs.  For example,", "creates a five-sided polygon with vertices at (0,0), (100,0), (100,75), (50,100), and\n(0,75).  Every pair of numbers in the ", " attribute specifies a vertex.  The numbers\ncan be separated by either spaces or commas.  I've used a mixture of spaces and commas here to\nmake it clear how the numbers pair up.   Of course, you can add the usual style attributes\nfor stroke and fill to the polygon element.  A ", " is similar to a ", ",\nexcept that it leaves out the last line from the final vertex back to the starting vertex.\nThe difference only shows up when a polyline is stroked; a polyline is filled as if the\nmissing side were added.", "The ", " element is much more interesting. In fact, all of the other basic shapes,\nexcept text, could be made using path elements.  A path can consist of line segments,\n", ", and elliptical arcs (although I won't\ndiscuss elliptical arcs here).  The syntax for\nspecifying a path is very succinct, and it has some features that we have not seen before.\nA path element has an attribute named ", " that contains the data for the path.  The\ndata consists of one or more commands, where each command consists of a single letter followed\nby any data necessary for the command.  The moveTo, lineTo, cubic Bezier, and quadratic\nBezier commands that you are already familiar with are coded by the letters M, L, C, and Q.\nThe command for closing a path segment is Z, and it requires no data.\nFor example the path data \"M\u00a010\u00a020\u00a0L\u00a0100\u00a0200\" would draw a line segment\nfrom the point (10,20) to the point (100,200).  You can combine several connected line segments\ninto one L command.  For example, the ", " example given above could be created\nusing the ", " element", "The Z at the end of the data closes the path by adding the final side to the polygon.\n(Note that, as usual, you can use either commas or spaces in the data.)", "The C command takes six numbers as data, to specify the two control points and the final\nendpoint of the cubic Bezier curve segment.  You can also give a multiple of six values to get\na connected sequence of curve segements.  Similarly, the Q command uses four data values to\nspecify the control point and final endpoint of the quadratic Bezier curve segment.\nThe large, curvy, yellow shape shown in the picture earlier in this section was created\nas a path with two line segments and two Bezier curve segments:", "SVG paths add flexibility by defining \"relative\" versions of the path commands,\nwhere the data for the command is given relative to the current position.\nA relative move command, for example, instead of telling ", " to move,\ntells ", " to move from the current position.  The names of the \nrelative versions of the path commands are lower case letters instead of upper case.\n\"M\u00a010,20\" means to move to the point with coordinates (10,20), while\n\"m\u00a010,20\" means to move 10 units horizontally and 20 units vertically\nfrom the current position.  Similarly, if the current position is (", "), then\nthe command \"l\u00a03,5\", where the first character is a lower case L, draws a line from (", ") to\n(", "+3,", ").", "SVG would not be a very interesting language if it could only work with\nindividual simple shapes.  For complex scenes, we want to be able to do\n", ", where objects can be constructed from\nsub-objects, and a transform can be applied to an entire complex object.\nWe need a way to group objects so that they can be treated as a unit.\nFor that, SVG has the ", " element.  The content of a ", "\nelement is a list of shape elements, which can be simple shapes or\nnested ", " elements.", "You can add style and ", " attributes to a ", " element.\nThe main point of grouping is that a group can be treated as a single\nobject.  A ", " attribute in a ", " will transform the\nentire group as a whole.  A style attribute, such as ", " or\n", ", on a ", " element will set a default value \nfor the group, replacing the current default.  Here is an example:", "The nested shapes use fill=\"none\" stroke=\"black\" stroke-width=\"2\" for the\ndefault values of the attributes.  The default can be overridden by specifying\na different value for the element, as is done for the stroke-width of the\n", " element in this example.  Setting transform=\"scale(1,\u22121)\"\nfor the group flips the entire image vertically.  I do this only because\nI am more comfortable working in a coordinate system in which y increases\nfrom bottom-to-top rather than top-to-bottom.  Here is the simple line\ndrawing of a face that is produced by this group:", "\n", "Now, suppose that we want to include multiple copies of an object in\na scene.  It shouldn't be necessary to repeat the code for drawing the object.\nIt would be nice to have something like reusable subroutines.  In fact,\nSVG has something very similar: You can define reusable objects inside a\n", " element.  An object that is defined inside ", " is\nnot added to the scene, but copies of the object can be added to the scene\nwith a single command.  For this to work, the object must have an ", " attribute\nto identify it.  For example, we could define an object that looks like a plus sign:", "A ", " element can then be used to add a copy of the plus sign\nobject to the scene.  The syntax is", "The value of the ", " attribute must be the ", " of the object,\nwith a \"#\" character added at the beginning. (Don't forget the\u00a0#.  If you leave it out,\nthe ", " element will simply be ignored.)  You can add a ", " attribute\nto the ", " element to apply a transformation to the copy of the object.  You can also apply\nstyle attributes, which will be used as default values for the attributes in the copy.  For\nexample, we can draw several plus signs with different transforms and stroke widths:", "Note that we can't change the color of the plus sign, since it already specifies\nits own stroke color.", "An object that has been defined in the ", " section can also be used\nas a sub-object in other object definitions.  This makes it possible to create\na hierarchy with multiple levels.  Here is an example from ", "\nthat defines a \"wheel\" object, then uses two copies of the wheel as sub-objects in a \n\"cart\" object:", "The SVG file goes on to add one copy of the wheel and four copies of the\ncart to the image.  The four carts have different colors and transforms.\nHere is the image:", "\n", "SVG has a number of advanced features that I won't discuss here, but I do want to\nmention one: ", ".  It is possible to animate almost any property\nof an SVG object, including geometry, style, and transforms.  The syntax for animation\nis itself fairly complex, and I will only do a few examples.  But I will tell you enough\nto produce a fairly complex hierarchical animation like the \"cart-and-windmills\"\nexample that was discussed and used as a demo in ", ".\nAn SVG version of that animation can be found in ", ".\nHere is what it looks like, although some web browsers might show it as a static\nimage instead of an animation:", "\n", "Many attributes of a shape element can be animated by adding an ", "\nelement to the content of the shape element.   Here is an example that makes a rectangle\nmove across the image from left to right:", "Note that the ", " is nested inside the ", ".\nThe ", " attribute tells which attribute of the ", "\nis being animated, in this case,\u00a0", ".  The ", " and ", " attributes\nsay that ", " will take on values from 0 to 430.  The ", " attribute is the\n\"duration\", that is, how long the animation lasts; the value \"7s\" means \"7 seconds.\"\nThe attribute ", "=\"indefinite\" means that after the animation completes,\nit will start over, and it will repeat indefinitely, that is, as long as the image is\ndisplayed.  If the ", " attribute is omitted, then after the animation\nruns once, the rectangle will jump back to its original position and remain there.\nIf ", " is replaced by ", "=\"freeze\", then after the animation runs,\nthe rectangle will br frozen in its final position, instead of jumping back to the starting\nposition.  The animation begins when the image first loads.  If you want the animation to\nstart at a later time, you can add a ", " attribute whose value gives the time\nwhen the animation should start, as a number of seconds after the image loads.", "What if we want the rectangle to move back and forth between its initial and final\nposition?  For that, we need something called ", ",\nwhich is an important idea in its own right.  The ", " and ", " attributes\nallow you to specify values only for the beginning and end of the animation.  In a keyframe\nanimation, values are specified at additional times in the middle of the animation.\nFor a keyframe animation in SVG, the ", " and ", " attributes are replaced\nby ", " and ", ".  Here is our moving rectangle example,\nmodified to use keyframes:", "The ", " attribute is a list of numbers, separated by semicolons.\nThe numbers are in the range 0 to 1, and should be in increasing order.  The first number\nshould be 0 and the last number should be 1.  A number specifies a time during the animation,\nas a fraction of the complete animation.  For example, 0.5 is a point half-way through the\nanimation, and 0.75 is three-quarters of the way.  The ", " attribute is a list\nof values, with one value for each key time.  In this case, the value for ", " is\n0 at the start of the animation, 430 half-way through the animation, and 0 again at the\nend of the animation.  Between the key times, the value for ", " is obtained by interpolating\nbetween the values specified for the key times.  The result in this case is that the rectangle\nmoves from left to right during the first half of the animation and then back from right to\nleft in the second half.", "Transforms can also be animated, but you need to use the ", "\ntag instead of ", ", and you need to add a ", " attribute to specify\nwhich transform you are animating, such as \"rotate\" or \"translate\".  Here, for example,\nis a transform animation applied to a group:", "The animation shows a growing \"tree\" made from a green triangle and a brown rectangle.\nIn the animation, the transform goes from ", "(0,0) to ", "(0.4,0.7).\nThe animation starts 3 seconds after the image loads and lasts 15 seconds.  At the end\nof the animation, the tree freezes at its final scale.  The ", " attribute\non the ", " element specifies the scale that is in effect until the animation\nstarts.  (A scale factor of 0 collapses the object to size zero, so that it is invisible.)\nYou can find this example, along with a moving rectangle and a keyframe animation, in \nthe sample file ", ". Here is the\nanimation itself.  To see the growing trees, you might have to reload this page or view\nthe image in a separate window:", "\n", "You can create animated objects in the ", " section of an SVG file,\nand you can apply animation to ", " elements.  This makes it possible\nto create hierarchical animations.  Here is a simple example:", "\n", "The example shows a rotating hexagon with a rotating square at each vertex of the\nhexagon.  The hexagon is constructed from six copies of one object, with a different rotation\napplied to each copy.  (A copy of the basic object is shown in the image to the right of the\nhexagon.)  The square is defined as an animated object with its own rotation.  It is used\nas a sub-object in the hexagon.  The rotation that is applied to the hexagon applies to the\nsquare, on top of its own built-in rotation.  That's what makes this an example of\nhierarchical animation.", "If you look back at the ", " \nexample now, you can probably see how to do the animation.  Don't forget to check out the source code,\nwhich is surprisingly short!"], "chapter_title": "Two-Dimensional Graphics", "id": 2.7}, {"section_title": "Pixels, Coordinates, and Colors", "chapter_id": "Chapter 2", "section_id": "Section 2.1", "content": ["To create a two-dimensional image, each point in the image is\nassigned a color.  A point in 2D can be identified by a pair of numerical\ncoordinates.  Colors can also\nbe specified numerically.  However, the assignment of numbers to points\nor colors is somewhat arbitrary.  So we need to spend some time\nstudying ", ", which associate\nnumbers to points, and ", ", which\nassociate numbers to colors.", "A digital image is made up of rows and columns of ", ".\nA pixel in such an image can be specified by saying which column and which row contains\nit.  In terms of coordinates, a pixel can be identified by a pair of integers giving\nthe column number and the row number.  For example, the pixel with coordinates (3,5)\nwould lie in column number 3 and row number 5.  Conventionally, columns are numbered from left\nto right, starting with zero.  Most graphics systems, including the ones we will study\nin this chapter, number rows from top to bottom, starting from zero.  Some, including\nOpenGL, number the rows from bottom to top instead.\n", "\n", "Note in particular that the pixel that is identified by a pair of\ncoordinates (", ",", ") depends on the choice of coordinate system.\nYou always need to know what coordinate system is in use before you know what\npoint you are talking about.", "Row and column numbers identify a pixel, not a point.  A pixel contains many points;\nmathematically, it contains an infinite number of points.  The goal of computer graphics is not\nreally to color pixels\u2014it is to create and manipulate images.  In some ideal\nsense, an image should be defined by specifying a color for each point, not just for\neach pixel.  Pixels are an approximation.  If we imagine that there is a true, ideal\nimage that we want to display, then any image that we display by coloring pixels is\nan approximation.  This has many implications.", "Suppose, for example, that we want to draw a line segment.  A mathematical line\nhas no thickness and would be invisible.  So we really want to draw a thick line\nsegment, with some specified width.  Let's say that the line should be \none pixel wide.  The problem is that, unless the line is horizontal or vertical,\nwe can't actually draw the line by coloring pixels.  A diagonal geometric line will cover some\npixels only partially. It is not possible to make part of a pixel black and part of it white.\nWhen you try to draw a line with black and white pixels only, the result is a jagged\nstaircase effect.  This effect is an example of something called \"aliasing.\"  Aliasing can also be seen\nin the outlines of characters drawn on the screen and in diagonal or curved boundaries between\nany two regions of different color.  (The term aliasing likely comes from the fact that\nideal images are naturally described in real-number coordinates.  When you try to represent\nthe image using pixels, many real-number coordinates will map to the same integer\npixel coordinates; they can all be considered as different names or \"aliases\" for the\nsame pixel.)", "\n", "  is a term for techniques that are designed to\nmitigate the effects of aliasing.  The idea is that when a pixel is only partially\ncovered by a shape, the color of the pixel should be a mixture of the color of the\nshape and the color of the background.  When drawing a black line on a white background,\nthe color of a partially covered pixel would be gray, with the shade of gray depending\non the fraction of the pixel that is covered by the line.  (In practice, calculating this\narea exactly for each pixel would be too difficult, so some approximate method is used.)\nHere, for example, is a geometric line, shown on the left, along with two approximations\nof that line made by coloring pixels.  The lines are greately magnified so that you can see the\nindividual pixels.  The line on the right is drawn using antialiasing, while the one in the \nmiddle is not:", "\n", "Note that antialiasing does not give a perfect image, but it can reduce the \"jaggies\" that \nare caused by aliasing (at least when it is viewed on a normal scale).", "There are other issues involved in mapping real-number coordinates to pixels.\nFor example, which point in a pixel should correspond to integer-valued coordinates\nsuch as (3,5)?  The center of the pixel?  One of the corners of the pixel?\nIn general, we think of the numbers as referring to the top-left corner of the pixel.\nAnother way of thinking about this is to say that integer coordinates refer to the\nlines between pixels, rather than to the pixels themselves.  But that still\ndoesn't determine exactly which pixels are affected when a geometric shape is drawn.\nFor example, here are two lines drawn using HTML canvas graphics,\nshown greatly magnified.  The lines were specified to be colored black with a\none-pixel line width:", "\n", "The top line was drawn from the point (100,100) to the point (120,100).  In\ncanvas graphics, integer coordinates corresponding to the lines between pixels, \nbut when a one-pixel line is drawn, it\nextends one-half pixel on either side of the infinitely thin geometric line.  So for the top line,\nthe line as it is drawn lies half\nin one row of pixels and half in another row.  The graphics system, which uses\nantialiasing, ", " the line by coloring both\nrows of pixels gray.  The bottom line was drawn from the point (100.5,100.5) to\n(120.5,120.5).  In this case, the line lies exactly along one line of pixels,\nwhich gets colored black.  The gray pixels at the ends of the bottom line have to do with\nthe fact that the line only extends halfway into the pixels at its endpoints.\nOther graphics systems might render the same lines differently.", "The following interactive demo lets you experiment with\npixels and antialiasing.\n\n(Note that in any of the interactive demos that accompany this book, you can click\nthe question mark icon in the upper left for more information about how to use it.)", "\n", "\n", "All this is complicated further by the fact that pixels aren't what they used to\nbe.   Pixels today are smaller!  The resolution of a display device can be measured\nin terms of the number of pixels per inch on the display, a quantity referred to\nas PPI (pixels per inch) or sometimes DPI (dots per inch).  Early screens tended to have\nresolutions of somewhere close to 72 PPI.  At that resolution, and at a typical viewing\ndistance, individual pixels are clearly visible.  For a while, it seemed like most\ndisplays had about 100 pixels per inch, but high resolution displays today can have\n200, 300 or even 400 pixels per inch.  At the highest resolutions, individual\npixels can no longer be distinguished.", "The fact that pixels come in such a range of sizes is a problem if we use\ncoordinate systems based on pixels.  An image created assuming that there are\n100 pixels per inch will look tiny on a 400 PPI display.  A one-pixel-wide line\nlooks good at 100 PPI, but at 400 PPI, a one-pixel-wide line is probably\ntoo thin.", "In fact, in many graphics systems, \"pixel\" doesn't really refer to the \nsize of a physical pixel.  Instead, it is just another unit of measure, which is\nset by the system to be something appropriate.  (On a desktop system, a pixel\nis usually about one one-hundredth of an inch.  On a smart phone, which is\nusually viewed from a closer distance, the value might be closer to 1/160 inch.\nFurthermore, the meaning of a pixel as a unit of measure can change when,\nfor example, the user applies a magnification to a web page.)", "Pixels cause problems that have not been completely solved.  Fortunately, they\nare less of a problem for ", ", which is mostly what we\nwill use in this book.  For vector graphics, pixels only become an issue during\n", ", the step in which a vector image is converted\ninto pixels for display.  The vector image itself can be created using any\nconvenient coordinate system.  It represents an idealized, resolution-independent\nimage.  A rasterized image is an approximation of that ideal image, but how to\ndo the approximation can be left to the display hardware.", "When doing 2D graphics, you are given a rectangle in which you want to\ndraw some ", ".\nPrimitives are specified using some coordinate system on the rectangle.\nIt should be possible to select a coordinate system that is appropriate\nfor the application.  For example, if the rectangle represents a floor\nplan for a 15 foot by 12 foot room, then you might want to use a\ncoordinate system in which the unit of measure is one foot and the\ncoordinates range from 0 to 15 in the horizontal direction and 0 to\n12 in the vertical direction.  The unit of measure in this case is feet\nrather than pixels, and one foot can correspond to many pixels in the\nimage.  The coordinates for a pixel will, in general, be real numbers\nrather than integers.  In fact, it's better to forget about pixels\nand just think about points in the image.  A point will have a pair\nof coordinates given by real numbers.", "To specify the coordinate system on a rectangle, you just have\nto specify the horizontal coordinates for the left and right\nedges of the rectangle and the vertical coordinates for the\ntop and bottom.  Let's call these values ", ",\n", ", ", ", and ", ".  Often, they are\nthought of as ", ", ", ", ", ", and ", ",\nbut there is no reason to assume that, for example, ", "\nis less than ", ".  We might want a coordinate system in\nwhich the vertical coordinate increases from bottom to top instead\nof from top to bottom.  In that case, ", " will correspond to\nthe maximum ", "-value instead of the minimum value.", "To allow programmers to specify the coordinates system that\nthey would like to use, it would be good to have a subroutine such as", "The graphics system would then be responsible for automatically\n ", " the  \ncoordinates from the specfiied coordinate system into pixel coordinates.\nSuch a subroutine might not be available, so it's useful to see how the transformation\nis done by hand.  Let's consider the general case.  Given coordinates for a point in \none coordinate system, we want to find the coordinates for the same point in a second \ncoordinate system.  (Remember that a coordinate system is just a way of assigning numbers\nto points.  It's the points that are real!)  Suppose that the horizontal and vertical\nlimits are ", ", ", ", ", ", and ", " for\nthe first coordinate system, and are ", ", ", ", ", ", \nand ", " for the second.  Suppose that a point has coordinates (", ")\nin the first coordinate system.  We want to find the coordinates (", ")\nof the point in the second coordinate system", "\n", "Formulas for ", " and ", " are then given by", "The logic here is that ", " is located at a certain fraction of the distance from ", " to\n", ".  That fraction is given by", "The formula for ", " just says that ", " should lie at the same fraction of the distance\nfrom ", " to ", ".  You can also check the formulas by testing that\nthey work when ", " is equal to ", " or to ", ", and when\n", " is equal to ", " or to ", ".", "As an example, suppose that we want to transform some real-number coordinate system\nwith limits ", ", ", ", ", ", and ", " into pixel\ncoordinates that range from 0 at left to 800 at the right and from 0 at the top\n600 at the bottom.  In that case, ", " and ", " are zero, and \nthe formulas become simply\n", "Of course, this gives ", " and ", " as real numbers, and they will have\nto be rounded or truncated to integer values if we need integer coordinates for pixels.\nThe reverse transformation\u2014going from pixel coordinates to real number coordinates\u2014is\nalso useful.  For example, if the image is displayed on a computer screen, and you want to\nreact to mouse clicks on the image, you will probably get the mouse coordinates in terms\nof integer pixel coordinates, but you will want to transform those pixel coordinates into \nyour own chosen coordinate system.", "In practice, though, you won't usually have to do the transformations yourself, since most\ngraphics APIs provide some higher level way to specify transforms.  We will talk more about\nthis in ", ".", "The ", " of a rectangle is the ratio of its width to its height.\nFor example an aspect ratio of 2:1 means that a rectangle is twice as wide as it is tall,\nand an aspect ratio of 4:3 means that the width is 4/3 times the height.  Although aspect ratios\nare often written in the form ", ":", ", I will use the term to refer to the\nfraction ", ".  A square has aspect ratio equal to\u00a01.  A rectangle with aspect\nratio 5/4 and height 600 has a width equal to 600*(5/4), or 750.", "A coordinate system also has an aspect ratio.  If the horizontal and vertical limits for\nthe coordinate system are ", ", ", ", ", ", and ", ", as \nabove, then the aspect ratio is the absolute value of", "If the coordinate system is used on a rectangle with the same aspect ratio, then when viewed in\nthat rectangle, one unit in the horizontal direction will have the same apparent length as a unit in the\nvertical direction.  If the aspect ratios don't match, then there will be some distortion.\nFor example, the shape defined by the equation ", "\u00a0+", "\u00a0=\u00a09\nshould be a circle, but that will only be true if the aspect ratio of the (", ",", ")\ncoordinate system matches the aspect ratio of the drawing area.", "\n", "It is not always a bad thing to use different units of length in the vertical and horizontal \ndirections.  However, suppose that you want to use coordinates with limits ", ", ", ", \n", ", and ", ", and that you do want to preserve the aspect ratio.  In that case,\ndepending on the shape of the display rectangle, you might have to adjust the values either of\n", " and ", " or of ", " and ", " to make the aspect ratios match:\n", "\n", "We will look more deeply into geometric transforms later in the chapter, and at that time,\nwe'll see some program code for setting up coordinate systems.", "We are talking about the most basic foundations of computer graphics.  One of those is\ncoordinate systems.  The other is color.  Color is actually a surprisingly complex topic.\nWe will look at some parts of the topic that are most relevant to computer graphics\napplications.", "The colors on a computer screen are produced as combinations of red, green, and blue light.\nDifferent colors are produced by varying the intensity of each type of light.  A color can be\nspecified by three numbers giving the intensity of red, green, and blue in the color.\nIntensity can be specified as a number in the range zero, for minimum intensity, to one, for\nmaximum intensity.  This method of specifying color is called the ", ",\nwhere RGB stands for Red/Green/Blue.  For example, in the RGB color model, the number triple \n(1,\u00a00.5,\u00a00.5) represents the color obtained by setting red to full intensity, while \ngreen and blue are set to half intensity. The red, green, and blue values for a color\nare called the ", " of that color \nin the RGB color model.", "Light is made up of waves with a variety of wavelengths. \nA pure color is one for which all the light has the same wavelength,\nbut in general, a color can contain many wavelengths\u2014mathematically,\nan infinite number.  How then can we represent all colors by combining just red, green, and\nblue light?  In fact, we can't quite do that.", "You might have heard that combinations of the three basic, or \"primary,\" colors are sufficient\nto represent all colors, because the human eye has three kinds of color sensors that detect red,\ngreen, and blue light.  However, that is only an approximation.  The eye does contain three\nkinds of color sensor.  The sensors are called \"cone cells.\"\nHowever, cone cells do not respond exclusively to red, green, and blue light.  Each kind\nof cone cell responds, to a varying degree, to wavelengths of light in a wide range.  A given\nmix of wavelengths will stimulate each type of cell to a certain degree, and the intensity of\nstimulation determines the color that we see.  A different mixture of wavelengths that stimulates\neach type of cone cell to the same extent will be perceived as the same color.  So a perceived\ncolor can, in fact, be specified by three numbers giving the intensity of stimulation of\nthe three types of cone cell. However, it is not possible to produce all possible patterns of\nstimulation by combining just three basic colors, no matter how those colors are chosen.  \nThis is just a fact about the way our eyes actually work; it might have been different.\nThree basic colors can produce a reasonably large fraction of the set of perceivable colors,\nbut there are colors that you can see in the world that you will never see on your computer\nscreen.  (This whole discussion only applies to people who actually have three kinds of\ncone cell.  Color blindness, where someone is missing one or more kinds of cone cell, is\nsurprisingly common.)", "The range of colors that can be produced by a device such as a computer screen is called\nthe ", " of that device.  Different computer screens can have different\ncolor gamuts, and the same RGB values can produce somewhat different colors on different screens.\nThe color gamut of a color printer is noticeably different\u2014and probably\nsmaller\u2014than the color gamut of a screen, which explain why a printed image probably\ndoesn't look exactly the same as it did on the screen.  (Printers, by the way, make colors\ndifferently from the way a screen does it.  Whereas a screen combines light to make a color, \na printer combines inks or dyes.  Because of this difference, colors meant for printers are often\nexpressed using a different set of basic colors.  A common color model for printer colors\nis CMYK, using the colors cyan, magenta, yellow, and black.)", "In any case, the most common color model for computer graphics is RGB.  RGB colors are most\noften represented using 8 bits per color component, a total of 24 bits to represent a color.\nThis representation is sometimes called \"24-bit color.\"\nAn 8-bit number can represent 2", ", or 256, different values, which we can take to\nbe the positive integers from 0 to 255. A\u00a0color is then specified as a triple of integers\n(r,g,b) in that range.", "This representation works well because 256 shades of red, green, and\nblue are about as many as the eye can distinguish.  In applications where images are processed\nby computing with color components, it is common to use additional bits per color component,\nto avoid visual effects that might occur due to rounding errors in the computations.\nSuch applications might use a 16-bit integer or even a 32-bit floating point value for\neach color component.  On the other hand, sometimes fewer bits are used.  For example, one\ncommon color scheme uses 5 bits for the red and blue components and 6 bits for the green\ncomponent, for a total of 16 bits for a color.  (Green gets an addition bit because\nthe eye is more sensitive to green light than to red or blue.)  This \"16-bit color\" saves memory\ncompared to 24-bit color and was more common when memory was more expensive.", "There are many other color models besides RGB.  RGB is sometimes criticized as being unintuitive.\nFor example, it's not obvious to most people that yellow is made of a combination of red and green.\nThe closely related color models ", " \nand ", " describe the same set of colors as RGB, but attempt\nto do it in a more intuitive way.  (HSV is sometimes called HSB, with the \"B\"\nstanding for \"brightness.\"  HSV and HSB are exactly the same model.)", "The \"H\" in these models stands for \"hue,\" a basic spectral color.\nAs H increases, the color changes from red to yellow to green to cyan to blue to magenta, and then\nback to red.  The value of H is often taken to range from 0 to 360, since the colors can be thought\nof as arranged around a circle with red at both 0 and 360 degrees.", "The \"S\" in HSV and HSL stands for \"saturation,\"\nand is taken to range from 0 to 1.  A saturation of 0 gives a shade of gray (the shade depending on\nthe value of V or L). A saturation of 1 gives a \"pure color,\" and decreasing the saturation is\nlike adding more gray to the color.  \"V\"\u00a0stands for \"value,\" and \"L\" stands for \"lightness.\"\nThey determine how bright or dark the color is.  The main difference is that in the HSV model, the\npure spectral colors occur for V=1, while in HSL, they occur for L=0.5.", "Let's look at some colors in the HSV color model.   The illustration below shows\ncolors with a full range of H-values, for S and V equal to 1 and to 0.5.  Note that for S=V=1, you\nget bright, pure colors.  S=0.5 gives paler, less saturated colors.  V=0.5 gives darker colors.", "\n", "It's probably easier to understand color models by looking at some actual colors\nand how they are represented. Here is an interactive demo that \nlet's you do that for the RGB and HSV color models:\n", "\n", "\n", "Often, a fourth component is added to color models.  The fourth component is called\n", ", and color models that use it are\nreferred to by names such as RGBA and HSLA.  Alpha is not a color as such.  It is usually used\nto represent transparency.  A color with maximal alpha value is fully opaque; that is, it is\nnot at all transparent.  A color with alpha equal to zero is completely transparent and therefore\ninvisible.  Intermediate values give translucent, or partly transparent, colors.\nTransparency determines what happens when you draw with one color (the foreground color) \non top of another color (the background color).  If the foreground color is fully opaque, it \nsimply replaces the background color.  If the foreground color is partly transparent, then\nthen it is blended with the background color.  Assuming that the alpha component ranges from\n0\u00a0to\u00a01, the color that you get can be computed as", "This computation is done separately for the red, blue, and green color components.\nThis is called ", ".\nThe effect is like viewing the background through colored glass; the color of the glass\nadds a tint to the background color.  This type of blending is not the only possible use\nof the alpha component, but it is the most common.", "An RGBA color model with 8 bits per component uses a total of 32 bits to represent a color.\nThis is a convenient number because integer values are often represented using 32-bit values.\nA 32-bit integer value can be interpreted as a 32-bit RGBA color.  How the color components are\narranged within a 32-bit integer is somewhat arbitrary.  The most common layout is to store\nthe alpha component in the eight high-order bits, followed by red, green, and blue.  (This should\nprobably be called ARGB color.)  However, other layouts are also in use."], "chapter_title": "Two-Dimensional Graphics", "id": 2.1}, {"section_title": "HTML Canvas Graphics", "chapter_id": "Chapter 2", "section_id": "Section 2.6", "content": ["Most modern web browsers support a 2D graphics ", " that can be used\nto create images on a web page.  The API is implemented using ", ", the client-side programming \nlanguage for the web.  I won't cover the JavaScript language in this section.  To understand the \nmaterial presented here, you don't need to know much about it.  Even if you\nknow nothing about it at all, you can learn something about its 2D graphics API and\nsee how it is similar to, and how it differs from, the Java API presented in the\n", ".  (For a short review\nof JavaScript, see ", " in ", ".)", "The visible content of a web page is made up of \"elements\" such\nas headlines and paragraphs.  The content is specified using the ", " language.\nA \"canvas\" is an HTML element. It appears on the page as a blank rectangular area which can\nbe used as a drawing surface by what I am calling the \"", "\" graphics API.\nIn the source code of a web page, a canvas element is created with code of the form", "The ", " and ", " give the size of the drawing area, in pixels.  The\n", " is an identifier that can be used to refer to the canvas in JavaScript.", "To draw on a canvas, you need a graphics context.  A graphics context is an object that\ncontains functions for drawing shapes.  It also contains variables that record the current graphics \nstate, including  things like the current drawing color, transform, and font.  Here, I will \ngenerally use ", " as the name of the variable that refers to the graphics context, \nbut the variable name is, of course, up to the programmer.  This graphics context plays the same role in \nthe canvas API that a variable of type ", " plays in Java.\nA typical starting point is\n", "The first line gets a reference to the canvas element on the web page, using its ", ".\nThe second line creates the graphics context for that canvas element.  (This code will\nproduce an error in a web browser that doesn't support canvas, so you might add some error\nchecking such as putting these commands inside a ", " statement.)", "Typically, you will store the canvas graphics context in a global variable\nand use the same graphics context throughout your program.  This is in contrast\nto Java, where you typically get a new ", " context\neach time the ", "() method is called, and that new context\nis in its initial state with default color and stroke\nproperties and with no applied transform.  When a graphics context \ncontext is global, changes made to the state in one function\ncall will carry over to subsequent function calls, unless you do something to limit\ntheir effect.  This can actually lead to a fairly common type of bug: For example, \nif you apply a 30-degree rotation in a function, those rotations will ", "\neach time the function is called, unless you do something to undo the previous rotation\nbefore applying the next rotation.", "The rest of this section will be mostly concerned with describing what you can do with\na canvas graphics context.  But here, for the record, is the complete source code for\na very minimal web page that uses canvas graphics:\n", "For a more complete, though still minimal, example, look at the sample page\n", ".  (You should look at the page\nin a browser, but you should also read the source code.)  This example shows\nhow to draw some basic shapes using canvas graphics, and you can use it as\na basis for your own experimentation.  There are also three more advanced\n\"starter\" examples:  ", " adds\nsome utility functions for drawing shapes and setting up a coordinate system;\n", " adds animation and includes\na simple ", " example; and\n", " shows how to respond to keyboard\nand mouse events.", "The default coordinate system on a canvas is the usual: The unit of measure is one pixel;\n(0,0) is at the upper left corner; the ", "-coordinate increases to the right;\nand the ", "-coordinate increases downward.   The range of ", " and ", "\nvalues are given by the ", " and ", " properties of the ", "\nelement.  The term \"pixel\" here for the unit of measure is not really correct.  \nProbably, I should say something like \"one nominal pixel.\"\nThe unit of measure is one pixel at typical desktop resolution with no magnification.\nIf you apply a magnification to a browser window, the unit of measure gets stretched.\nAnd on a high-resolution screen, one unit in the default coordinate system might \ncorrespond to several actual pixels on the display device.", "The canvas API supports only a very limited set of basic shapes. In fact, the\nonly basic shapes are rectangles and text.  Other shapes must be created as paths.\nShapes can be ", " and \n", ".  That includes text: When you stroke a string of\ntext, a pen is dragged along the outlines of the characters; when you fill a string,\nthe insides of the characters are filled.  It only really makes sense to stroke text\nwhen the characters are rather large.  Here are the functions for drawing\nrectangles and text, where ", " refers to the object that represents\nthe graphics context:", "A path can be created using functions in the graphics context.  The context keeps track of\na \"current path.\"  In the current version of the API, paths are not represented by objects,\nand there is no way to work with more than one path at a time or to keep a copy of a path\nfor later reuse.  Paths can contain lines, ", ", and circular arcs.\nHere are the most common functions for working with paths:", "Creating a curve with these commands does not draw anything.  To get something visible\nto appear in the image, you must fill or stroke the path.", "The commands ", "() and ", "() are used to fill\nand to stroke the current path.  If you fill a path that has not been closed, the fill\nalgorithm acts as though a final line segment had been added to close the path.\nWhen you stroke a shape, it's the center of the virtual pen that moves along the path.\nSo, for high-precision canvas drawing, it's common to\nuse paths that pass through the centers of pixels rather than through their corners.\nFor example, to draw a line that extends from the pixel with coordinates (100,200) to\nthe pixel with coordinates (300,200), you would actually stroke the geometric line\nwith endpoints (100.5,200.5) and (100.5,300.5).  We should look at some examples.\nIt takes four steps to draw a line:", "Remember that the line remains as part of the current path until the\nnext time you call ", "().  Here's how to draw a filled,\nregular octagon centered at (200,400) and with radius 100:", "The function ", "() can be used to draw a circle, with a start \nangle of 0 and an end angle of ", ".  Here's a filled circle with radius \n100, centered at 200,300:", "To draw just the outline of the circle, use ", "()\nin place of ", "().  You can apply both operations to the same path.\nIf you look at the details of ", "(),\nyou can see how to draw a wedge of a circle:", "There is no way to draw an oval that is not a circle, except by using \ntransforms.  We will cover that later in this section.  But JavaScript has\nthe interesting property that it is possible to add new functions and \nproperties to an existing object.  The sample program\n", " shows how to\nadd functions to a graphics context for drawing lines, ovals, and\nother shapes that are not built into the API.", "Attributes such as line width that affect the visual appearance of\nstrokes and fills are stored as properties of the graphics context.\nFor example, the value of ", " is a number that\nrepresents the width that will be used for strokes.  (The width is \ngiven in pixels for the default coordinate system, but it is subject \nto transforms.)  You can change the line width by assigning a value\nto this property:", "The change affects subsequent strokes.  You can also read the current\nvalue:", "The property ", " controls the appearance of\nthe endpoints of a stroke.  It can be set to\n\"round\", \"square\", or \"butt\".  The quotation marks are part of the value.  For example,", "Similarly, ", " controls\nthe appearance of the point where one segment of a stroke joins another\nsegment; its possible values are \"round\", \"bevel\", or \"miter\".  (Line\nendpoints and joins were discussed in ", ".)", "Note that the values for ", " and ", "\nare strings.  This is a somewhat unusual aspect of the API.  Several other properties\nof the graphics context take values that are strings, including the properties that\ncontrol the colors used for drawing and the font that is used for drawing\ntext.", "Color is controlled by the values of the properties ", "\nand ", ".  The graphics context maintains separate styles\nfor filling and for stroking.  A\u00a0solid color for stroking or filling is specified\nas a string.  Valid color strings are ones that can be used in ", ", the language\nthat is used to specify colors and other style properties of elements on web pages.\nMany solid colors can be specified by their names, such as \"red\", \"black\", and\n\"beige\".  An ", " can be specified as a string of the\nform \"rgb(r,g,b)\", where the parentheses contain three numbers in the range\n0 to 255 giving the red, green, and blue components of the color.  Hexadecimal color\ncodes are also supported, in the form \"#XXYYZZ\" where XX, YY, and ZZ are two-digit\nhexadecimal numbers giving the RGB color components.  For example,", "The style can actually be more complicated\nthan a simple solid color:  ", " and \n", " are also supported.  As an \nexample, a gradient can be created with a series of steps such as", "The first line creates a linear gradient that will vary in color along\nthe line segment from the point (420,420) to the point (550,200).\nColors for the gradient are specified by the ", " function:\nthe first parameter gives the fraction of the distance from the initial\npoint to the final point where that color is applied, and the second is a string\nthat specifies the color itself.  A color stop at 0 specifies\nthe color at the initial point; a color stop at 1 specifies the color\nat the final point.  Once a gradient has been created, it can be used both\nas a fill style and as a stroke style in the graphics context.", "Finally, I note that the font that is used for drawing text is the\nvalue of the property ", ".  The value is a string\nthat could be used to specify a font in ", ".\nAs such, it can be fairly complicated, but the simplest versions\ninclude a font-size (such as ", " or ", ") and a font-family\n(such as ", ", ", ", ", ", or the name of any font\nthat is accessible to the web page).\nYou can add ", " or ", " or both to the front of the string.\nSome examples:\n", "The default is \"10px sans-serif,\" which is usually too small.  Note that text, like all drawing, is\nsubject to coordinate transforms.  Applying a scaling operation changes the\nsize of the text, and a negative scaling factor can produce mirror-image text.", "A graphics context has three basic functions for modifying the current transform\nby scaling, rotation, and translation.  There are also functions that will compose\nthe current transform with an arbitrary transform and for completely\nreplacing the current transform:", "Note that there is no ", ", but you can apply a shear as\na general transform.  For example, for a horizontal shear with shear factor\u00a00.5, use", "To implement hierarchical modeling, as discussed in ", ", \nyou need to be able to save\nthe current transformation so that you can restore it later.  Unfortunately,\nno way is provided to read the current transformation from a canvas graphics\ncontext.  However, the graphics context itself keeps a stack of transformations\nand provides methods for pushing and popping the current transformation.  In fact,\nthese methods do more than save and restore the current transformation.  They actually\nsave and restore almost the entire state of the graphics context, including properties\nsuch as current colors, line width, and font (but not the current path):", "Using these methods, the basic setup for drawing an object with a modeling\ntransform becomes:", "Note that if drawing the object includes any changes to attributes\nsuch as drawing color, those changes will be also undone by the call to ", "().\nIn hierarchical graphics, this is usually what you want, and it eliminates the\nneed to have extra statements for saving and restoring things like color.", "To draw a hierarchical model, you need to traverse a ", ", either\nprocedurally or as a data structure.  It's pretty much the same as in Java.\nIn fact, you should see that the basic concepts that you learned about\ntransformations and modeling carry over to the canvas graphics API.  Those\nconcepts apply very widely and even carry over to 3D graphics APIs, with\njust a little added complexity.  The demo program\n", " from ", "\nimplements hierarchical modeling using the 2D canvas API.", "Now that we know how to do transformations, we can see how to draw an oval\nusing the canvas API.  Suppose that we want an oval with center at (", "),\nwith horizontal radius ", " and with vertical radius ", ".\nThe idea is to draw a circle of radius 1 with center at (0,0), then transform\nit.  The circle needs to be scaled by a factor of ", " horizontally and\n", " vertically.  It should then be translated to move its center from\n(0,0) to (", ").  We can use ", "() and ", "()\nto make sure that the transformations only affect the circle.  Recalling that\nthe order of transforms in the code is the opposite of the order in which they\nare applied to objects, this becomes:", "Note that the current path is ", " affected by the\ncalls to ", "() and ", "().  So,\nin the example, the oval-shaped path is not discarded when\n", "() is called. When ", "() is\ncalled at the end, it is the oval-shaped path that is stroked.  On the\nother hand, the line width that is used for the stroke is not affected\nby the scale transform that was applied to the oval.  Note that if\nthe order of the last two commands were reversed, then the line width\nwould be subject to the scaling.", "There is an interesting point here about transforms and paths.  In the HTML canvas\nAPI, the points that are used to create a path are transformed by the\ncurrent transformation before they are saved.  That is, they are saved\nin pixel coordinates.  Later, when the path is stroked or filled, the current\ntransform has no effect on the path (although it can affect,\nfor example, the line width when the path is stroked).  In particular,\nyou can't make a path and then apply different transformations.  For example,\nyou can't make an oval-shaped path, and then use it to draw several ovals\nin different positions.  Every time you draw the oval, it will be in the\nsame place, even if different translation transforms are applied to\nthe graphics context.", "The situation is different in Java, where the coordinates that are stored\nin the path are the actual numbers that are used to specify the path,\nthat is, the ", ".  When the path is stroked or\nfilled, the transformation that is in effect at that time is applied\nto the path.  The path can be reused many times\nto draw copies with different transformations.  This comment is offered as an\nexample of how APIs that look very similar can have subtle differences.", "In ", ", we looked at the sample program\n", ", which uses a\n", " both to implement an\n", " and to allow direct manipulation of\nthe colors of individual pixels.  The same ideas can be applied\nin HTML canvas graphics, although the way it's done is a little different.\nThe sample web application ", "\ndoes pretty much the same thing as the Java program (except for the\nimage filters).", "Here\nis a live demo \nversion of the program that has the same functionality.\nYou can try it out to see how the various drawing tools work.  Don't\nforget to try the \"Smudge\" tool! (It has to be applied to shapes that\nyou have already drawn.)", "\n", "\n", "For JavaScript, a web page is represented as a data structure, defined\nby a standard called the ", ", or Document Object model.\nFor an off-screen canvas, we can use a ", " that is not part of\nthat data structure and therefore is not part of the page.\nIn JavaScript, a ", "\ncan be created with the function call ", "(\"canvas\").\nThere is a way to add this kind of dynamically created canvas to the\nDOM for the web page, but it can be used as an off-screen canvas without doing so.\nTo use it, you have to set its width and height properties, and you\nneed a graphics context for drawing on it.  Here, for example, is\nsome code that creates a 640-by-480 canvas, gets a graphics\ncontext for the canvas, and fills the whole canvas with white:", "The sample program lets the user drag the mouse on the canvas to\ndraw some shapes. The off-screen canvas holds the official copy of\nthe picture, but it is not seen by the user.  There is also an\non-screen canvas that the user sees.  The off-screen canvas is copied \nto the on-screen canvas whenever the picture is modified.  \nWhile the user is dragging the mouse to\ndraw a line, oval, or rectangle, the new shape is actually\ndrawn on-screen, over the contents of the off-screen canvas. It is\nonly added to the off-screen canvas when the user finishes the\ndrag operation. For the other tools, changes are made directly\nto the off-screen canvas, and the result is then copied to the\nscreen.  This is an exact imitation of the Java program.", "(The demo version shown above \nactually uses a somewhat different technique to accomplish the\nsame thing.  It uses two on-screen canvases, one located exactly\non top of the other.  The lower canvas holds the actual image.\nThe upper canvas is completely transparent, except when the\nuser is drawing a line, oval, or rectangle.  While the user\nis dragging the mouse to draw such a shape, the new shape\nis drawn on the upper canvas, where it hides the part of\nthe lower canvas that is beneath the shape.  When the user\nreleases the mouse, the shape is added to the lower canvas\nand the upper canvas is cleared to make it completely transparent\nagain.  Again, the other tools operate directly on the lower\ncanvas.)", "The \"Smudge\" tool in the ", " \nand demo is implemented by computing with the color component values of pixels in the image.\nThe implementation requires some way to read the colors of pixels in a canvas.  That can be \ndone with the function ", "(", "), where ", " is a 2D graphics\ncontext for the canvas.  The function reads the colors of a rectangle of pixels, where (", ") is\nthe upper left corner of the rectangle, ", " is its width, and ", " is its height.  The\nparameters are always expressed in pixel coordinates.  Consider, for example", "This returns the color data for a 20-by-10 rectangle in the upper left corner of the canvas.\nThe return value, ", ", is an object with properties ", ",\n", ", and ", ".  The ", " and ", " give the number of\nrows and columns of pixels in the returned data.  (According to the documentation, on a high-resolution \nscreen, they might not be the same as the width and height in the function call.  The data can be \nfor real, physical pixels on the display device, not the \"nominal\" pixels that are used in the pixel \ncoordinate system on the canvas. There might be several device pixels for each nominal pixel.\nI'm not sure whether this can really happen.)", "The value of ", " is an array, with four array elements for each pixel.  The four\nelements contain the red, blue, green, and alpha color components of the pixel, given as integers\nin the range 0 to 255.  For a pixel that lies outside the canvas, the four component values will\nall be zero.  The array is a value of type ", " whose elements are\n8-bit unsigned integers limited to the range 0 to 255.  This is one of JavaScript's\n", " datatypes, which can only hold values of a specific numerical type.\nAs an example, suppose that you just want to read the RGB color of one pixel, at coordinates (", ").\nYou can set", "Then the RGB color components for the pixel are R = ", "[0],\nG = ", "[1], and B = ", "[2].", "The function ", "(", ",", ",", ") is\nused to copy the colors from an image data object into a canvas, placing it into\na rectangle in the canvas with upper left corner at (", ").  The ", "\nobject can be one that was returned by a call to ", ", possibly\nwith its color data modified.  Or you can create a blank image data object by\ncalling ", "(", ") and fill it with data.", "Let's consider the \"Smudge\" tool in the sample program. When the user clicks the\nmouse with this tool, I use ", " to get the color data from a \n9-by-9 square of pixels surrounding the mouse location.  ", " is the graphics\ncontext for the canvas that contains the image.  Since I want to do real-number\narithmetic with color values, I copy the color components into another typed array,\none of type ", ", which can hold 32-bit floating point numbers.\nHere is the function that I call to do this:", "The floating point array, ", ", will be used for computing new\ncolor values for the image as the mouse moves.  The color values\nfrom this array will be copied into the image data object, ", ", \nwhich will them be used to put the color values into the image.  This is done in\nanother function, which is called for each point that is visited as the user\ndrags the Smudge tool over the canvas:", "In this function, a new color is computed for each pixel in a 9-by-9 square of\npixels around the mouse location.  The color is replaced by a weighted average\nof the current color of the pixel and the color of the corresponding pixel in the\n", ".  At the same time, the color in ", "\nis replaced by a similar weighted average.", "It would be worthwhile to try to understand this example to see how pixel-by-pixel\nprocessing of color data can be done.  See the \n", "\nof the example for more details.", "For another example of pixel manipulation, we can look at \nimage filters that modify an image by replacing the color of each pixel with\na weighted average of the color of that pixel and the 8 pixels that\nsurround it. Depending on the weighting factors that are used, the\nresult can be as simple as a slightly blurred version of the image, or\nit can something more interesting.", "Here is \nan an\ninteractive demo that lets you apply several different image filters to\na variety of images:", "\n", "\n", "The filtering operation in the demo uses the image data functions\n", ", ", ", and ", "\nthat were discussed above.  Color data from the entire image is obtained\nwith a call to ", ".  The results of the averaging \ncomputation are placed in a new image data object, and the resulting\nimage data is copied back to the image using ", ".", "The remaining question is, where do the original images come\nfrom, and how do they get onto the canvas in the first place?\nAn image on a web page is specified by an element in the web page\nsource such as", "The ", " attribute specifies the URL from which the image is\nloaded.  The optional ", " can be used to reference the image\nin JavaScript.  In the script,", "gets a reference to the object that represents the image in the\ndocument structure.  Once you have such an object, you can use it to\ndraw the image on a canvas.  If ", " is a graphics context\nfor the canvas, then", "draws the image with its upper left corner at (", ").  Both\nthe point (", ") and the image itself are transformed by any\ntransformation in effect in the graphics context.  This will draw\nthe image using its natural width and height (scaled by the transformation,\nif any).  You can also specify the width and height of the rectangle\nin which the image is drawn:", "With this version of ", ", the image is scaled to fit\nthe specified rectangle.", "Now, suppose that the image you want to draw onto the canvas is not\npart of the web page?  In that case, it is possible to load the image dynamically.\nThis is much like making an off-screen canvas, but you are making\nan \"off-screen image.\"  Use the ", " object to create an\n", " element:", "An ", " element needs a ", " attribute that\nspecifies the URL from which it is to be loaded.  For example,", "As soon as you assign a value to the ", " attribute, the browser\nstarts loading the image.  The loading is done asynchronously; that is,\nthe computer continues to execute the script without waiting for the\nload to complete.  This means that you can't simply draw the image on\nthe line after the above assignment statement:  The image is very likely\nnot done loading at that time.  You want to draw the image after it has\nfinished loading.  For that to happen, you need to assign a function to the image's ", "\nproperty before setting the ", ". That function will\nbe called when the image has been fully loaded.  Putting this together, here is a simple \nJavaScript function for loading an image from a specified URL and drawing it on a canvas\nafter it has loaded:", "A similar technique is used to load the images in the filter demo.", "There is one last mystery to clear up.  When discussing the use of an off-screen\ncanvas in the ", " example earlier in this section, I noted that\nthe contents of the off-screen canvas have to be copied to the main canvas,\nbut I didn't say how that can be done.  In fact, it is done using ", ".\nIn addition to drawing an image onto a canvas, ", " can be used to draw the contents of\none canvas into another canvas.  In the sample program, the command", "is used to draw the off-screen canvas to the main canvas.  Here, ", "\nis a graphics context for drawing on the main canvas, and ", " is the object\nthat represents the off-screen canvas."], "chapter_title": "Two-Dimensional Graphics", "id": 2.6}, {"section_title": "Java Graphics2D", "chapter_id": "Chapter 2", "section_id": "Section 2.5", "content": ["In the rest of this chapter, we look at specific implementations\nof two-dimensional graphics.  There are a few new ideas here,\nbut mostly you will see how the general concepts that we have covered are used in several\nreal graphics systems.", "In this section, our focus is on the Java programming language.\nJava remains one of the most popular programming languages.  Its\nstandard desktop version includes a sophisticated 2D graphics API,\nwhich is our topic here.  Before reading this section, you should\nalready know the basics of Java programming. But even if you don't,\nyou should be able to follow most of the discussion of the\ngraphics API itself.  (See ", " in ", " for a very basic\nintroduction to Java.)", "The original version of Java had a much smaller graphics API.  It was\ntightly focused on pixels, and it used only integer coordinates.  The API\nhad subroutines for stroking and filling a variety of basic shapes,\nincluding lines, rectangles, ovals, and polygons (although Java uses the\nterm ", " instead of ", ").  Its specification\nof the meaning of drawing operations was very precise on the pixel\nlevel.  Integer coordinates are defined to refer to the lines\nbetween pixels.  For example, a 12-by-8 pixel grid has\n", "-coordinates from 0 to 12 and ", "-coordinates from\n0 to 8, as shown below.  The lines between pixels are numbered,\nnot the pixels.", "\n", "The command ", "(3,2,5,3)\nfills the rectangle with upper left corner at (3,2), with\nwidth 5, and with height 3, as shown on the left above.  The command\n", "(3,2,5,3) conceptually drags a \"pen\" around the outline\nof this rectangle.  However, the pen is a 1-pixel square, and it is the\nupper left corner of the pen that moves along the outline.  As the pen\nmoves along the right edge of the rectangle, the pixels to the ", "\nof that edge are colored; as the pen moves along the bottom edge, the\npixels below the edge are colored.  The result is as shown on the right above.\nMy point here is not to belabor the details, but to point out that having\na precise specification of the meaning of graphical operations gives you very\nfine control over what happens on the pixel level.", "Java's original graphics did not support things like real-number coordinates, \n", ", ", ", or \n", ".  Just a few years after Java was first introduced,\na new graphics API was added that does support all of these.  It is that\nmore advanced API that we will look at here.", "Java is an object-oriented language.  Its API is defined as a large set\nof classes,   The actual drawing operations in the original graphics API\nwere mostly contained in the class named ", ".  \nIn the newer API, drawing operations are methods in a class named ", ",\nwhich is a subclass of ", ", so that all the original drawing operations\nare still available.  (A class in Java is contained in a collection of classes known as a \"package.\"\n", " and ", ", for example, are in the\npackage named ", ".  Classes that define shapes and transforms are in a package\nnamed ", ".  However, in the rest of this section, I will talk about classes\nwithout mentioning their packages.)", "A graphics system needs a place to draw.  In Java, the drawing surface is often an object\nof the class ", ", which represents a rectangular area on the\nscreen.  The ", " class has a method named ", "()\nto draw its content.  To create a drawing surface, you can create a subclass of\n", " and provide a definition for its ", "()\nmethod.  All drawing should be done inside ", "(); when it is necessary\nto change the contents of the drawing, you can call the panel's ", "() method\nto trigger a call to ", "().  The ", "() method has\na parameter of type ", ", but the parameter that is passed\nto the method is actually an object of type ", ", and\nit can be type-cast to ", " to obtain access to the\nmore advanced graphics capabilities.  So, the definition of the ", "()\nmethod usually looks something like this:", "In the rest of this section, I will assume that ", " is a variable of\ntype ", ", and I will discuss some of the things\nthat you can do with it.  As a first example, I note that ", "\nsupports ", ", but it is not turned on by default.  It\ncan be enabled in a graphics context ", " with the rather intimidating\ncommand", "For simple examples of graphics in complete Java programs,\nyou can look at the sample programs ", "\nand ", ".  They provide very minimal\nframeworks for drawing static and animated images, respectively, using ", ".\nThe program ", " is a similar framework for\nworking with mouse and key events in a graphics program.\nYou can use these programs as the basis for some experimentation if you want to explore\nJava graphics.", "Drawing with the original ", " class is done using integer coordinates, \nwith the measurement given in pixels. This works well in the standard coordinate system, but is\nnot appropriate when real-number coordinates are used, since the unit of measure in such a \ncoordinate system will not be equal to a pixel.  We need to be able to specify shapes using\nreal numbers.  The Java package ", " provides support for shapes defined using real number \ncoordinates.  For example, the class ", " in that package represents line segments\nwhose endpoints are given as pairs of real numbers.", "Now, Java has two real number types: ", " and ", ".\nThe ", " type can represent a larger range of numbers than ", ", with a greater\nnumber of significant digits, and ", " is the\nmore commonly used type.  In fact, ", " are simply easier to use in Java.\nHowever, ", "  values generally have enough accuracy\nfor graphics applications, and they have the advantage of taking up less space in memory.\nFurthermore, computer graphics hardware often uses float values internally.", "So, given\nthese considerations, the ", " package actually provides\ntwo versions of each shape, one using coordinates of type ", " and\none using coordinates of type ", ".  This is done in a rather strange way.\nTaking ", " as an example, the class ", "\nitself is an ", ".  It has two subclasses, one that represents lines using\n", " coordinates and one using ", " coordinates.\nThe strangest part is that these subclasses are defined as nested classes\ninside ", ": ", " and\n", ".  This means that you can declare a variable of\ntype ", ", but to create an object, you need to use\n", " or ", ":\n", "Note that when using constants of type ", " in Java,\nyou have to add \"F\" as a suffix to the value.  this is one reason why ", "\nare easier in Java.  For simplicity, you might want to stick to using\n", ".  However, ", " might give\nslightly better performance.", "Let's take a look at some of the other classes from ", ".\nThe abstract class ", "\u2014with its concrete subclasses \n", " and ", "\u2014represents\na point in two dimensions, specified by two real number coordinates.  A point is not a\nshape; you can't fill or stroke it.  A point can be\nconstructed from two real numbers (\"", "\").  If ", "\nis a variable of type ", ", you can use ", "() and\n", "() to retrieve its coordinates, and you can use ", "(", "),\n", "(", "), or ", "(", ",", ") to set its coordinates.\nIf ", " is a variable of type ", ", you can also refer\ndirectly to the coordinates as ", " and ", "\n(and similarly for ", ").\nOther classes in ", " offer a similar variety of ways\nto manipulate their properties, and I won't try to list them all here.\n", " The package ", "\ncontains a variety of classes that represent geometric shapes, including  ", ",\n", ", ", ",\n", ", ", ",\nand ", ".\nAll of these are abstract classes, and each of them contains a pair of subclasses such as\n", " and ", ".\nSome shapes, such as rectangles, have\ninteriors that can be filled; such shapes also have\noutlines that can be stroked.  Some shapes, such as lines, are purely one-dimensional\nand can only be stroked.", "Aside from lines, rectangles are probably the simplest shapes.  A ", "\nhas a corner point (", ",", "), a ", ", and a ", ", and\ncan be constructed from that data (\"", "\").  The corner point\n(", ",", ") specifies the minimum ", "- and ", "-values in the rectangle.\nFor the usual pixel coordinate\nsystem, (", ",", ") is the upper left corner.  However, in a coordinate system in which the\nminimum value of ", " is at the bottom, (", ",", ") would be the lower left corner.\nThe sides of the rectangle are parallel to the coordinate axes.  A variable\n", " of type ", "\nhas public instance variables ", ", ", ", ", ", and ", ".\nIf the width or the height is less than or equal to zero, nothing will be drawn when the rectangle\nis filled or stroked.   A common task is to define a rectangle from two corner points (", ",", ")\nand (", ",", ").  This can be accomplished by creating a rectangle with height and width\nequal to zero and then ", " the second point to the rectangle.\nAdding a point to a rectangle causes the rectangle to grow just enough to include that point:\n", "The classes ", ",\n", ", ", "\nand ", " create other basic shapes and work similarly\nto ", ".  You can check the Java API documentation for details.", "The ", " class is more interesting. It represents general\npaths made up of segments that can be lines and ", ".\nPaths are created using methods similar to the ", " and ", "\nsubroutines that were discussed in ", ".  To create a\npath, you start by constructing an object of type ", "\n(or ", "):", "The path ", " is empty when it is first created.\nYou construct the path by moving an imaginary \"pen\" along the path that you want to create.\nThe method ", "(", ",", ") moves the pen to the point (", ",", ") without\ndrawing anything.  It is used to specify the initial point of the path or\nthe starting point of a new piece of the path.\nThe method ", "(", ",", ") draws a line\nfrom the current pen position to (", ",", "), leaving the pen at (", ",", ").\nThe method ", "() can be used to close the path (or the current piece of the path) \nby drawing a line back to its starting point.\nFor example, the following code creates a triangle with vertices at (0,5), (2,-3), and (-4,1):\n", "You can also add Bezier curve segments to a ", ".  \nBezier curves were discussed in ", ".   You can\nadd a cubic Bezier curve to a ", " ", " with the method\n", "This adds a curve segment that starts at the current pen position and ends at\n(", ",", "), using (", ",", ") and (", ",", ") as\nthe two ", " for the curve.  The\nmethod for adding a quadratic Bezier curve segment to a path is ", ".\nIt requires only a single control point:", "When a path intersects itself, its interior is determined by looking at\nthe ", ", as discussed in ", ".\nThere are two possible rules for determining whether a point is interior:\nasking whether the winding number of the curve about that point is non-zero, \nor asking whether it is even.  You can set the winding rule used by a ", "\n", " with", "The default is ", ".", "Finally, I will note that it is possible to draw a copy of an image into a graphics context.\nThe image could be loaded from a file or created by the program.  I discuss the second possibility\nlater in this section.  An image is represented by an object of type ", ".\nIn fact, I will assume here that the object is of type ", ",\nwhich is a subclass of ", ".  If ", " is such an object, then", "will draw the image with its upper left corner at the point (", ",", ").  (The fourth\nparameter is hard to explain, but it should be specified as ", " for ", ".)  \nThis draws the image\nat its natural width and height, but a different width and height can be specified in the method:", "There is also a method for drawing a string of text.  The method specifies the\nstring and the basepoint of the string.  (The basepoint is the lower left corner of\nthe string, ignoring \"descenders\" like the tail on the letter \"g\".)  For example,", "Images and strings are subject to transforms in the same way as other shapes. Transforms\nare the only way to get rotated text and images.  As an example, here is what can happen\nwhen you apply a rotation to some text and an image:", "\n", "Once you have an object that represents a shape, you can fill the shape or stroke it.\nThe ", " class defines methods for doing this.\nThe method for stroking a shape is called ", ":", "Here, ", " is of type ", ", and\nshape can be of type ", ", ", ",\n", " or any of the other shape classes.  These are\noften used on a newly created object, when that object represents a shape that\nwill only be drawn once.  For example", "Of course, it is also possible to create shape objects and reuse them many\ntimes.", "The \"pen\" that is used for stroking a shape is usually represented by an\nobject of type ", ".  The default stroke has line\nwidth equal to\u00a01.  That's one unit in the current coordinate system, not\none pixel.  To get a line with a different width, you can install a new stroke\nwith", "The ", " in the constructor is of type ", ".  It is possible to\nadd parameters to the constructor to control the shape of a stroke at its endpoints and\nwhere two segments meet.  (See ", ".)  For example,", "It is also possible to make strokes out of dashes and dots, but I won't discuss how\nto do it here.", "Stroking or filling a shape means setting the colors of certain pixels.  In Java, the rule\nthat is used for coloring those pixels is called a \"paint.\"  Paints can be solid colors,\n", ", or ", ".\nLike most things in Java, paints are represented by objects.  If ", " is\nsuch an object, then", "will set ", " to be used in the graphics context ", " for subsequent\ndrawing operations, until the next time the paint is changed.  (There is also an\nolder method, ", "(", "), that works only for colors and is\nequivalent to calling ", "(", ").)", "Solid colors are represented by objects of type ", ".  A color\nis represented internally as an ", ". An opaque color, with maximal\nalpha component, can be created using the constructor", "where ", ", ", ", and ", " are integers in the range 0 to 255 that give\nthe red, green, and blue components of the color.  To get a translucent color, you can\nadd an alpha component, also in the range 0 to 255:", "There is also a function, ", "(", "), that creates a color\nfrom values in the HSB color model (which is another name for ", ").\nIn this case, the hue, saturation, and brightness color components must be given as values of\ntype ", ".  And there are constants to represent about a dozen common\ncolors, such as ", ", ", ", and ", ".\nFor example, here is how I might draw a square with a black outline and a light\nblue interior:", "Beyond solid colors, Java has the class ", ", to represent\nsimple ", ", and ", "\nto represent to represent ", ".  (Image patterns\nused in a similar way in 3D graphics are called ", ".)\nGradients and patterns were discussed in ", ".\nFor these paints, the color that is applied to a pixel depends on the coordinates of the\npixel.", "To create a ", ", you need a ", "\nobject to specify the image that it will use as a pattern.  You also\nhave to say how coordinates in the image will map\nto drawing coordinates in the display.  You do this by specifying a rectangle in\nthat will hold one copy of the image.  So the constructor takes the form:", "where ", " is the ", " and ", " \nis a ", ".  Outside that specified rectangle, the image is\nrepeated horizontally and vertically. The constructor for a ", " \ntakes the form", "Here, ", ", ", ", ", ", and ", " are values of type ", ";\n", " and ", " are of type ", "; and\n", " is ", ".  The gradient color will vary along the line\nsegment from the point (", ",", ") to the point (", ",", ").\nThe color is ", " at the first endpoint and is ", " at the second\nendpoint.  Color is constant along lines perpendicular to that line segment.  The\nboolean parameter ", " says whether or not the color pattern repeats.\nAs an example, here is a command that will install a ", "\ninto a graphics context:", "You should, by the way, note that the current paint is used for strokes as well\nas for fills.", "The sample Java program ", " displays a polygon\nfilled with a ", " or a ", " \nand lets you adjust their properties.  The image files ", "\nand ", " are part of that program, and they must be\nin the same location as the compiled class files that make up that program when it is run.", "Java implements ", " as\nmethods in the ", " class. For example, if ", " is a\n", ", then calling ", "(1,3) will apply\na translation by (1,3) to objects that are drawn after the method is called. The methods\nthat are available correspond to the transform functions discussed in ", ":", "A transform in Java is represented as an object of the class ", ".\nYou can create a general ", " with the contstructor\n", "The transform ", " will transform a point (", ") to the point (", ") given by", "You can apply the transform ", " to a graphics context ", " by calling\n", "(", ").", "The graphics context ", " includes the current affine transform, which is the\ncomposition of all the transforms that have been applied.  Commands such as\n", " and ", " modify the current transform.  You can\nget a copy of the current transform by calling ", "(), which returns\nan ", " object.\nYou can set the current transform using ", "(", ").\nThis replaces the current transform in ", " with the ", "\n", ".  (Note that ", "(", ") is different from ", "(", ");\nthe first command ", " the current transform in ", ", while the second\n", " the current transform by composing it with ", ".)", "The ", " and ", " methods can be used to implement\n", ".  The idea, as discussed in ", ",\nis that before drawing an object, you should save the current transform.  \nAfter drawing the object, restore the saved transform.  Any additional modeling\ntransformations that are applied while drawing the object and its sub-objects will have\nno effect outside the object.  In Java, this looks like", "For hierarchical graphics, we really need a ", " of transforms.  However, if the hierarchy is implemented\nusing subroutines, then the above code would be part of a subroutine, and the value of the local\nvariable ", " would be stored on the subroutine call stack.  Effectively, we\nwould be using the subroutine call stack to implement the stack of saved transforms.", "In addition to modeling transformations, transforms are used to set up the\n", "-to-", " transformation that\nestablishes the ", " that will be used for drawing.\nThis is usually done in Java just after the graphics context has been created,\nbefore any drawing operations.  It can be done with a Java version of the\n", " \nfunction from ", ".  See the sample program\n", " for an example.", "I will mention one more use for ", " objects:  Sometimes,\nyou do need to explicitly transform coordinates.  For example, given ", "\n(", ",", "), I might need to know where they will actually end up on the screen, in \npixel coordinates.  That is, I would like to transform (", ",", ") by the current transform\nto get the corresponding pixel coordinates.  The ", " class\nhas a method for applying the affine transform to a point.  It works with objects of type\n", ".  Here is an example:", "One way I have used this is when working with strings.  Often when displaying a string in a\ntransformed coordinate system, I want to transform the basepoint of a string, but not\nthe string itself.  That is, I want the transformation to affect the location of the string\nbut not its size or rotation.  To accomplish this, I use the above technique to obtain\nthe pixel coordinates for the transformed basepoint, and then draw the string at\nthose coordinates, using an original, untransformed graphics context.", "The reverse operation is also sometimes necessary.  That is, given pixel coordinates\n(", ",", "), find the point (", ",", ") that is transformed to (", ",", ")\nby a given affine transform.  For example, when implementing mouse interaction, you will\ngenerally know the pixel coordinates of the mouse, but you will want to find the corresponding\npoint in your own chosen coordinate system.  For that, you need an ", ".\nThe inverse of an affine transform ", " is another transform that performs the opposite transformation.\nThat is, if ", "(", ",", ") = (", ",", "), \nand if ", " is the inverse transform, then ", "(", ",", ")\n= (", ",", "). In Java, the inverse transform of an ", "\n", " can be obtained with", "(A final note: The older drawing\nmethods from ", ", such as ", ", use integer coordinates.\nIt's important to note that any shapes drawn using these older methods are subject to the same transformation\nas shapes such as ", " that are specified with real\nnumber coordinates. For example, drawing a line with ", "(1,2,5,7)\nwill have the same effect as drawing a ", " that\nhas endpoints (1.0,2.0) and (5.0,7.0).  In fact, all drawing is affected by\nthe transformation of coordinates.)", "In some graphics applications, it is useful to be able to work with images that\nare not visible on the screen.  That is, you need what I call an ", ".\nYou also need a way to quickly copy the off-screen canvas onto the screen.\nFor example, it can be useful to store a copy of the on-screen image in an off-screen canvas.\nThe canvas is the official copy of the image.  Changes to the image are made to the canvas,\nthen copied to the screen.  One reason to do this is that you can then draw extra stuff on\ntop of the screen image without changing the official copy.  For example, you might draw\na box around a selected region in the on-screen image.  You can do this without damaging the\nofficial copy in the off-screen canvas.  To remove the box from the screen, you just have\nto copy the canvas image onto the screen.", "In Java, an off-screen image can be implemented as an object of type ", ".\nA ", " represents a region in memory where you can draw, in exactly the\nsame way that you can draw to the screen.  That is, you can obtain a graphics context\n", " of type ", " that you can use for drawing on the image.\nA ", " is an ", ", and you can draw\nit onto the screen\u2014or into any other graphics context\u2014like any other ", ",\nthat is, by using the ", " method of the graphics context where you want to display the\nimage.  In a typical setup, there are variables", "The objects are created using, for example,", "The constructor for ", " specifies the\nwidth and height of the image along with its type.  The type tells what\ncolors can be represented in the image and how they are stored.  Here,\nthe type is ", ", which means the image uses\nregular ", " with 8 bits for each\ncolor component.  The three color components for a pixel are packed\ninto a single integer value.", "In a program that uses a ", " to store a copy of\nthe on-screen image, the ", " method generally has the form", "A sample program that uses this technique is ", ".\nIn that program, the user can draw lines, rectangles, and ovals by dragging the mouse.\nAs the mouse moves, the shape is drawn between the starting point of the mouse and its\ncurrent location.  As the mouse moves, parts of the existing image can be repeatedly covered \nand uncovered, without changing the existing image.  In fact, the image is in an off-screen \ncanvas, and the shape that the user is drawing is actually drawn by ", "\nover the contents of the canvas.  The shape is not drawn to the official image in the canvas\nuntil the user releases the mouse and ends the drag operation.", "But my main reason for writing the program was to illustrate pixel manipulation, that is,\ncomputing with the color components of individual pixels.  The ", "\nclass has methods for reading and setting the color of individual pixels.  An image consists of\nrows and columns of pixels.  If ", " is a ", ", then", "gets the integer that represents the color of the pixel in column number ", " and row\nnumber ", ".  Each color component is stored in an 8-bit field in the integer ", "\nvalue.  The individual color components can be extracted for processing using Java's bit\nmanipulation operators:", "Similarly, given red, green, and blue color component values in the range 0 to 255,\nwe can combine those component values into a single integer and use it to set the\ncolor of a pixel in the image:", "There are also methods for reading and setting the colors of an entire rectangular\nregion of pixels.", "Pixel operations are used to implement two features of the sample program.  First, there is a\n\"Smudge\" tool.  When the user drags with this tool, it's like smearing wet paint.  When\nthe user first clicks the mouse, the color components from a small square of pixels surrounding\nthe mouse position are copied into arrays.  As the user moves the mouse, color from the\narrays is blended with the color of the pixels near the mouse position.  Here is a\nsmall rectangle that has been \"smudged\":", "\n", "The second use of pixel manipulation is in implementing \"filters.\"  A filter, in this\nprogram, is an operation that modifies an image by replacing the color of each \npixel with a weighted average of the colors of a 3-by-3 square of pixels.\nA \"Blur\" filter for example, uses equal weights for all pixels in the average, \nso the color of a pixel is changed to the simple average of the colors of that \npixel and its neighbors.  Using different weights for each pixel can produce some \nstriking effects.", "The pixel manipulation in the sample program produces effects that can't be achieved\nwith pure ", ".  I encourage you to learn more by looking at\nthe ", ".\nYou might also take a look at the live demos in the  ", ",\nwhich implement the same effects using ", " graphics."], "chapter_title": "Two-Dimensional Graphics", "id": 2.5}, {"section_title": "Hierarchical Modeling", "chapter_id": "Chapter 2", "section_id": "Section 2.4", "content": ["In this section, we look at how complex scenes can be built\nfrom very simple shapes.  The key is hierarchical\nstructure.  That is, a complex object can be made up of\nsimpler objects, which can in turn be made up of even\nsimpler objects, and so on until it bottoms out with\nsimple ", "\nthat can be drawn directly.  This is called\n", ".  We will see\nthat the ", "\nthat were studied in the ", "\nplay an important role in hierarchical modeling.", "Hierarchical structure is the key to dealing with complexity\nin many areas of computer science (and in the rest of reality),\nso it be no surprise that it plays an important role in\ncomputer graphics.", "A major motivation for introducing a new coordinate system is that it should be\npossible to use the coordinate system that is most natural to the scene that you want to\ndraw.  We can extend this idea to individual objects in a scene:  When drawing an object,\nuse the coordinate system that is most natural for the object.\n", "Usually, we want an object in its natural coordinates to be centered at the origin, (0,0),\nor at least to use the origin as a convenient reference point.  Then, to place it in\nthe scene, we can use a ", " transform, followed by a ", ", \nfollowed by a ", " to set its size, orientation, and position in the scene.  \nRecall that transformations used in this way are called \n", ".\nThe transforms are often applied in the order scale, then rotate, then translate,\nbecause scaling and rotation leave the reference point, (0,0), fixed.  Once the object\nhas been scaled and rotated, it's easy\nto use a translation to move the reference point to any desired point in the scene.\n(Of course, in a particular case, you might not need all three operations.) Remember that in the code,\nthe transformations are specified in the opposite order from the order in which they are\napplied to the object and that the transformations are specified before drawing the\nobject.  So in the code, the translation would come first, followed by the rotation and\nthen the scaling.  Modeling transforms are not always composed in this order, but\nit is the most common usage.", "The modeling transformations that are used to place an object in the scene should not\naffect other objects in the scene.  To limit their application to just the one object,\nwe can save the current transformation before starting work on the object and restore it\nafterwards.  How this is done differs from one graphics ", " to another, \nbut let's suppose here that there are subroutines ", "() and\n", "() for performing those tasks.  That is, ", "\nwill make a copy of the modeling transformation that is currently in effect and store\nthat copy.  It does not change the current transformation; it merely saves a copy.\nLater, when ", " is called, it will retrieve that copy and will\nreplace the current modeling transform with the retrieved transform.  Typical code\nfor drawing an object will then have the form:", "Note that we don't know and don't need to know what the saved transform does.\nPerhaps it is simply the so-called ", ", which\nis a transform that doesn't modify the coordinates to which it is applied.\nOr there might already be another transform in place, such as a coordinate transform that affects the scene as a whole.\nThe modeling transform for the object is effectively applied in addition to any other transform that\nwas specified previously.  The modeling transform moves the object from its natural coordinates into its\nproper place in the scene.  Then on top of that, a coordinate transform that is applied to the scene as a whole\nwould carry the object along with it.", "Now let's extend this idea.  Suppose that the object that we want to draw is itself a complex \npicture, made up of a number of smaller objects.  Think, for example, of a potted flower made up of\npot, stem, leaves, and bloom.  We would like to be able to draw the smaller component objects in their\nown natural coordinate systems, just as we do the main object.  For example, we would like to specify\nthe bloom in a coordinate system in which the center of the bloom is at (0,0).\nBut this is easy:  We draw each small component object, such as the bloom,\nin its own coordinate system, and use a modeling transformation to move the sub-object\ninto position ", ".  We are composing the complex object in its\nown natural coordinate system as if it were a complete scene.", "On top of that, we can apply ", " modeling\ntransformation to the complex object as a whole, to move it into the actual scene; \nthe sub-objects of the complex object are carried along with it.  That is,\nthe overall transformation that applies to a sub-object consists of a modeling transformation\nthat places the sub-object into the complex object, followed by the transformation that\nplaces the complex object into the scene.", "In fact, we can build objects that are made up of smaller objects which in turn\nare made up of even smaller objects, to any level. For example, we could draw the bloom's petals in\ntheir own coordinate systems, then apply modeling transformations to place the petals into the\nnatural coordinate system for the bloom.  There will be another\ntransformation that moves the bloom into position\non the stem, and yet another transformation that places the entire potted flower into the scene.\nThis is hierarchical modeling.", "Let's look at a little example.  Suppose that we want to draw a simple 2D image of a cart with\ntwo wheels.", "\n", "This cart is used as one part of a complex scene in an example below.\nThe body of the cart can be drawn as a pair of rectangles.  For the wheels, suppose that we\nhave written a subroutine", "that draws a wheel.  This subroutine draws the wheel in its own natural coordinate system. \nIn this coordinate system, the wheel is centered at (0,0) and has radius\u00a01.", "In the cart's coordinate system, I found it convenient to use the midpoint of the base of the\nlarge rectangle as the reference point.  I \nassume that the positive direction of the ", "-axis points upward, which is the common\nconvention in mathematics.  The rectangular body of the cart has\nwidth 6 and height 2, so the coordinates of the lower left corner of the rectangle are (-3,0),\nand we can draw it with a command such as ", "(-3,0,6,2).\nThe top of the cart is a smaller red rectangle, which can be drawn in a similar way.\nTo complete the cart, we need\nto add two wheels to the object.  To make the size of the wheels fit the cart, they need to be scaled.\nTo place them in the correct positions relative to body of the cart, one wheel must be translated\nto the left and the other wheel, to the right.  When I coded this example, I had to play\naround with the numbers to get the right sizes and positions for the wheels, and I found\nthat the wheels looked better if I also moved them down a bit.  Using the usual techniques of\nhierarchical modeling, we save the current transform before drawing each wheel, and we restore it after\ndrawing the wheel. This restricts the effect of the modeling transformation for the wheel\nto that wheel alone, so that it does not affect any other part of the cart.\nHere is pseudocode for a  subroutine that draws the cart in its own coordinate system:", "It's important to note that the same subroutine is used to draw both wheels.  The reason that\ntwo wheels appear in the picture in different positions is that different modeling transformations are in effect for the\ntwo subroutine calls.", "Once we have this cart-drawing subroutine, we can use it to add a cart to a scene.\nWhen we do this, we apply another modeling transformation to the cart as a whole.  Indeed, we could add several carts\nto the scene, if we wanted, by calling the ", " subroutine several times with different modeling transformations.\n", "You should notice the analogy here:  Building up a complex scene out of objects is similar to\nbuilding up a complex program out of subroutines.  In both cases, you can work on pieces of the\nproblem separately, you can compose a solution to a big problem from solutions to smaller problems,\nand once you have solved a problem, you can reuse that solution in several places.\n", "Here is a demo that uses\nthe cart in an animated scene:", "\n", "\n", "You can probably guess how hierarchical modeling is used to draw \nthe three windmills in this example.\nThere is a ", " method that draws a windmill in its own coordinate system.  Each of the\nwindmills in the scene is then produced by applying a different modeling transform to the standard\nwindmill.  Furthermore, the windmill is itself a complex object that is constructed from several\nsub-objects using various modeling transformations.", "It might not be so easy to see how different parts of the scene can be animated.  In fact, animation\nis just another aspect of modeling.  A computer ", " consists of a sequence of frames.  Each frame\nis a separate image, with small changes from one frame to the next.  From our point of view, each frame\nis a separate scene and has to be drawn separately.  The same object can appear in many frames.  To\nanimate the object, we can simply apply a different modeling transformation to the object in each\nframe.  The parameters used in the transformation can be computed from the current time or from the frame number.\nTo make a cart move from left to right, for example, we might apply a modeling transformation", "to the cart, where ", " is the frame number.\nIn each frame, the cart will be 0.1 units farther to the right than in the previous\nframe.  (In fact, in the actual program, the translation that is applied to the cart is\n", "which moves the reference point of the cart from -3 to 13 along the horizontal axis\nevery 300 frames.  In the coordinate system that is used for the scene, the x-coordinate\nranges from 0 to 7, so this puts the cart outside the scene for much of the loop.)", "The really neat thing is that this type of animation works with hierarchical modeling.  For example,\nthe ", " method doesn't just draw a windmill\u2014it draws an ", " windmill,\nwith turning vanes.  That just means that the rotation applied to the vanes depends on the frame \nnumber.  When a modeling transformation is applied to the windmill, the rotating vanes are scaled and\nmoved as part of the object as a whole.  This is an example of hierarchical modeling.\nThe vanes are sub-objects of the windmill.  The rotation of the vanes is part of the modeling\ntransformation that places the vanes into the windmill object.  Then a further modeling transformation\nis applied to the windmill object to place it in the scene.\n", "The file ", " contains\nthe complete source code for a Java version of this example.  The ", "\nof this book covers graphics programming in Java.  Once you are familiar with that, you should take\na look at the source code, especially the ", "() method, which draws the entire scene.", "Logically, the components of a complex scene form a structure.  In this structure,\neach object is associated with the sub-objects that it contains.  If the scene is hierarchical,\nthen the structure is hierarchical.  This structure is known as a\n", ".  A scene graph is a tree-like structure,\nwith the root representing the entire scene, the children of the root representing the\ntop-level objects in the scene, and so on.  We can visualize the scene graph for our\nsample scene:", "\n", "In this drawing, a single object can have several connections to one or\nmore parent objects.  Each connection represents one occurrence of the object in its\nparent object.  For example, the \"filled square\" object occurs as a sub-object\nin the cart and in the windmill.  It is used twice in the cart and once in the\nwindmill.  (The cart contains two red rectangles, which are created as squares\nwith a non-uniform scaling; the pole of the windmill is made as a scaled square.)\nThe \"filled circle\" is used in the sun and is used twice in the wheel.  The \"line\"\nis used 12 times in the sun and 12 times in the wheel; I've drawn one thick arrow, marked\nwith a 12, to represent 12 connections.  The wheel, in turn, is used twice in\nthe cart.  (My diagram leaves out, for lack of space, two occurrences of the filled\nsquare in the scene: It is used to make the road and the line down the middle of the road.)", "Each arrow in the picture can be associated with a modeling transformation\nthat places the sub-object into its parent object.  When an object contains several\ncopies of a sub-object, each arrow connecting the sub-object to the object will have\na different associated modeling transformation.  The object is the same for each copy;\nonly the transformation differs.", "Although the scene graph exists conceptually, in some applications it exists\nonly implicitly.  For example, the Java version of the program that was\nmentioned above draws the image \"procedurally,\" that is, by calling subroutines.\nThere is no data structure to represent the scene graph.\nInstead, the scene graph is implicit in\nthe sequence of subroutine calls that draw the scene.  Each node in the graph is a subroutine,\nand each arrow is a subroutine call.  The various objects are drawn using different\nmodeling transformations.  As discussed in ", ",\nthe computer only keeps track of a \"current transformation\" that represents all\nthe transforms that are applied to an object.  When an object is drawn by a subroutine,\nthe program saves the current transformation before calling the subroutine.\nAfter the subroutine returns, the saved transformation is restored.  \nInside the subroutine, the object is drawn in its own\ncoordinate system, possibly calling other subroutines to draw sub-objects with their\nown modeling transformations. Those extra transformations will have no effect outside of the subroutine,\nsince the transform that is in effect before the subroutine is called will be restored\nafter the subroutine returns.", "It is also possible for a scene graph to be represented by an actual data structure in the program.\nIn an object-oriented approach, the graphical objects in the scene are represented by\nprogram objects.  There are many ways to build an object-oriented scene graph ", ".\nFor a simple example implemented in Java, you can take a look at\n", ".  This program draws\nthe same animated scene as the previous example, but it represents the scene with\nan object-oriented data structure rather than procedurally.   The same scene graph API\nis implemented in ", " in the live demo shown\nearlier on this page, and you might take a look at that after you read about\n", " graphics in ", ".", "In the example\nprogram, both in Java and in JavaScript, a node in the scene graph is\nrepresented by an object belonging to a class named ", ".\n", " is an abstract class, and actual nodes in the scene graph are defined by \nsubclasses of that class.  For example, there is a subclass named\n", " to represent a complex graphical object that is\nmade up of sub-objects.  A variable, ", ", of type ", " includes \na method ", "(", ") for adding a sub-object to the compound object.", "When implementing a scene graph as data structure made up of objects,\na decision has to be made about how to handle transforms. \nOne option is to allow transformations to be associated with any node in the scene graph.  In this case, however,\nI decided to use special nodes to represent transforms as\nobjects of type  ", ".\nA ", " is a ", " that\ncontains a link to another ", " and also contains a\nmodeling transformation that is to be applied to that object.\nThe modeling transformation is given in terms of scaling, rotation, and translation amounts\nthat are instance variables in the object.  It is worth noting that these are always applied\nin the order scale, then rotate, then translate, no matter what order the instance variables\nare set in the code. If you want to do a translation followed by a rotation, you will need\ntwo ", " to implement it, since a translation plus a rotation\nin the same ", " would be applied in the order rotate-then-translate.\nIt is also worth noting that the setter methods for the scaling,\nrotation, and translation have a return value that is equal to the object.  This makes it possible\nto chain calls to the methods into a single statement such as", "and even say things like", "This type of chaining can make for\nmore compact code and can eliminate the need for a lot of extra temporary variables.", "Another decision has to be made about how to handle color.  One possibility would be\nto make a ", " class similar to\n", ".  However, in this case I just added\na ", "() method to the main ", "\nclass.  A color that is set on a compound object is inherited by any sub-objects,\nunless a different color is set on the sub-object.  In other words, a color on a compound object\nacts as a default color for its sub-objects, but color can be overridden on the sub-objects.", "In addition to compound objects and transformed objects, we need scene graph\nnodes to represent the basic graphical objects that occupy the bottom level of the scene graph.\nThese are the nodes that do the actual drawing in the end.", "For those who are familiar with data structures, I will note that\na scene graph is actually an example of a \"directed acyclic graph\" or \"dag.\"\nThe process of drawing the scene involves a traversal of this dag.  The\nterm \"acyclic\" means that there can't be cycles in the graph.  For a scene graph,\nthis is the obvious requirement that an object cannot be a sub-object, either\ndirectly or indirectly, of itself.", "Suppose that you write a subroutine to draw an object. At the beginning of the\nsubroutine, you use a routine such as ", "() to save a copy of the current transform.\nAt the end of the subroutine, you call ", "() to reset the current\ntransform back to the value that was saved.  Now, in order for this to work correctly\nfor hierarchical graphics, these routines must actually use a ", " of transforms.\n(Recall that a stack is simply a list where items can be added, or \"pushed,\" onto\none end of the list and removed, or \"popped,\" from the same end.)  The problem is that\nwhen drawing a complex object, one subroutine can call other subroutines.  This means that\nseveral drawing subroutines can be active at the same time,\neach with its own saved transform.  When a transform is saved after\nanother transform has already been saved, the system needs\nto remember both transforms.  When ", "() is called, it is the\nmost recently saved transform that should be restored.", "A stack has exactly the structure that is needed to implement these operations.\nBefore you start drawing an object, you would push the current transform onto the stack.  After drawing\nthe object, you would pop the transform from the stack.  Between those two operations, if the object is\nhierarchical, the transforms for its sub-objects will have been pushed onto and popped from the\nstack as needed.", "Some graphics APIs come with transform stacks already defined.\nFor example, the original OpenGL API includes the functions\n", "() and ", "() for using a stack of transformation matrices\nthat is built into OpenGL.  The Java 2D graphics API does not include a built-in\nstack of transforms, but it does have methods for getting and setting the current\ntransform, and the get and set methods can be used with an explicit stack data structure\nto implement the necessary operations.\nWhen we turn to the HTML canvas API for 2D graphics, we'll see that it includes\nfunctions named ", "() and ", "() that are actually ", "\nand ", " operations on a stack.  These functions are essential to implementing\nhierarchical graphics for an HTML canvas.", "Let's try to bring this all together by considering how it applies to a simple object\nin a complex scene: one of the filled circles that is part of the front wheel on the cart\nin our example scene.  Here, I have rearranged part of the scene graph for that scene, and I've added\nlabels to show the modeling transformations that are applied to each object:", "\n", "The rotation amount for the wheel and the translation amount for the cart are shown as\nvariables, since they are different in different frames of the animation.  When the computer\nstarts drawing the scene, the modeling transform that is in effect is the\n", ", that is, no transform at all.  As it prepares to draw\nthe cart, it saves a copy of the current transform (the identity) by pushing it onto the stack.\nIt then modifies the current transform by multiplying it by the modeling transforms for the cart,\n", "(0.3,0.3) and ", "(dx,0).  When it comes to drawing the wheel, it\nagain pushes the current transform (the modeling transform for the cart as a whole) onto the\nstack, and it modifies the current transform to take the wheel's modeling transforms into\naccount.  Similarly, when it comes to the filled circle, it saves the modeling transform\nfor the wheel, and then applies the modeling transform for the circle.", "When, finally, the\ncircle is actually drawn in the scene, it is transformed by the combined transform.\nThat transform places the circle directly into the scene, but it has been composed\nfrom the transform that places the circle into the wheel, the one that places the wheel \ninto the cart, and the one that places the cart into the scene.  After drawing the circle,\nthe computer replaces the current transform with one it pops from the stack.  That will be the \nmodeling transform for the wheel as a whole, and that transform will be used for any further parts of the\nwheel that have to be drawn.  When the wheel is done, the transform for the cart is popped.\nAnd when the cart is done, the original transform, the identity, is popped.  When the computer\ngoes onto the next object in the scene, it starts the whole process again, with the identity\ntransform as the starting point.", "This might sound complicated, but I should emphasize that it something that the computer\ndoes for you.  Your responsibility is simply to design the individual objects, in their\nown natural coordinate system. As part of that, you specify the modeling transformations that are applied\nto the sub-objects of that object.  You construct the scene as a whole in a similar way.\nThe computer will then put everything together for you, taking into account the many layers\nof hierarchical structure.  You only have to deal with one component of the structure at\na time.  That's the power of hierarchical design; that's how it helps you deal with complexity."], "chapter_title": "Two-Dimensional Graphics", "id": 2.4}, {"section_title": "Hardware and Software", "chapter_id": "Chapter 1", "section_id": "Section 1.3", "content": ["We will be using OpenGL as the primary basis for 3D graphics programming.\nThe original version of OpenGL was released in 1992 by a company named\nSilicon Graphics, which was known for its graphics workstations\u2014powerful,\nexpensive computers designed for intensive graphical applications.  (Today,\nyou probably have more graphics computing power on your smart phone.)  OpenGL\nis supported by the graphics hardware in most modern computing devices, including\ndesktop computers, laptops, and many mobile devices.  This section will give\nyou a bit of background about the history of OpenGL and about the graphics \nhardware that supports it.", "In the first desktop computers, the contents of the screen were managed\ndirectly by the ", ".  For example, to draw a line segment on the screen, the CPU\nwould run a loop to set the color of each pixel that lies along the line.\nNeedless to say, graphics could take up a lot of the CPU's time.  And graphics\nperformance was very slow, compared to what we expect today.  So what has changed?\nComputers are much faster in general, of course, but the big change is that\nin modern computers, graphics processing is done by a specialized component\ncalled a ", ", or Graphics Processing Unit.  A GPU includes processors\nfor doing graphics computations; in fact, it can include a large number of such\nprocessors that work in parallel to greatly speed up graphical operations.  \nIt also includes its own dedicated memory for storing things like images and \nlists of coordinates.  GPU processors have very fast\naccess to data that is stored in GPU memory\u2014much faster than their access to data\nstored in the computer's main memory.", "To draw a line or perform some other graphical operation, the CPU simply has to\nsend commands, along with any necessary data, to the GPU, which is responsible\nfor actually carrying out those commands.  The CPU offloads most of the graphical\nwork to the GPU, which is optimized to carry out that work very quickly.\nThe set of commands that the GPU understands make up the ", "\nof the GPU.  OpenGL is an example of a graphics API, and most GPUs support\nOpenGL in the sense that they can understand OpenGL commands, or at least\nthat OpenGL commands can efficiently be translated into commands that the\nGPU can understand.", "OpenGL is not the only graphics API.  The best-known alternative is probably \nDirect3D, a 3D graphics API used for Microsoft Windows.  OpenGL is more widely\navailable, since it is not limited to Microsoft, but Direct3D is supported by\nmost graphics cards, and it has often introduced new features earlier than OpenGL. ", "I have said that OpenGL is an API, but in fact it is a series of APIs that have\nbeen subject to repeated extension and revision.  The current version, in early\n2015, is 4.5, and it is very different from the 1.0 version from 1992.  Furthermore,\nthere is a specialized version called OpengGL\u00a0ES for \"embedded systems\" such\nas mobile phones and tablets.  And there is also WebGL, for use in Web browsers,\nwhich is basically a port of OpenGL ES\u00a02.0.  It's useful to know something\nabout how and why OpenGL has changed.", "First of all, you should know that OpenGL was designed as a \"client/server\"\nsystem.  The server, which is responsible for controlling the computer's\ndisplay and performing graphics computations, carries out commands issued by the\nclient.  Typically, the server is a GPU, including its graphics processors and memory.\nThe server executes OpenGL commands.  The client is the CPU in the same computer, along \nwith the application program that it is running. OpenGL commands come from the\nprogram that is running on the CPU.  However,\nit is actually possible to run OpenGL programs remotely over a network.  That\nis, you can execute an application program on a remote computer (the OpenGL client), while\nthe graphics computations and display are done on the computer that you are\nactually using (the OpenGL server).", "The key idea is that the client and the server are separate components, and there\nis a communication channel between those components.  OpenGL commands and the\ndata that they need are communicated from the client (the CPU) to the server (the GPU)\nover that channel.  The capacity of the channel can be a limiting factor in graphics\nperformance.  Think of drawing an image onto the screen.  If the GPU can draw the\nimage in microseconds, but it takes milliseconds to send the data for the image\nfrom the CPU to the GPU, then the great speed of the GPU is irrelevant\u2014most of\nthe time that it takes to draw the image is communication time.", "For this reason, one of the driving factors in the evolution of OpenGL has been\nthe desire to limit the amount of communication that is needed between the CPU and\nthe GPU.  One approach is to store information in the GPU's memory.  If some data\nis going to be used several times, it can be transmitted to the GPU once and\nstored in memory there, where it will be immediately accessible to the GPU.\nAnother approach is to try to decrease the number of OpenGL commands that must\nbe transmitted to the GPU to draw a given image.", "OpenGL draws ", " such as triangles.\nSpecifying a primitive means specifying ", "\nand ", " for each of its ", ".  In the\noriginal OpenGL\u00a01.0, a separate command was used to specify the coordinates of each vertex,\nand a command was needed each time the value of an attribute changed.  To draw a single \ntriangle would require three or more commands.  Drawing a complex object made up of\nthousands of triangles would take many thousands of commands.  Even in OpenGL\u00a01.1,\nit became possible to draw such an object with a single command instead of thousands.  All the data\nfor the object would be loaded into arrays, which could then be sent in a single\nstep to the GPU.  Unfortunately, if the object was going to be drawn more than\nonce, then the data would have to be retransmitted each time the object was drawn.\nThis was fixed in OpenGL\u00a01.5 with ", ".\nA VBO is a block of memory in the GPU that can store the coordinates or attribute values for\na set of vertices.  This makes it possible to reuse the data without having to retransmit it\nfrom the CPU to the GPU every time it is used.", "Similarly, OpenGL 1.1 introduced ", "\nto make it possible to store several images on the GPU for use as ", ".\nThis means that texture images that are going to be reused several times can be loaded once\ninto the GPU, so that the GPU can easily switch between images without having to reload them.", "As new capabilities were added to OpenGL, the API grew in size.  But the growth was still\noutpaced by the invention of new, more sophisticated techniques for doing graphics.  Some\nof these new techniques were added to OpenGL, but\nthe problem is that no matter how many features you add, there will always be demands for \nnew features\u2014as well as complaints that all the new features are making things too \ncomplicated! OpenGL was a giant machine, with new pieces always being tacked onto it, \nbut still not pleasing everyone. The real solution was to make the machine ", ".\nWith OpenGL 2.0, it became possible to write programs to be executed as part of the\ngraphical computation in the GPU.  The programs are run on the GPU at GPU speed.\nA programmer who wants to use a new graphics technique can write a program to \nimplement the feature and just hand it to the GPU.  The OpenGL API doesn't have to\nbe changed.  The only thing that the API has to support is the ability to send programs\nto the GPU for execution.", "The programs are called ", " (although the term does't\nreally describe what most of them actually do).  The first shaders to be introduced were\n", " and ", ".\nWhen a ", " is drawn, some work has to be done at each vertex of the primitive,\nsuch as applying a ", " to the vertex coodinates or\nusing the ", " and global ", " environment\nto compute the color of that vertex.  A vertex shader is a program that can take over the\njob of doing such \"per-vertex\" computations.  Similarly, some work has to be done for each\npixel inside the primitive.  A fragment shader can take over the job of performing such\n\"per-pixel\" computations.  (Fragment shaders are also called pixel shaders.)", "The idea of programmable graphics hardware was very successful\u2014so successful that\nin OpenGL\u00a03.0, the usual per-vertex and per-fragment processing\nwas deprecated (meaning that its use was discouraged). \nAnd in OpenGL\u00a03.1, it was removed from\nthe OpenGL standard, although it is still present as an optional extension.  In practice,\nall the original features of OpenGL are still supported in desktop versions of OpenGL and will\nprobably continue to be available in the future.  On the embedded system side, however,\nwith OpenGL\u00a0ES\u00a02.0 and later, the use of shaders is mandatory, and a large part\nof the OpenGL\u00a01.1 API has been completely removed.\nWebGL, the version of OpenGL for use in web browsers, \nis based on OpenGL\u00a0ES\u00a02.0, and it also requires shaders to get anything at all done.\nNevertheless, we will begin our study of OpenGL with version 1.1.  Most of the concepts and\nmany of the details from that version are still relevant, and it offers an easier entry point\nfor someone new to 3D graphics programming.", "OpenGL shaders are written in ", " (OpenGL Shading Language).  Like\nOpenGL itself, GLSL has gone through several versions. We will spend some time later in the\ncourse studying GLSL\u00a0ES\u00a01.0, the version used with WebGL\u00a01.0 and\nOpenGL\u00a0ES\u00a02.0.  GLSL uses a syntax similar to the C programming language.", "As a final remark on GPU hardware, I should note that the computations that are done for\ndifferent vertices are pretty much independent, and so can potentially be done in parallel.\nThe same is true of the computations for different fragments.  In fact, GPUs can\nhave hundreds or thousands of processors that can operate in parallel.  Admittedly, the\nindividual processors are much less powerful than a CPU, but then typical per-vertex\nand per-fragment computations are not very complicated.  The large number of processors,\nand the large amount of parallelism that is possible in graphics computations, makes\nfor impressive graphics performance even on fairly inexpensive GPUs."], "chapter_title": "Introduction", "id": 1.3}, {"section_title": "Elements of 3D Graphics", "chapter_id": "Chapter 1", "section_id": "Section 1.2", "content": ["When we turn to 3D graphics, we find that the most common approaches have more\nin common with ", " than with ", ".  \nThat is, the content of an image is specified as a list of geometric objects. \nThe technique is referred to as ", ". The starting point\nis to construct an \"artificial 3D world\" as a collection of simple geometric shapes, arranged in\nthree-dimensional space.  The objects can have ", " that, combined with\nglobal properties of the world, determine the appearance of the objects.\nOften, the range of basic shapes is very limited, perhaps including only points, line segments,\nand triangles.  A more complex shape such as a polygon or sphere can be built or\napproximated as a collection of more basic shapes, if it is not itself considered\nto be basic.  To make a two-dimensional image of the scene,\nthe scene is ", " from three dimensions \ndown to two dimensions.  Projection is the equivalent of\ntaking a photograph of the scene.  Let's look at how it all works in a\nlittle more detail.", "\n", "\nWe start with an empty 3D space or \"world.\" Of course, this space exists only conceptually, but it's \nuseful to think of it as real and to be able to visualize it in your mind.  The space needs\na ", " that associates each point in the space with three numbers, \nusually referred to as the ", ", ", ", and ", " coordinates of the point.\nThis coordinate system is referred to as \"world coordinates.\"", "We want to build a scene inside the world, made up of geometric objects.  For example, \nwe can specify a line segment in the scene by giving the coordinates of its two endpoints, \nand we can specify a triangle by giving the coordinates of its three vertices.  The smallest building\nblocks that we have to work with, such as line segments and triangles, are called\n", ".  Different graphics\nsystems make different sets of primitive available, but in many cases only very basic\nshapes such as lines and triangles are considered primitive.  A complex scene can contain\na large number of primitives, and it would be very difficult to create the scene by\ngiving explicit coordinates for each individual primitive.  The solution, as any programmer\nshould immediately guess, is to chunk together primitives into reusable components.\nFor example, for a scene that contains several automobiles, we might create a geometric\nmodel of a wheel.  An automobile can be modeled as four wheels together with models of\nother components.  And we could then use several copies of the automobile model in the\nscene.  Note that once a geometric model has been designed, it can be used as a\ncomponent in more complex models.  This is referred to as ", ".", "Suppose that we have constructed a model of a wheel out of geometric primitives.\nWhen that wheel is moved into position in the model of an automobile, the coordinates of\nall of its primitives will have to be adjusted.  So what exactly have we gained by building\nthe wheel?  The point is that all of the coordinates in the wheel are adjusted\n", ".  That is, to place the wheel in the automobile, we just have to\nspecify a single adjustment that is applied to the wheel as a whole.  The type of \"adjustment\"\nthat is used is called a ", " (or geometric\ntransformation).  A geometric transform\nis used to adjust the size, orientation, and position of a geometric object.  When making\na model of an automobile, we build ", " wheel.  We then apply four different\ntransforms to the wheel model to add four copies of the wheel to the automobile.\nSimilarly, we can add several automobiles to a scene by applying different transforms\nto the same automobile model.", "The three most basic kinds of geometric transform are called ", ",\n", ", and ", ".\nA scaling transform is used to set the size of an object, that is, to make it bigger or smaller\nby some specified factor.\nA rotation transform is used to set an object's orientation, by rotating it by some  angle\nabout some specific axis.  A translation transform is used to set the position of an\nobject, by displacing it by a given amount from its original position.\nIn this book, we will meet these transformations first in two dimensions, where they\nare easier to understand. But it is in 3D graphics that they become truly essential.", "\n", "\nGeometric shapes by themselves are not very interesting.  You have to be able\nto set their appearance.  This is done by assigning ", "\nto the geometric objects.  An obvious attribute is color, but getting a realistic \nappearance turns out to be a lot more complicated than simply specifying a color\nfor each primitive.  In 3D graphics, instead of color, we usually talk about\n", ".   The term material here refers to the properties that determine the\nintrinsic visual appearance of a surface.  Essentially, this means how the surface\ninteracts with light that hits the surface.  Material properties can include a basic\ncolor as well as other properties such as shininess, roughness, and transparency.\n", "One of the most useful kinds of material property is a ", ".\nIn most general terms, a texture is a way of varying material properties from point-to-point\non a surface.  The most common use of texture is to allow different colors for different\npoints.  This is done by using a 2D image as a texture, which can be applied to a surface\nso that the image looks like it is \"painted\" onto the surface.\nHowever, texture can also refer to changing values for things like transparency or\n\"bumpiness.\"  Textures allow us to add detail to a scene without using a huge number of\ngeometric primitives; instead, you can use a smaller number of textured primitives.", "A material is an intrinsic property of an object, but the actual appearance of the\nobject also depends on the environment in which the object is viewed.\nIn the real world, you don't see anything unless there is some light in the environment.\nThe same is true in 3D graphics:  you have to add simulated ", "\nto a scene.  There can be several sources of light in a scene.  Each light source can have \nits own color, intensity, and direction or position.  The light from those sources will \nthen interact with the material properties of the objects in the scene.  Support for\nlighting in a graphics system can range from fairly simple to very complex and computationally\nintensive.", "\n", "\nIn general, the ultimate goal of 3D graphics is to produce 2D images of the 3D world.  \nThe transformation from 3D to 2D involves ", " and\n", ".  The world looks different when seen from different\npoints of view.  To set up a point of view, we need to specify the position of the viewer \nand the direction that the viewer is looking.  It is also necessary to specify\nan \"up\" direction, a direction that will be pointing upwards in the final image.\nThis can be thought of as placing a \"virtual camera\" into the scene.  Once the\nview is set up, the world as seen from that point of view can be projected into\n2D.  Projection is analogous to taking a picture with the camera.", "The final step in 3D graphics is to assign colors to individual pixels in \nthe 2D image. This process is called ", ",\nand the whole process of producing an image is referred to as ", "\nthe scene.", "In many cases the ultimate goal is not to create a single image, but to create an\n", ", consisting a sequence of images that show the world\nat different times.  In an animation, there are small changes from one image in the\nsequence to the next.  Almost any aspect of a scene can change during an animation,\nincluding coordinates of primitives, transformations, material properties, and the view.\nFor example, an object can be made to grow over the course of an animation by\ngradually increasing the scale factor in a scaling transformation that is applied to\nthe object.  And changing the view during an animation can give the effect of\nmoving or flying through the scene.  Of course, it can be difficult to compute\nthe necessary changes.  There are many techniques to help with the computation.  One of the most \nimportant is to use a \"physics engine,\" which computes the motion \nand interaction of objects based on the laws of physics.  (However, you won't learn\nabout physics engines in this book.)"], "chapter_title": "Introduction", "id": 1.2}, {"section_title": "Painting and Drawing", "chapter_id": "Chapter 1", "section_id": "Section 1.1", "content": ["The main focus of this book is three-dimensional (3D) graphics,\nwhere most of the work goes into producing a 3D model of a scene.\nBut ultimately, in almost all cases, the end result of a computer\ngraphics project is a two-dimensional image.   And of course,\nthe direct production and manipulation of 2D images is an important\ntopic in its own right.  Furthermore, a lot of ideas carry over\nfrom two dimensions to three.  So, it makes sense to start\nwith graphics in 2D.", "An image that is presented on the computer screen is made up of ", ".  The screen\nconsists of a rectangular grid of pixels, arranged in rows and columns.  The pixels are small enough that\nthey are not easy to see individually.  In fact, for many very high-resolution displays, they become\nessentially invisible.  At a given time, each pixel can\nshow only one color.  Most screens these days use 24-bit color, where\na color can be specified by three 8-bit numbers, giving the levels of red, green, and blue in the color.\nAny color that can be shown on the screen is made up of some combination of these three \"primary\" colors.\nOther formats are possible, such as ", ", where each pixel is some shade of gray\nand the pixel color is given by one number that specifies the level of gray on a black-to-white scale.\nTypically, 256 shades of gray are used.\nEarly computer screens used ", ", where only a small set of colors, usually\n16 or 256, could be displayed.  For an indexed color display, there is a numbered list of possible colors,\nand the color of a pixel is specified by an integer giving the position of the color in the list.", "In any case, the color values for all the pixels on the screen are stored in a large block of memory\nknown as a ", ".  Changing the image on the screen requires changing\ncolor values that are stored in the frame buffer.  The screen is redrawn many times per second, so that almost immediately\nafter the color values are changed in the frame buffer, the colors of the pixels on the screen will\nbe changed to match, and the displayed image will change.", "A computer screen used in this way is the basic model of ", ".  The term \"raster\" technically\nrefers to the mechanism used on older vacuum tube computer monitors:  An electron beam would move along\nthe rows of pixels, making them glow.  The beam was moved\nacross the screen by powerful magnets that would deflect the path of the electrons.\nThe stronger the beam, the brighter the glow of the pixel, so the brightness of\nthe pixels could be controlled by modulating the intensity of the electron beam.  The color values\nstored in the frame buffer were used to determine the intensity of the electron beam.  (For a color\nscreen, each pixel had a red dot, a green dot, and a blue dot, which were separately illuminated by\nthe beam.)\n", "A modern flat-screen computer monitor is not a raster in the same sense.  There is no moving\nelectron beam.  The mechanism that controls the colors of the pixels is different for different\ntypes of screen.  But the screen is still made up of pixels, and the color values for all the\npixels are still stored in a frame buffer.  The idea of an image consisting of a grid of\npixels, with numerical color values for each pixel, defines raster graphics.\n", "Although images on the computer screen are represented using pixels, specifying individual\npixel colors is not always the best way to create an image.  Another way\nis to specify the basic geometric objects that it contains, shapes such as lines, circles,\ntriangles, and rectangles.  This is the idea that defines ", ":  Represent an\nimage as a list of the geometric shapes that it contains.  To make things more interesting,\nthe shapes can have ", ", such as the thickness of a line or the\ncolor that fills a rectangle.  Of course, not every image can be composed from simple\ngeometric shapes. This approach certainly wouldn't work for a picture of a beautiful sunset\n(or for most any other photographic image).  However, it works well for many types of\nimages, such as architectural blueprints and scientific illustrations.\n", "In fact, early in the history of computing, vector graphics was even used directly on\ncomputer screens.  When the first graphical computer displays were developed,\nraster displays were too slow and expensive to be practical.  Fortunately, it was\npossible to use vacuum tube technology in another way:  The electron beam could be made\nto directly draw a line on the screen, simply by sweeping the beam along that line.\nA vector graphics display would store a ", " of lines\nthat should appear on the screen.  Since a point on the screen would glow only very briefly\nafter being illuminated by the electron beam, the graphics display would go through\nthe display list over and over, continually redrawing all the lines on the list.\nTo change the image, it would only be necessary to change the contents of the display list.\nOf course, if the display list became too long, the image would start to flicker\nbecause a line would have a chance to visibly fade before its next turn to be redrawn.\n", "But here is the point: For an image that can be specified as a reasonably small\nnumber of geometric shapes, the amount of information needed to represent the image\nis much smaller using a vector representation than using a raster representation.\nConsider an image made up of one thousand line segments.  For a vector representation\nof the image, you only need to store the coordinates of two thousand points, the\nendpoints of the lines.  This would take up only a few kilobytes of memory.  To store\nthe image in a frame buffer for a raster display would require much more memory.  \nSimilarly, a vector display could\ndraw the lines on the screen more quickly than a raster display could copy the the same image from\nthe frame buffer to the screen.  (As soon as raster displays became fast and \ninexpensive, however, they quickly displaced vector displays because of their\nability to display all types of images reasonably well.)\n", "The divide between raster graphics and vector graphics persists in several areas\nof computer graphics.  For example, it can be seen in a division between two\ncategories of programs that can be used to create images:  ", "\nand ", ".  In a painting program, the image is represented\nas a grid of pixels, and the user creates an image by assigning colors to pixels.\nThis might be done by using a \"drawing tool\" that acts like a painter's brush,\nor even by tools that draw geometric shapes such as lines or rectangles. But the point in a\npainting program is to color the individual pixels, and it is only the pixel colors that are saved.\nTo make this clearer, suppose that you use a painting program to draw a house, then\ndraw a tree in front of the house.  If you then erase the tree, you'll only reveal a blank\nbackground, not a house.  In fact, the image never really contained a \"house\" at all\u2014only\nindividually colored pixels that the viewer might perceive as making up a picture of a house.\n", "In a drawing program, the user creates an image by adding geometric shapes, and the\nimage is represented as a list of those shapes.  If you place a house shape (or collection of shapes\nmaking up a house) in the image, and you then place a tree shape on\ntop of the house, the house is still there, since it\nis stored in the list of shapes that the image contains.  If you delete the tree, the house will\nstill be in the image, just as it was before you added the tree.  Furthermore, you should be able\nto select one of the shapes in the image and move it or change its size, so drawing programs\noffer a rich set of editing operations that are not possible in painting programs.  (The reverse,\nhowever, is also true.)\n", "A practical program for image creation and editing might combine elements of painting and\ndrawing, although one or the other is usually dominant.  For example, a drawing program might\nallow the user to include a raster-type image, treating it as one shape.  A painting program\nmight let the user create \"layers,\" which are separate images that can be layered one on top\nof another to create the final image.  The layers can then be manipulated much like the shapes\nin a drawing program (so that you could keep both your house and your tree in separate layers,\neven if in the image of the house is in back of the tree).\n", "Two well-known graphics programs are ", " and ", ".\n", " is in the category of painting programs, while ", " is more of a drawing program.\nIn the world of free software, the GNU image-processing program, ", ", is a good alternative\nto ", ", while ", " is a reasonably capable free drawing program.\nShort introductions to Gimp and Inkscape can be found in ", ".", "The divide between raster and vector graphics also appears in the field of graphics file formats.\nThere are many ways to represent an image as data stored in a file.  If the original image\nis to be recovered from the bits stored in the file, the representation must follow some exact, known\nspecification.  Such a specification is called a graphics file format.  Some popular graphics file\nformats include GIF, PNG, JPEG, and SVG.  Most images used on the Web are GIF, PNG, or JPEG.\nModern web browsers also have support for SVG images.\n", "GIF, PNG, and JPEG are basically raster graphics formats; an image is specified by storing a color \nvalue for each pixel.  GIF is an older file format,\nwhich has largely been superseded by PNG, but you can still find GIF images on the web.  (The GIF\nformat supports animated images, so GIFs are often used for simple animations on Web pages.) GIF uses\nan indexed color model with a maximum of 256 colors.  PNG can use either indexed or full 24-bit color,\nwhile JPEG is meant for full color images. \n", "The amount of data necessary to represent a raster image can be quite\nlarge.  However, the data usually contains a lot of redundancy, and the data can be \"compressed\"\nto reduce its size.  GIF and PNG use ", ", which means that the\noriginal image can be recovered perfectly from the compressed data.\nJPEG uses a ", " algorithm,\nwhich means that the image that is recovered from\na JPEG file is not exactly the same as the original image; some information has been lost.\nThis might not sound like a good idea, but in fact the difference is often not very noticeable, and\nusing lossy compression usually permits a greater reduction in the size of the compressed data.\nJPEG generally works well for photographic images, but not as well for images that have sharp edges\nbetween different colors.  It is especially bad for line drawings and images that contain text; PNG is \nthe preferred format for such images.  \n", "SVG, on the other hand, is fundamentally a vector graphics format (although SVG images can include\nraster images).  SVG is actually an XML-based language for describing two-dimensional vector graphics\nimages.  \"SVG\" stands for \"Scalable Vector Graphics,\" and the term \"scalable\" indicates one of the\nadvantages of vector graphics: There is no loss of quality  when the size of the image is increased.\nA line between two points can be represented at any scale, and it is still the same perfect geometric line.\nIf you try to greatly increase the size of a raster image, on the other hand, you will find that you don't\nhave enough color values for all the pixels in the new image; each pixel from the original image\nwill be expanded to cover a rectangle of pixels in the scaled image, and you will get multi-pixel blocks of\nuniform color.  The scalable nature of SVG images make them a good choice for web browsers and for\ngraphical elements on your computer's desktop.  And indeed, some desktop environments are now using\nSVG images for their desktop icons.", "A digital image, no matter what its format, is specified using a ", ".\nA coordinate system sets up a correspondence between numbers and geometric points.  In two dimensions,\neach point is assigned a pair of numbers, which are called the coordinates of the point.  The two coordinates\nof a point are often called its ", "-coordinate and ", "-coordinate, although the names\n\"x\" and \"y\" are arbitrary.", "A raster image is a two-dimensional grid of pixels arranged into\nrows and columns.  As such, it has a natural coordinate system in which each pixel corresponds \nto a pair of integers giving the number of the row and the number of the column that contain the\npixel.  (Even in this simple case, there is some disagreement as to whether the rows should be numbered from top-to-bottom\nor from bottom-to-top.)", "For a vector image, it is natural to use real-number coordinates.  The coordinate system for an\nimage is arbitrary to some degree; that is, the same image can be specified using different coordinate\nsystems.  I do not want to say a lot about coordinate systems here, but they will be a major\nfocus of a large part of the book, and they are even more important in three-dimensional graphics\nthan in two dimensions."], "chapter_title": "Introduction", "id": 1.1}]